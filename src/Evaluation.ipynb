{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models\n",
    "\n",
    "This notebook contains the code used for evaluating the following learning models:\n",
    "\n",
    "-  **Standard GBDT** (_baseline 1_)\n",
    "-  **Adversarial Boosting** (_baseline 2_)\n",
    "-  **Non-Interferent GBDT** (our proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-05 15:26:23,473 *** INFO [robust_forest.py:1151 - __init__()] *** ***** Robust Decision Tree successfully created *****\n",
      "2019-06-05 15:26:23,476 *** INFO [robust_forest.py:1152 - __init__()] *** *\tTree ID: 0\n",
      "2019-06-05 15:26:23,477 *** INFO [robust_forest.py:1153 - __init__()] *** *\tAttacker: <robust_forest.Attacker object at 0x7fe144028630>\n",
      "2019-06-05 15:26:23,478 *** INFO [robust_forest.py:1155 - __init__()] *** *\tSplitting criterion: SSE\n",
      "2019-06-05 15:26:23,479 *** INFO [robust_forest.py:1156 - __init__()] *** *\tMax depth: 8\n",
      "2019-06-05 15:26:23,480 *** INFO [robust_forest.py:1158 - __init__()] *** *\tMin instances per tree node: 20\n",
      "2019-06-05 15:26:23,481 *** INFO [robust_forest.py:1160 - __init__()] *** *\tMax samples: 100.0%\n",
      "2019-06-05 15:26:23,482 *** INFO [robust_forest.py:1162 - __init__()] *** *\tMax features: 100.0%\n",
      "2019-06-05 15:26:23,483 *** INFO [robust_forest.py:1164 - __init__()] *** *\tFeature blacklist: set()\n",
      "2019-06-05 15:26:23,485 *** INFO [robust_forest.py:1165 - __init__()] *** *\tAffinity: False\n",
      "2019-06-05 15:26:23,485 *** INFO [robust_forest.py:1167 - __init__()] *** *****************************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm\n",
    "import functools\n",
    "import parallel_robust_forest\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from nilib import *\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard evaluation metric\n",
    "\n",
    "The following function is the one used for evaluating the quality of the learned model (either _standard_, _adversarial-boosting_, or _non-interferent_). This is the standard <code>avg_log_loss</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    return np.log(p/(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(preds):\n",
    "    if np.min(preds)<-0.001:\n",
    "        return np.where(preds>=0,  1.0, -1.0)\n",
    "    else:\n",
    "        return np.where(preds>=.5, 1.0, -1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss(preds, train_data):\n",
    "    \n",
    "    labels = train_data.get_label()\n",
    "    losses = np.log(1.0 + np.exp(-preds*labels))\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    return 'avg_binary_log_loss', avg_loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_log_loss(y_true, y_pred):\n",
    "    losses = np.log(1.0 + np.exp(-y_pred*y_true))\n",
    "    avg_loss = np.mean(losses)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom evaluation metric\n",
    "\n",
    "Similarly to what we have done for <code>fobj</code>, <code>feval</code> can be computed from a weighted combination of two evaluation metrics:\n",
    "\n",
    "-  <code>avg_log_loss</code> (standard, defined above);\n",
    "-  <code>avg_log_loss_uma</code> (custom, defined below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss_uma</code>\n",
    "\n",
    "This is the binary log loss yet modified to operate on groups of perturbed instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom metric\n",
    "\n",
    "def binary_log_loss(pred, true_label):\n",
    "\n",
    "    return np.log(1.0 + np.exp(-pred * true_label))\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss_uma(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    attack_lens = train_data.get_group()\n",
    "    \n",
    "    offset = 0\n",
    "    max_logloss = []\n",
    "    avg_max_logloss = 0.0\n",
    "    \n",
    "    if attack_lens is not None:\n",
    "    \n",
    "        for atk in attack_lens:\n",
    "            losses = [binary_log_loss(h,t) for h,t in zip(preds[offset:offset+atk], labels[offset:offset+atk])]\n",
    "            max_logloss.append(max(losses))\n",
    "            \n",
    "            offset += atk\n",
    "        \n",
    "        avg_max_logloss = np.mean(max_logloss)  \n",
    "        \n",
    "    return 'avg_binary_log_loss_under_max_attack', avg_max_logloss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_log_loss_uma(preds, test, test_groups=None, svm=False):\n",
    "    \n",
    "    lgbm_test = lightgbm.Dataset(data=test.iloc[:,:-1].values, \n",
    "                                 label=test.iloc[:,-1].values,\n",
    "                                 group=test_groups,\n",
    "                                 free_raw_data=False)\n",
    "    \n",
    "    return avg_log_loss_uma(preds,lgbm_test)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_binary_err_rate</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_binary_err_rate(y_true, y_pred):\n",
    "    errs = np.sum(binarize(y_pred) != y_true)\n",
    "    return errs/len(y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_roc_auc</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_roc_auc(y_true, y_pred):\n",
    "    return roc_auc_score(y_true=y_true, y_score=y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_specificity</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_specificity(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y_true, y_pred=y_pred).ravel()\n",
    "\n",
    "    return tn/(tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_precision</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_precision(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    return precision_score(y_true=y_true, y_pred=y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_recall</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_recall(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    return recall_score(y_true=y_true, y_pred=y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_f1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_f1(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    return f1_score(y_true=y_true, y_pred=y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate each model w.r.t. _all_ evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def model_predict(model,test_set):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        print (\"BaggingClassifier\")\n",
    "#         print ( np.min( model.predict_proba(X)[:,0] ), np.max( model.predict_proba(X)[:,0] ) )\n",
    "#         print ( np.min( model.predict_proba(X)[:,1] ), np.max( model.predict_proba(X)[:,1] ) )\n",
    "        return model.predict_proba(X)[:,1]\n",
    "        # return model.predict(X)\n",
    "    else:\n",
    "        print (\"LightGBM\")\n",
    "#        print (np.unique( model.predict(X) ) )\n",
    "#         lgbm_X = lightgbm.Dataset(data=test_set.iloc[:,:-1], \n",
    "#                                   label=test_set.iloc[:,-1])\n",
    "\n",
    "        return model.predict(test_set.iloc[:,:-1])\n",
    "\n",
    "def model_worst_predict(model, test_set, test_groups):\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    preds  = model_predict(model, test_set)\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = preds[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "\n",
    "    return np.array(true_labels), np.array(worst_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learned_models(eval_metrics, model, model_type, test, test_groups=None, budget=0):\n",
    "    # output dataframe\n",
    "    header = ['Model'] + ['Budget'] + [m.__name__.replace('eval_','').replace('_',' ').strip().title() \n",
    "                                       for m in eval_metrics]\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    first_row = [model_type] + [budget] + [None for m in eval_metrics]\n",
    "    df.loc[0] = first_row\n",
    "    \n",
    "    # predictions for plan and atk datasets\n",
    "    if test_groups is None: # NOT ATKed\n",
    "        y_true = test.iloc[:,-1].values\n",
    "        y_pred = model_predict(model, test)\n",
    "    else:\n",
    "        y_true, y_pred = model_worst_predict(model, test, test_groups)\n",
    "        \n",
    "    for eval_metric in eval_metrics:\n",
    "        res = eval_metric(y_true=y_true, y_pred=y_pred)\n",
    "        print(\"{} learning - {} = {:.5f}\"\n",
    "                  .format(model_type, eval_metric.__name__, res))\n",
    "        column_metric = eval_metric.__name__\n",
    "        df[column_metric.replace('eval_','').replace('_',' ').strip().title()] = res\n",
    "\n",
    "    print(\"******************************************************************************************************\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load attacked datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an attacked dataset with a specific budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attacked_dataset(budget):\n",
    "    # load train/valid/test (attacked)\n",
    "    train_att, valid_att, test_att = load_atk_train_valid_test(TRAINING_FILENAME_ATT.format(budget), \n",
    "                                                                  VALIDATION_FILENAME_ATT.format(budget), \n",
    "                                                                  TEST_FILENAME_ATT.format(budget))\n",
    "\n",
    "    test_groups = test_att['instance_id'].value_counts().sort_index().values\n",
    "    test_att = test_att.iloc[:, 1:]\n",
    "\n",
    "    valid_groups = valid_att['instance_id'].value_counts().sort_index().values\n",
    "    valid_att = valid_att.iloc[:, 1:]\n",
    "\n",
    "    train_groups = train_att['instance_id'].value_counts().sort_index().values\n",
    "    train_att = train_att.iloc[:, 1:]\n",
    "    \n",
    "    return train_att, train_groups, valid_att, valid_groups, test_att, test_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load _all_ the attacked datasets given a list of budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attacked_datasets(budgets):\n",
    "    att_datasets = {}\n",
    "    for b in budgets:\n",
    "        att_datasets[b] = load_attacked_dataset(b)\n",
    "    \n",
    "    return att_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all models w.r.t. standard metrics (i.e., attack-free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_name(model_filename):\n",
    "    model_fileroot = model_filename.split('/')[-1].split('.')[0]\n",
    "    model_name = model_fileroot.split('_')[0].title()\n",
    "    training_budget = ''\n",
    "    budget = model_fileroot.split('_B')[-1].split('_')[0]\n",
    "    try: \n",
    "        int(budget)\n",
    "        training_budget = ' [train budget={}]'.format(budget)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return model_name + training_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    model = None\n",
    "    try:\n",
    "        model = lightgbm.Booster(model_file=model_file)\n",
    "    except:\n",
    "        print(\"LightGBM loading exception\")\n",
    "        try:\n",
    "            with open(model_file, 'rb') as mf:\n",
    "                model = dill.load(mf)\n",
    "                print(model)\n",
    "                model.n_jobs = 16\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Dill loading exception\")\n",
    "            pass\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_models(eval_metrics, models_dir, test, model_filenames=None):\n",
    "    \n",
    "    if model_filenames is None:\n",
    "        model_csv = sorted(glob.glob(models_dir + \"/*.csv\"))\n",
    "        model_filenames = []\n",
    "\n",
    "        for m in model_csv:\n",
    "            model_df = pd.read_csv(m)\n",
    "            # print(model_df)\n",
    "            model_filenames.append(model_df.sort_values(by='metric')['filename'].iloc[0])\n",
    "    \n",
    "    print (\"### Evaluating Models:\", model_filenames)\n",
    "    \n",
    "    df = pd.concat([eval_learned_models(eval_metrics, \n",
    "                                        load_model(mf), \n",
    "                                        extract_model_name(mf), \n",
    "                                        test) for mf in model_filenames],\n",
    "                   axis=0,\n",
    "                   sort=False\n",
    "                  )\n",
    "    \n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_models_under_attack_budget(eval_metrics, models_dir, test, test_groups, budget, model_filenames=None):\n",
    "    \n",
    "    #model_filenames = sorted(glob.glob(models_dir + \"/*.model\"))\n",
    "    if model_filenames is None:\n",
    "        model_csv = sorted(glob.glob(models_dir + \"/*.csv\"))\n",
    "        model_filenames = []\n",
    "\n",
    "        for m in model_csv:\n",
    "            model_df = pd.read_csv(m)\n",
    "            model_filenames.append(model_df.sort_values(by='metric')['filename'].iloc[0])\n",
    "    \n",
    "    print (\"### Evaluating Models:\", model_filenames)\n",
    "\n",
    "    df = pd.concat([eval_learned_models(eval_metrics, \n",
    "                                        load_model(mf), \n",
    "                                        extract_model_name(mf), \n",
    "                                        test,\n",
    "                                        test_groups, \n",
    "                                        budget=budget\n",
    "                                       ) for mf in model_filenames],\n",
    "                   axis=0,\n",
    "                   sort=False\n",
    "                  )\n",
    "    \n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_models_under_attack(eval_metrics, models_dir, att_tests, budgets, model_filenames=None):\n",
    "    \n",
    "    eval_att_dfs = []\n",
    "\n",
    "    for b in budgets:\n",
    "        eval_att_dfs.append(\n",
    "            eval_all_models_under_attack_budget(eval_metrics, models_dir, att_tests[b][4], att_tests[b][5], \n",
    "                                                b, model_filenames))\n",
    "        \n",
    "        \n",
    "    eval_att_df = functools.reduce(lambda left,right: pd.merge(left,right,on=['Model', 'Budget']), eval_att_dfs)\n",
    "    eval_att_df = pd.concat(eval_att_dfs, axis=0, sort=False)\n",
    "    eval_att_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return eval_att_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRICS = [eval_log_loss, \n",
    "                eval_binary_err_rate,\n",
    "                eval_specificity,\n",
    "                eval_precision,\n",
    "                eval_recall,\n",
    "                eval_f1,\n",
    "                eval_roc_auc\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"census\"\n",
    "TRAINING_BUDGETS= [30, 60]\n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "adv_models = [\"../out/models/census/adv-boosting_census_B30_T100_S0050_L24_R99.model\",\n",
    "              \"../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model\",\n",
    "              \"../out/models/census/adv-boosting_census_B60_T100_S0050_L24_R96.model\",\n",
    "              \"../out/models/census/adv-boosting_census_B60_T100_S0050_L256_R96.model\"\n",
    "             ]\n",
    "\n",
    "gdbt_models = [\"../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model\",\n",
    "               \"../out/models/census/std-gbdt_census_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "red_models = [\"../out/models/census/red-gbdt_census_T100_S0050_L24_R95.model\",\n",
    "             \"../out/models/census/red-gbdt_census_T100_S0050_L256_R93.model\"]\n",
    "\n",
    "rf_models = [\"../out/models/census/rf-gbdt_census_T100_S0050_L24_R100.model\",\n",
    "             \"../out/models/census/rf-gbdt_census_T100_S0050_L256_R92.model\"]\n",
    "\n",
    "\n",
    "\n",
    "robust_models = [\"../out/models/census/par-robust_census_B0_T100_D8_I20.model\"]\n",
    "\n",
    "test_models =  adv_models + gdbt_models + rf_models + robust_models\n",
    "\n",
    "# REDUCED are not working any more??!?\n",
    "#test_models = red_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%capture tests\n",
    "\n",
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "TRAINING_BUDGETS= [10,20,30] \n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "adv_models = [\"../out/models/wine/adv-boosting_wine_B10_T100_S0050_L24_R100.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B20_T100_S0050_L24_R100.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R95.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B30_T100_S0050_L24_R100.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B30_T100_S0050_L256_R100.model\"\n",
    "              ]\n",
    "\n",
    "gdbt_models = [\"../out/models/wine/std-gbdt_wine_T100_S0050_L24_R100.model\",\n",
    "               \"../out/models/wine/std-gbdt_wine_T100_S0050_L256_R97.model\"]\n",
    "\n",
    "red_models = [\"../out/models/wine/red-gbdt_wine_T100_S0050_L24_R99.model\",\n",
    "             \"../out/models/wine/red-gbdt_wine_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "rf_models = [\"../out/models/wine/rf-gbdt_wine_T100_S0050_L24_R100.model\",\n",
    "             \"../out/models/wine/rf-gbdt_wine_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "robust_models = [\"../out/models/wine/par-robust_wine_B0_T100_D8_I20.model\",\n",
    "                 \"../out/models/wine/par-robust_wine_B10_T100_D8_I20.model\",\n",
    "                \"../out/models/wine/par-robust_wine_B20_T100_D8_I20.model\",\n",
    "                \"../out/models/wine/par-robust_wine_B30_T100_D8_I20.model\"]\n",
    "\n",
    "test_models = adv_models + robust_models \n",
    "#test_models = robust_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed files...\n",
      "### Evaluating Models: ['../out/models/wine/adv-boosting_wine_B10_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R95.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L256_R100.model', '../out/models/wine/par-robust_wine_B0_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B10_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B20_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B30_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.55243\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.22692\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.64570\n",
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.76993\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.77308\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.77061\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.83976\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.53881\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.21769\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.67086\n",
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.77995\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.78231\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.78066\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.85397\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.55282\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.22000\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.65409\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.77698\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.78000\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.77755\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.83858\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.53904\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.20462\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.69811\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.79373\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.79538\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.79432\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.85596\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.55254\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.21846\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.67505\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.77947\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.78154\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.78018\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.83776\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.53633\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.21385\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.67505\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.78381\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.78615\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.78448\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.85738\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=0] learning - eval_log_loss = 0.60006\n",
      "Par-Robust [train budget=0] learning - eval_binary_err_rate = 0.24154\n",
      "Par-Robust [train budget=0] learning - eval_specificity = 0.62055\n",
      "Par-Robust [train budget=0] learning - eval_precision = 0.75469\n",
      "Par-Robust [train budget=0] learning - eval_recall = 0.75846\n",
      "Par-Robust [train budget=0] learning - eval_f1 = 0.75549\n",
      "Par-Robust [train budget=0] learning - eval_roc_auc = 0.82525\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=10] learning - eval_log_loss = 0.59877\n",
      "Par-Robust [train budget=10] learning - eval_binary_err_rate = 0.22923\n",
      "Par-Robust [train budget=10] learning - eval_specificity = 0.63732\n",
      "Par-Robust [train budget=10] learning - eval_precision = 0.76734\n",
      "Par-Robust [train budget=10] learning - eval_recall = 0.77077\n",
      "Par-Robust [train budget=10] learning - eval_f1 = 0.76794\n",
      "Par-Robust [train budget=10] learning - eval_roc_auc = 0.83271\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=20] learning - eval_log_loss = 0.59879\n",
      "Par-Robust [train budget=20] learning - eval_binary_err_rate = 0.24538\n",
      "Par-Robust [train budget=20] learning - eval_specificity = 0.62683\n",
      "Par-Robust [train budget=20] learning - eval_precision = 0.75139\n",
      "Par-Robust [train budget=20] learning - eval_recall = 0.75462\n",
      "Par-Robust [train budget=20] learning - eval_f1 = 0.75236\n",
      "Par-Robust [train budget=20] learning - eval_roc_auc = 0.83043\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=30] learning - eval_log_loss = 0.59926\n",
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.22923\n",
      "Par-Robust [train budget=30] learning - eval_specificity = 0.64151\n",
      "Par-Robust [train budget=30] learning - eval_precision = 0.76752\n",
      "Par-Robust [train budget=30] learning - eval_recall = 0.77077\n",
      "Par-Robust [train budget=30] learning - eval_f1 = 0.76821\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.83076\n",
      "******************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Binary Err Rate</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552425</td>\n",
       "      <td>0.226923</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.769929</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.770610</td>\n",
       "      <td>0.839759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538809</td>\n",
       "      <td>0.217692</td>\n",
       "      <td>0.670860</td>\n",
       "      <td>0.779955</td>\n",
       "      <td>0.782308</td>\n",
       "      <td>0.780664</td>\n",
       "      <td>0.853968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552818</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.776983</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.777545</td>\n",
       "      <td>0.838577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539037</td>\n",
       "      <td>0.204615</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.793731</td>\n",
       "      <td>0.795385</td>\n",
       "      <td>0.794319</td>\n",
       "      <td>0.855960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552537</td>\n",
       "      <td>0.218462</td>\n",
       "      <td>0.675052</td>\n",
       "      <td>0.779469</td>\n",
       "      <td>0.781538</td>\n",
       "      <td>0.780177</td>\n",
       "      <td>0.837762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536333</td>\n",
       "      <td>0.213846</td>\n",
       "      <td>0.675052</td>\n",
       "      <td>0.783812</td>\n",
       "      <td>0.786154</td>\n",
       "      <td>0.784482</td>\n",
       "      <td>0.857376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Par-Robust [train budget=0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600058</td>\n",
       "      <td>0.241538</td>\n",
       "      <td>0.620545</td>\n",
       "      <td>0.754687</td>\n",
       "      <td>0.758462</td>\n",
       "      <td>0.755485</td>\n",
       "      <td>0.825252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Par-Robust [train budget=10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598770</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.637317</td>\n",
       "      <td>0.767345</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.767945</td>\n",
       "      <td>0.832713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Par-Robust [train budget=20]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598793</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>0.626834</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0.752362</td>\n",
       "      <td>0.830426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599261</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.767518</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.830762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model Budget  Log Loss  Binary Err Rate  \\\n",
       "0  Adv-Boosting [train budget=10]      0  0.552425         0.226923   \n",
       "1  Adv-Boosting [train budget=10]      0  0.538809         0.217692   \n",
       "2  Adv-Boosting [train budget=20]      0  0.552818         0.220000   \n",
       "3  Adv-Boosting [train budget=20]      0  0.539037         0.204615   \n",
       "4  Adv-Boosting [train budget=30]      0  0.552537         0.218462   \n",
       "5  Adv-Boosting [train budget=30]      0  0.536333         0.213846   \n",
       "6     Par-Robust [train budget=0]      0  0.600058         0.241538   \n",
       "7    Par-Robust [train budget=10]      0  0.598770         0.229231   \n",
       "8    Par-Robust [train budget=20]      0  0.598793         0.245385   \n",
       "9    Par-Robust [train budget=30]      0  0.599261         0.229231   \n",
       "\n",
       "   Specificity  Precision    Recall        F1   Roc Auc  \n",
       "0     0.645702   0.769929  0.773077  0.770610  0.839759  \n",
       "1     0.670860   0.779955  0.782308  0.780664  0.853968  \n",
       "2     0.654088   0.776983  0.780000  0.777545  0.838577  \n",
       "3     0.698113   0.793731  0.795385  0.794319  0.855960  \n",
       "4     0.675052   0.779469  0.781538  0.780177  0.837762  \n",
       "5     0.675052   0.783812  0.786154  0.784482  0.857376  \n",
       "6     0.620545   0.754687  0.758462  0.755485  0.825252  \n",
       "7     0.637317   0.767345  0.770769  0.767945  0.832713  \n",
       "8     0.626834   0.751386  0.754615  0.752362  0.830426  \n",
       "9     0.641509   0.767518  0.770769  0.768211  0.830762  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed files...\n",
      "Loading pre-processed files...\n",
      "Loading pre-processed files...\n",
      "### Evaluating Models: ['../out/models/wine/adv-boosting_wine_B10_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R95.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L256_R100.model', '../out/models/wine/par-robust_wine_B0_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B10_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B20_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B30_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.56490\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.24077\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.61426\n",
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.75516\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.75923\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.75576\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.81949\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.55053\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.23308\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.64151\n",
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.76383\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.76692\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.76465\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.83756\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.56236\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.23308\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.62893\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.76326\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.76692\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.76384\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.82296\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.54983\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.21538\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.67505\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.78236\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.78462\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.78305\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.83999\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.56227\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.23385\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.63941\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.76299\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.76615\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.76381\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.82221\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.54865\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.22385\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.65199\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.77317\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.77615\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.77385\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.83941\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=0] learning - eval_log_loss = 0.62875\n",
      "Par-Robust [train budget=0] learning - eval_binary_err_rate = 0.34231\n",
      "Par-Robust [train budget=0] learning - eval_specificity = 0.34801\n",
      "Par-Robust [train budget=0] learning - eval_precision = 0.63922\n",
      "Par-Robust [train budget=0] learning - eval_recall = 0.65769\n",
      "Par-Robust [train budget=0] learning - eval_f1 = 0.63532\n",
      "Par-Robust [train budget=0] learning - eval_roc_auc = 0.73022\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=10] learning - eval_log_loss = 0.59885\n",
      "Par-Robust [train budget=10] learning - eval_binary_err_rate = 0.22923\n",
      "Par-Robust [train budget=10] learning - eval_specificity = 0.63732\n",
      "Par-Robust [train budget=10] learning - eval_precision = 0.76734\n",
      "Par-Robust [train budget=10] learning - eval_recall = 0.77077\n",
      "Par-Robust [train budget=10] learning - eval_f1 = 0.76794\n",
      "Par-Robust [train budget=10] learning - eval_roc_auc = 0.83218\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=20] learning - eval_log_loss = 0.59882\n",
      "Par-Robust [train budget=20] learning - eval_binary_err_rate = 0.24538\n",
      "Par-Robust [train budget=20] learning - eval_specificity = 0.62683\n",
      "Par-Robust [train budget=20] learning - eval_precision = 0.75139\n",
      "Par-Robust [train budget=20] learning - eval_recall = 0.75462\n",
      "Par-Robust [train budget=20] learning - eval_f1 = 0.75236\n",
      "Par-Robust [train budget=20] learning - eval_roc_auc = 0.83020\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=30] learning - eval_log_loss = 0.59928\n",
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.22923\n",
      "Par-Robust [train budget=30] learning - eval_specificity = 0.64151\n",
      "Par-Robust [train budget=30] learning - eval_precision = 0.76752\n",
      "Par-Robust [train budget=30] learning - eval_recall = 0.77077\n",
      "Par-Robust [train budget=30] learning - eval_f1 = 0.76821\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.83068\n",
      "******************************************************************************************************\n",
      "### Evaluating Models: ['../out/models/wine/adv-boosting_wine_B10_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R95.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L256_R100.model', '../out/models/wine/par-robust_wine_B0_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B10_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B20_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B30_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.57453\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.25538\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.58281\n",
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.73955\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.74462\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.74005\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.80404\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.55941\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.24231\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.62055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.75395\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.75769\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.75478\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.82508\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.56876\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.24154\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.61006\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.75425\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.75846\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.75475\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.81181\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.55643\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.22615\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.64990\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.77086\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.77385\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.77158\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.83055\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.56799\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.24000\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.63103\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.75670\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.76000\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.75760\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.81277\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.55609\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.23308\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.62893\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.76326\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.76692\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.76384\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.82844\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=0] learning - eval_log_loss = 0.64983\n",
      "Par-Robust [train budget=0] learning - eval_binary_err_rate = 0.42000\n",
      "Par-Robust [train budget=0] learning - eval_specificity = 0.15094\n",
      "Par-Robust [train budget=0] learning - eval_precision = 0.52123\n",
      "Par-Robust [train budget=0] learning - eval_recall = 0.58000\n",
      "Par-Robust [train budget=0] learning - eval_f1 = 0.52868\n",
      "Par-Robust [train budget=0] learning - eval_roc_auc = 0.64111\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=10] learning - eval_log_loss = 0.59901\n",
      "Par-Robust [train budget=10] learning - eval_binary_err_rate = 0.23000\n",
      "Par-Robust [train budget=10] learning - eval_specificity = 0.63522\n",
      "Par-Robust [train budget=10] learning - eval_precision = 0.76651\n",
      "Par-Robust [train budget=10] learning - eval_recall = 0.77000\n",
      "Par-Robust [train budget=10] learning - eval_f1 = 0.76710\n",
      "Par-Robust [train budget=10] learning - eval_roc_auc = 0.83155\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=20] learning - eval_log_loss = 0.59885\n",
      "Par-Robust [train budget=20] learning - eval_binary_err_rate = 0.24538\n",
      "Par-Robust [train budget=20] learning - eval_specificity = 0.62683\n",
      "Par-Robust [train budget=20] learning - eval_precision = 0.75139\n",
      "Par-Robust [train budget=20] learning - eval_recall = 0.75462\n",
      "Par-Robust [train budget=20] learning - eval_f1 = 0.75236\n",
      "Par-Robust [train budget=20] learning - eval_roc_auc = 0.83011\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=30] learning - eval_log_loss = 0.59928\n",
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.22923\n",
      "Par-Robust [train budget=30] learning - eval_specificity = 0.64151\n",
      "Par-Robust [train budget=30] learning - eval_precision = 0.76752\n",
      "Par-Robust [train budget=30] learning - eval_recall = 0.77077\n",
      "Par-Robust [train budget=30] learning - eval_f1 = 0.76821\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.83067\n",
      "******************************************************************************************************\n",
      "### Evaluating Models: ['../out/models/wine/adv-boosting_wine_B10_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R95.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L24_R100.model', '../out/models/wine/adv-boosting_wine_B30_T100_S0050_L256_R100.model', '../out/models/wine/par-robust_wine_B0_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B10_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B20_T100_D8_I20.model', '../out/models/wine/par-robust_wine_B30_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.57719\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.25692\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.57862\n",
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.73787\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.74308\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.73831\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.79938\n",
      "******************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "Adv-Boosting [train budget=10] learning - eval_log_loss = 0.56222\n",
      "Adv-Boosting [train budget=10] learning - eval_binary_err_rate = 0.24308\n",
      "Adv-Boosting [train budget=10] learning - eval_specificity = 0.61845\n",
      "Adv-Boosting [train budget=10] learning - eval_precision = 0.75311\n",
      "Adv-Boosting [train budget=10] learning - eval_recall = 0.75692\n",
      "Adv-Boosting [train budget=10] learning - eval_f1 = 0.75393\n",
      "Adv-Boosting [train budget=10] learning - eval_roc_auc = 0.82088\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.57166\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.24462\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.60377\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.75099\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.75538\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.75148\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.80719\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=20] learning - eval_log_loss = 0.55925\n",
      "Adv-Boosting [train budget=20] learning - eval_binary_err_rate = 0.22846\n",
      "Adv-Boosting [train budget=20] learning - eval_specificity = 0.64361\n",
      "Adv-Boosting [train budget=20] learning - eval_precision = 0.76835\n",
      "Adv-Boosting [train budget=20] learning - eval_recall = 0.77154\n",
      "Adv-Boosting [train budget=20] learning - eval_f1 = 0.76905\n",
      "Adv-Boosting [train budget=20] learning - eval_roc_auc = 0.82650\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.56971\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.24154\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.62893\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.75513\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.75846\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.75604\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.81007\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_log_loss = 0.55813\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.23538\n",
      "Adv-Boosting [train budget=30] learning - eval_specificity = 0.62474\n",
      "Adv-Boosting [train budget=30] learning - eval_precision = 0.76085\n",
      "Adv-Boosting [train budget=30] learning - eval_recall = 0.76462\n",
      "Adv-Boosting [train budget=30] learning - eval_f1 = 0.76143\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.82566\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=0] learning - eval_log_loss = 0.65284\n",
      "Par-Robust [train budget=0] learning - eval_binary_err_rate = 0.43385\n",
      "Par-Robust [train budget=0] learning - eval_specificity = 0.11321\n",
      "Par-Robust [train budget=0] learning - eval_precision = 0.49234\n",
      "Par-Robust [train budget=0] learning - eval_recall = 0.56615\n",
      "Par-Robust [train budget=0] learning - eval_f1 = 0.50685\n",
      "Par-Robust [train budget=0] learning - eval_roc_auc = 0.62696\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=10] learning - eval_log_loss = 0.59914\n",
      "Par-Robust [train budget=10] learning - eval_binary_err_rate = 0.23000\n",
      "Par-Robust [train budget=10] learning - eval_specificity = 0.63522\n",
      "Par-Robust [train budget=10] learning - eval_precision = 0.76651\n",
      "Par-Robust [train budget=10] learning - eval_recall = 0.77000\n",
      "Par-Robust [train budget=10] learning - eval_f1 = 0.76710\n",
      "Par-Robust [train budget=10] learning - eval_roc_auc = 0.83106\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=20] learning - eval_log_loss = 0.59888\n",
      "Par-Robust [train budget=20] learning - eval_binary_err_rate = 0.24538\n",
      "Par-Robust [train budget=20] learning - eval_specificity = 0.62683\n",
      "Par-Robust [train budget=20] learning - eval_precision = 0.75139\n",
      "Par-Robust [train budget=20] learning - eval_recall = 0.75462\n",
      "Par-Robust [train budget=20] learning - eval_f1 = 0.75236\n",
      "Par-Robust [train budget=20] learning - eval_roc_auc = 0.83001\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BAGGING\n",
      "Par-Robust [train budget=30] learning - eval_log_loss = 0.59928\n",
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.22923\n",
      "Par-Robust [train budget=30] learning - eval_specificity = 0.64151\n",
      "Par-Robust [train budget=30] learning - eval_precision = 0.76752\n",
      "Par-Robust [train budget=30] learning - eval_recall = 0.77077\n",
      "Par-Robust [train budget=30] learning - eval_f1 = 0.76821\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.83064\n",
      "******************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Binary Err Rate</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552425</td>\n",
       "      <td>0.226923</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.769929</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.770610</td>\n",
       "      <td>0.839759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538809</td>\n",
       "      <td>0.217692</td>\n",
       "      <td>0.670860</td>\n",
       "      <td>0.779955</td>\n",
       "      <td>0.782308</td>\n",
       "      <td>0.780664</td>\n",
       "      <td>0.853968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552818</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.776983</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.777545</td>\n",
       "      <td>0.838577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539037</td>\n",
       "      <td>0.204615</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.793731</td>\n",
       "      <td>0.795385</td>\n",
       "      <td>0.794319</td>\n",
       "      <td>0.855960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552537</td>\n",
       "      <td>0.218462</td>\n",
       "      <td>0.675052</td>\n",
       "      <td>0.779469</td>\n",
       "      <td>0.781538</td>\n",
       "      <td>0.780177</td>\n",
       "      <td>0.837762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536333</td>\n",
       "      <td>0.213846</td>\n",
       "      <td>0.675052</td>\n",
       "      <td>0.783812</td>\n",
       "      <td>0.786154</td>\n",
       "      <td>0.784482</td>\n",
       "      <td>0.857376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Par-Robust [train budget=0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600058</td>\n",
       "      <td>0.241538</td>\n",
       "      <td>0.620545</td>\n",
       "      <td>0.754687</td>\n",
       "      <td>0.758462</td>\n",
       "      <td>0.755485</td>\n",
       "      <td>0.825252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Par-Robust [train budget=10]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598770</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.637317</td>\n",
       "      <td>0.767345</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.767945</td>\n",
       "      <td>0.832713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Par-Robust [train budget=20]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598793</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>0.626834</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0.752362</td>\n",
       "      <td>0.830426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599261</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.767518</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.830762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.564899</td>\n",
       "      <td>0.240769</td>\n",
       "      <td>0.614256</td>\n",
       "      <td>0.755164</td>\n",
       "      <td>0.759231</td>\n",
       "      <td>0.755758</td>\n",
       "      <td>0.819493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.550530</td>\n",
       "      <td>0.233077</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.763833</td>\n",
       "      <td>0.766923</td>\n",
       "      <td>0.764653</td>\n",
       "      <td>0.837555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.562361</td>\n",
       "      <td>0.233077</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.763265</td>\n",
       "      <td>0.766923</td>\n",
       "      <td>0.763844</td>\n",
       "      <td>0.822965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.549829</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.675052</td>\n",
       "      <td>0.782355</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.783047</td>\n",
       "      <td>0.839993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.562268</td>\n",
       "      <td>0.233846</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>0.762992</td>\n",
       "      <td>0.766154</td>\n",
       "      <td>0.763811</td>\n",
       "      <td>0.822211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.548645</td>\n",
       "      <td>0.223846</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.773171</td>\n",
       "      <td>0.776154</td>\n",
       "      <td>0.773848</td>\n",
       "      <td>0.839407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Par-Robust [train budget=0]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.628754</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.348008</td>\n",
       "      <td>0.639221</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.635321</td>\n",
       "      <td>0.730217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Par-Robust [train budget=10]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.598848</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.637317</td>\n",
       "      <td>0.767345</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.767945</td>\n",
       "      <td>0.832181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Par-Robust [train budget=20]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.598824</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>0.626834</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0.752362</td>\n",
       "      <td>0.830201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.599277</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.767518</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.830678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.574530</td>\n",
       "      <td>0.255385</td>\n",
       "      <td>0.582809</td>\n",
       "      <td>0.739551</td>\n",
       "      <td>0.744615</td>\n",
       "      <td>0.740047</td>\n",
       "      <td>0.804035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.559410</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.620545</td>\n",
       "      <td>0.753947</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.754778</td>\n",
       "      <td>0.825076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.568760</td>\n",
       "      <td>0.241538</td>\n",
       "      <td>0.610063</td>\n",
       "      <td>0.754251</td>\n",
       "      <td>0.758462</td>\n",
       "      <td>0.754755</td>\n",
       "      <td>0.811807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.556426</td>\n",
       "      <td>0.226154</td>\n",
       "      <td>0.649895</td>\n",
       "      <td>0.770858</td>\n",
       "      <td>0.773846</td>\n",
       "      <td>0.771580</td>\n",
       "      <td>0.830553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.631027</td>\n",
       "      <td>0.756699</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.757595</td>\n",
       "      <td>0.812768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.556089</td>\n",
       "      <td>0.233077</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.763265</td>\n",
       "      <td>0.766923</td>\n",
       "      <td>0.763844</td>\n",
       "      <td>0.828436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Par-Robust [train budget=0]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.649829</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>0.521232</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.528678</td>\n",
       "      <td>0.641115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Par-Robust [train budget=10]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.599006</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.766513</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.767098</td>\n",
       "      <td>0.831554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Par-Robust [train budget=20]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.598848</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>0.626834</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0.752362</td>\n",
       "      <td>0.830107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.599281</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.767518</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.830665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.577189</td>\n",
       "      <td>0.256923</td>\n",
       "      <td>0.578616</td>\n",
       "      <td>0.737867</td>\n",
       "      <td>0.743077</td>\n",
       "      <td>0.738314</td>\n",
       "      <td>0.799382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Adv-Boosting [train budget=10]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.562225</td>\n",
       "      <td>0.243077</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.753105</td>\n",
       "      <td>0.756923</td>\n",
       "      <td>0.753928</td>\n",
       "      <td>0.820881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.571663</td>\n",
       "      <td>0.244615</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.750986</td>\n",
       "      <td>0.755385</td>\n",
       "      <td>0.751478</td>\n",
       "      <td>0.807189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Adv-Boosting [train budget=20]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.559248</td>\n",
       "      <td>0.228462</td>\n",
       "      <td>0.643606</td>\n",
       "      <td>0.768352</td>\n",
       "      <td>0.771538</td>\n",
       "      <td>0.769055</td>\n",
       "      <td>0.826503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.569712</td>\n",
       "      <td>0.241538</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.755126</td>\n",
       "      <td>0.758462</td>\n",
       "      <td>0.756041</td>\n",
       "      <td>0.810073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.558130</td>\n",
       "      <td>0.235385</td>\n",
       "      <td>0.624738</td>\n",
       "      <td>0.760845</td>\n",
       "      <td>0.764615</td>\n",
       "      <td>0.761435</td>\n",
       "      <td>0.825665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Par-Robust [train budget=0]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.652836</td>\n",
       "      <td>0.433846</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.492341</td>\n",
       "      <td>0.566154</td>\n",
       "      <td>0.506852</td>\n",
       "      <td>0.626962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Par-Robust [train budget=10]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.599142</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.766513</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.767098</td>\n",
       "      <td>0.831057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Par-Robust [train budget=20]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.598881</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>0.626834</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0.752362</td>\n",
       "      <td>0.830005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.599284</td>\n",
       "      <td>0.229231</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.767518</td>\n",
       "      <td>0.770769</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.830642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model Budget  Log Loss  Binary Err Rate  \\\n",
       "0   Adv-Boosting [train budget=10]      0  0.552425         0.226923   \n",
       "1   Adv-Boosting [train budget=10]      0  0.538809         0.217692   \n",
       "2   Adv-Boosting [train budget=20]      0  0.552818         0.220000   \n",
       "3   Adv-Boosting [train budget=20]      0  0.539037         0.204615   \n",
       "4   Adv-Boosting [train budget=30]      0  0.552537         0.218462   \n",
       "5   Adv-Boosting [train budget=30]      0  0.536333         0.213846   \n",
       "6      Par-Robust [train budget=0]      0  0.600058         0.241538   \n",
       "7     Par-Robust [train budget=10]      0  0.598770         0.229231   \n",
       "8     Par-Robust [train budget=20]      0  0.598793         0.245385   \n",
       "9     Par-Robust [train budget=30]      0  0.599261         0.229231   \n",
       "10  Adv-Boosting [train budget=10]     10  0.564899         0.240769   \n",
       "11  Adv-Boosting [train budget=10]     10  0.550530         0.233077   \n",
       "12  Adv-Boosting [train budget=20]     10  0.562361         0.233077   \n",
       "13  Adv-Boosting [train budget=20]     10  0.549829         0.215385   \n",
       "14  Adv-Boosting [train budget=30]     10  0.562268         0.233846   \n",
       "15  Adv-Boosting [train budget=30]     10  0.548645         0.223846   \n",
       "16     Par-Robust [train budget=0]     10  0.628754         0.342308   \n",
       "17    Par-Robust [train budget=10]     10  0.598848         0.229231   \n",
       "18    Par-Robust [train budget=20]     10  0.598824         0.245385   \n",
       "19    Par-Robust [train budget=30]     10  0.599277         0.229231   \n",
       "20  Adv-Boosting [train budget=10]     20  0.574530         0.255385   \n",
       "21  Adv-Boosting [train budget=10]     20  0.559410         0.242308   \n",
       "22  Adv-Boosting [train budget=20]     20  0.568760         0.241538   \n",
       "23  Adv-Boosting [train budget=20]     20  0.556426         0.226154   \n",
       "24  Adv-Boosting [train budget=30]     20  0.567993         0.240000   \n",
       "25  Adv-Boosting [train budget=30]     20  0.556089         0.233077   \n",
       "26     Par-Robust [train budget=0]     20  0.649829         0.420000   \n",
       "27    Par-Robust [train budget=10]     20  0.599006         0.230000   \n",
       "28    Par-Robust [train budget=20]     20  0.598848         0.245385   \n",
       "29    Par-Robust [train budget=30]     20  0.599281         0.229231   \n",
       "30  Adv-Boosting [train budget=10]     30  0.577189         0.256923   \n",
       "31  Adv-Boosting [train budget=10]     30  0.562225         0.243077   \n",
       "32  Adv-Boosting [train budget=20]     30  0.571663         0.244615   \n",
       "33  Adv-Boosting [train budget=20]     30  0.559248         0.228462   \n",
       "34  Adv-Boosting [train budget=30]     30  0.569712         0.241538   \n",
       "35  Adv-Boosting [train budget=30]     30  0.558130         0.235385   \n",
       "36     Par-Robust [train budget=0]     30  0.652836         0.433846   \n",
       "37    Par-Robust [train budget=10]     30  0.599142         0.230000   \n",
       "38    Par-Robust [train budget=20]     30  0.598881         0.245385   \n",
       "39    Par-Robust [train budget=30]     30  0.599284         0.229231   \n",
       "\n",
       "    Specificity  Precision    Recall        F1   Roc Auc  \n",
       "0      0.645702   0.769929  0.773077  0.770610  0.839759  \n",
       "1      0.670860   0.779955  0.782308  0.780664  0.853968  \n",
       "2      0.654088   0.776983  0.780000  0.777545  0.838577  \n",
       "3      0.698113   0.793731  0.795385  0.794319  0.855960  \n",
       "4      0.675052   0.779469  0.781538  0.780177  0.837762  \n",
       "5      0.675052   0.783812  0.786154  0.784482  0.857376  \n",
       "6      0.620545   0.754687  0.758462  0.755485  0.825252  \n",
       "7      0.637317   0.767345  0.770769  0.767945  0.832713  \n",
       "8      0.626834   0.751386  0.754615  0.752362  0.830426  \n",
       "9      0.641509   0.767518  0.770769  0.768211  0.830762  \n",
       "10     0.614256   0.755164  0.759231  0.755758  0.819493  \n",
       "11     0.641509   0.763833  0.766923  0.764653  0.837555  \n",
       "12     0.628931   0.763265  0.766923  0.763844  0.822965  \n",
       "13     0.675052   0.782355  0.784615  0.783047  0.839993  \n",
       "14     0.639413   0.762992  0.766154  0.763811  0.822211  \n",
       "15     0.651992   0.773171  0.776154  0.773848  0.839407  \n",
       "16     0.348008   0.639221  0.657692  0.635321  0.730217  \n",
       "17     0.637317   0.767345  0.770769  0.767945  0.832181  \n",
       "18     0.626834   0.751386  0.754615  0.752362  0.830201  \n",
       "19     0.641509   0.767518  0.770769  0.768211  0.830678  \n",
       "20     0.582809   0.739551  0.744615  0.740047  0.804035  \n",
       "21     0.620545   0.753947  0.757692  0.754778  0.825076  \n",
       "22     0.610063   0.754251  0.758462  0.754755  0.811807  \n",
       "23     0.649895   0.770858  0.773846  0.771580  0.830553  \n",
       "24     0.631027   0.756699  0.760000  0.757595  0.812768  \n",
       "25     0.628931   0.763265  0.766923  0.763844  0.828436  \n",
       "26     0.150943   0.521232  0.580000  0.528678  0.641115  \n",
       "27     0.635220   0.766513  0.770000  0.767098  0.831554  \n",
       "28     0.626834   0.751386  0.754615  0.752362  0.830107  \n",
       "29     0.641509   0.767518  0.770769  0.768211  0.830665  \n",
       "30     0.578616   0.737867  0.743077  0.738314  0.799382  \n",
       "31     0.618449   0.753105  0.756923  0.753928  0.820881  \n",
       "32     0.603774   0.750986  0.755385  0.751478  0.807189  \n",
       "33     0.643606   0.768352  0.771538  0.769055  0.826503  \n",
       "34     0.628931   0.755126  0.758462  0.756041  0.810073  \n",
       "35     0.624738   0.760845  0.764615  0.761435  0.825665  \n",
       "36     0.113208   0.492341  0.566154  0.506852  0.626962  \n",
       "37     0.635220   0.766513  0.770000  0.767098  0.831057  \n",
       "38     0.626834   0.751386  0.754615  0.752362  0.830005  \n",
       "39     0.641509   0.767518  0.770769  0.768211  0.830642  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'overall_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c85fabf40290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moverall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moverall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=10'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'overall_df' is not defined"
     ]
    }
   ],
   "source": [
    "overall_df[overall_df['Model'].str.contains('=10')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPETITORS\n",
    "\n",
    "Model\tBudget\tLog Loss\tBinary Err Rate\tSpecificity\tPrecision\tRecall\tF1\tRoc Auc\n",
    "0\tAdv-Boosting [train budget=30]\t0\t0.552537\t0.218462\t0.675052\t0.779469\t0.781538\t0.780177\t0.837762\n",
    "1\tAdv-Boosting [train budget=30]\t0\t0.536333\t0.213846\t0.675052\t0.783812\t0.786154\t0.784482\t0.857376\n",
    "2\tAdv-Boosting [train budget=60]\t0\t0.557392\t0.229231\t0.654088\t0.768163\t0.770769\t0.768977\t0.834622\n",
    "3\tAdv-Boosting [train budget=60]\t0\t0.540496\t0.218462\t0.683438\t0.780012\t0.781538\t0.780619\t0.851586\n",
    "4\tStd-Gbdt\t0\t0.551204\t0.232308\t0.631027\t0.764097\t0.767692\t0.764692\t0.839458\n",
    "5\tStd-Gbdt\t0\t0.540879\t0.222308\t0.658281\t0.774936\t0.777692\t0.775651\t0.851046\n",
    "6\tRed-Gbdt\t0\t0.720991\t0.624615\t0.849057\t0.468787\t0.375385\t0.290690\t0.398885\n",
    "7\tRed-Gbdt\t0\t0.701899\t0.450000\t0.419287\t0.556118\t0.550000\t0.552762\t0.481782\n",
    "8\tRf-Gbdt\t0\t0.576459\t0.239231\t0.597484\t0.756262\t0.760769\t0.755938\t0.817466\n",
    "9\tRf-Gbdt\t0\t0.565125\t0.236923\t0.607966\t0.758810\t0.763077\t0.758839\t0.834560\n",
    "10\tAdv-Boosting [train budget=30]\t30\t0.569712\t0.241538\t0.628931\t0.755126\t0.758462\t0.756041\t0.810073\n",
    "11\tAdv-Boosting [train budget=30]\t30\t0.558130\t0.235385\t0.624738\t0.760845\t0.764615\t0.761435\t0.825665\n",
    "12\tAdv-Boosting [train budget=60]\t30\t0.576883\t0.256923\t0.601677\t0.738991\t0.743077\t0.740061\t0.801165\n",
    "13\tAdv-Boosting [train budget=60]\t30\t0.565061\t0.250769\t0.622642\t0.746104\t0.749231\t0.747135\t0.814220\n",
    "14\tStd-Gbdt\t30\t0.626599\t0.387692\t0.224319\t0.574796\t0.612308\t0.572900\t0.695082\n",
    "15\tStd-Gbdt\t30\t0.632325\t0.397692\t0.224319\t0.563710\t0.602308\t0.565373\t0.674240\n",
    "16\tRed-Gbdt\t30\t0.727191\t0.633077\t0.849057\t0.445089\t0.366923\t0.276275\t0.349323\n",
    "17\tRed-Gbdt\t30\t0.713142\t0.498462\t0.299790\t0.497063\t0.501538\t0.499194\t0.407729\n",
    "18\tRf-Gbdt\t30\t0.633231\t0.404615\t0.148847\t0.537706\t0.595385\t0.538716\t0.684260\n",
    "19\tRf-Gbdt\t30\t0.626627\t0.395385\t0.186583\t0.558575\t0.604615\t0.556913\t0.696457\n",
    "20\tAdv-Boosting [train budget=30]\t60\t0.571455\t0.242308\t0.626834\t0.754280\t0.757692\t0.755196\t0.807250\n",
    "21\tAdv-Boosting [train budget=30]\t60\t0.560589\t0.238462\t0.620545\t0.757672\t0.761538\t0.758316\t0.821925\n",
    "22\tAdv-Boosting [train budget=60]\t60\t0.579503\t0.259231\t0.595388\t0.736430\t0.740769\t0.737498\t0.796106\n",
    "23\tAdv-Boosting [train budget=60]\t60\t0.567124\t0.251538\t0.620545\t0.745248\t0.748462\t0.746290\t0.810939\n",
    "24\tStd-Gbdt\t60\t0.628858\t0.387692\t0.224319\t0.574796\t0.612308\t0.572900\t0.688013\n",
    "25\tStd-Gbdt\t60\t0.634201\t0.399231\t0.222222\t0.561660\t0.600769\t0.563691\t0.668282\n",
    "26\tRed-Gbdt\t60\t0.728780\t0.633077\t0.849057\t0.445089\t0.366923\t0.276275\t0.335776\n",
    "27\tRed-Gbdt\t60\t0.716420\t0.525385\t0.241090\t0.464610\t0.474615\t0.469203\t0.378909\n",
    "28\tRf-Gbdt\t60\t0.635470\t0.412308\t0.134172\t0.523740\t0.587692\t0.528536\t0.677227\n",
    "29\tRf-Gbdt\t60\t0.629036\t0.405385\t0.167715\t0.542278\t0.594615\t0.544130\t0.688354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"spam\"\n",
    "TRAINING_BUDGETS= [30, 60] \n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "adv_models = [\"../out/models/wine/adv-boosting_wine_B30_T100_S0050_L24_R100.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B30_T100_S0050_L256_R100.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B60_T100_S0050_L24_R82.model\",\n",
    "              \"../out/models/wine/adv-boosting_wine_B60_T100_S0050_L256_R85.model\"\n",
    "             ]\n",
    "\n",
    "gdbt_models = [\"../out/models/spam/std-gbdt_spam_T100_S0050_L24_R100.model\",\n",
    "               \"../out/models/spam/std-gbdt_spam_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "red_models = [\"../out/models/spam/red-gbdt_spam_T100_S0050_L24_R100.model\",\n",
    "             \"../out/models/spam/red-gbdt_spam_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "rf_models = [\"../out/models/spam/rf-gbdt_spam_T100_S0050_L24_R98.model\",\n",
    "             \"../out/models/spam/rf-gbdt_spam_T100_S0050_L256_R98.model\"]\n",
    "\n",
    "robust_models = [\"../out/models/wine/par-robust_wine_B0_T100_D8_I20.model\",\n",
    "                \"../out/models/wine/par-robust_wine_B60_T100_D8_I20.model\",\n",
    "                \"../out/models/wine/par-robust_wine_B30_T100_D8_I20.model\"]\n",
    "\n",
    "test_models = gdbt_models + red_models + rf_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune Robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_pruned_models = [\"../out/models/census/robust_census_B0_T100_D8_I20_20.tmp\"]\n",
    "\n",
    "for m in to_be_pruned_models:\n",
    "    prune_trained_model(m, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune LGBM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_lgbm(in_file, out_file, n):\n",
    "    model = lightgbm.Booster(model_file=in_file)\n",
    "    model.save_model(out_file, num_iteration=n)\n",
    "    print (\"saved.\")\n",
    "    \n",
    "prune_lgbm(\"../out/models/wine/std-gbdt_wine_T200_S0050_L24_R199.model\",\n",
    "           \"../out/models/wine/std-gbdt_wine_T200_S0050_L24_R199.T10.model\",\n",
    "           10)\n",
    "# prune_lgbm(\"../out/models/census/adv-boosting_census_B60_T200_S0050_L24_R200.model\",\n",
    "#            \"../out/models/census/adv-boosting_census_B60_T200_S0050_L24_R200.T20.model\",\n",
    "#            20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../out/models/wine/par-robust_wine_B0_T100_D8_I20.model\", 'rb') as f:\n",
    "    model = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pretty_print(node, out=sys.stdout, tabs=''):\n",
    "\n",
    "    leaf_txt = \"{}Prediction: {}; Score: {:.5f}; N. instances: {}; Loss: {:.5f}\".format(tabs,\n",
    "                                                                                        node.get_node_prediction()[\n",
    "                                                                                            0],\n",
    "                                                                                        node.get_node_prediction()[\n",
    "                                                                                            1],\n",
    "                                                                                        node.values,\n",
    "                                                                                        node.loss_value)\n",
    "    internal_node_txt = \"{}Feature ID: {}; Threshold: {}; N. instances: {}\".format(tabs,\n",
    "                                                                                   node.best_split_feature_id,\n",
    "                                                                                   node.best_split_feature_value,\n",
    "                                                                                   node.values\n",
    "                                                                                   )\n",
    "\n",
    "    if node.is_leaf():  # base case\n",
    "        out.write(leaf_txt + \"\\n\")\n",
    "    else:  # recursive case\n",
    "        out.write(internal_node_txt + \"\\n\")\n",
    "        node.left.pretty_print(out, tabs + \"\\t\")\n",
    "        node.right.pretty_print(out, tabs + \"\\t\")\n",
    "\n",
    "pretty_print(model.estimators_[0].root )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(model.estimators_[1].root )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fx_imp(model, colnames):\n",
    "    fx_uses = model.feature_importance(importance_type='split')\n",
    "    fx_gain = model.feature_importance(importance_type='gain')\n",
    "\n",
    "    for i,f in enumerate(np.argsort(fx_gain)[::-1]):\n",
    "        print (\"{:2d} {:20s} {:.3f} {:4d}\".format(i, colnames[f], fx_gain[f], fx_uses[f]))\n",
    "\n",
    "print(\" -- GDBT --\")    \n",
    "gbdt = lightgbm.Booster(model_file=\"../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model\")\n",
    "print(gbdt.num_trees())\n",
    "print_fx_imp(gbdt, TRAIN.columns)\n",
    "\n",
    "print(\" -- Reduced GDBT --\")    \n",
    "redf = lightgbm.Booster(model_file=\"../out/models/census/red-gbdt_census_T100_S0050_L24_R98.model\")\n",
    "print(redf.num_trees())\n",
    "print_fx_imp(redf, TRAIN.drop(columns=[\"workclass\", \n",
    "                                       \"marital_status\", \n",
    "                                       \"occupation\", \n",
    "                                       \"education_num\", \n",
    "                                       \"hours_per_week\", \n",
    "                                       \"capital_gain\"\n",
    "                                      ]).columns)\n",
    "\n",
    "\n",
    "print(\" -- Adv. Boosting --\")    \n",
    "advb = lightgbm.Booster(model_file=\"../out/models/census/adv-boosting_census_B30_T100_S0050_L24_R100.model\")\n",
    "print(advb.num_trees())\n",
    "print_fx_imp(advb, TRAIN.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = 40\n",
    "eval_learned_models(lightgbm.Booster(model_file=\"../out/models/wine2/red-gbdt_wine2_T500_S0050_L24_R281.model\"), \n",
    "                                        extract_model_name(\"../out/models/wine2/red-gbdt_wine2_T500_S0050_L24_R281.model\"), \n",
    "                                        att_datasets[bb][4].drop(columns=[\"alcohol\", \"residual_sugar\", \"volatile_acidity\"]), \n",
    "                                        att_datasets[bb][5], \n",
    "                                        budget=bb\n",
    "                                       ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../out/models/census/par-robust_census_B0_T100_D8_I20.model | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git commit -am \"calza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
