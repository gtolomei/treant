{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models\n",
    "\n",
    "This notebook contains the code used for evaluating the following learning models:\n",
    "\n",
    "-  **Standard GBDT** (_baseline 1_)\n",
    "-  **Adversarial Boosting** (_baseline 2_)\n",
    "-  **Non-Interferent GBDT** (our proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm\n",
    "import functools\n",
    "import parallel_robust_forest\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, precision_score, recall_score\n",
    "from nilib import *\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard evaluation metric\n",
    "\n",
    "The following function is the one used for evaluating the quality of the learned model (either _standard_, _adversarial-boosting_, or _non-interferent_). This is the standard <code>avg_log_loss</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    return np.log(p/(1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(preds):\n",
    "    if np.min(preds)<-0.001:\n",
    "        return np.where(preds>=0,  1.0, -1.0)\n",
    "    else:\n",
    "        return np.where(preds>=.5, 1.0, -1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss(preds, train_data):\n",
    "    \n",
    "    labels = train_data.get_label()\n",
    "    losses = np.log(1.0 + np.exp(-preds*labels))\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    return 'avg_binary_log_loss', avg_loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_log_loss(y_true, y_pred):\n",
    "    losses = np.log(1.0 + np.exp(-y_pred*y_true))\n",
    "    avg_loss = np.mean(losses)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom evaluation metric\n",
    "\n",
    "Similarly to what we have done for <code>fobj</code>, <code>feval</code> can be computed from a weighted combination of two evaluation metrics:\n",
    "\n",
    "-  <code>avg_log_loss</code> (standard, defined above);\n",
    "-  <code>avg_log_loss_uma</code> (custom, defined below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss_uma</code>\n",
    "\n",
    "This is the binary log loss yet modified to operate on groups of perturbed instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom metric\n",
    "\n",
    "def binary_log_loss(pred, true_label):\n",
    "\n",
    "    return np.log(1.0 + np.exp(-pred * true_label))\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss_uma(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    attack_lens = train_data.get_group()\n",
    "    \n",
    "    offset = 0\n",
    "    max_logloss = []\n",
    "    avg_max_logloss = 0.0\n",
    "    \n",
    "    if attack_lens is not None:\n",
    "    \n",
    "        for atk in attack_lens:\n",
    "            losses = [binary_log_loss(h,t) for h,t in zip(preds[offset:offset+atk], labels[offset:offset+atk])]\n",
    "            max_logloss.append(max(losses))\n",
    "            \n",
    "            offset += atk\n",
    "        \n",
    "        avg_max_logloss = np.mean(max_logloss)  \n",
    "        \n",
    "    return 'avg_binary_log_loss_under_max_attack', avg_max_logloss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_log_loss_uma(preds, test, test_groups=None, svm=False):\n",
    "    \n",
    "    lgbm_test = lightgbm.Dataset(data=test.iloc[:,:-1].values, \n",
    "                                 label=test.iloc[:,-1].values,\n",
    "                                 group=test_groups,\n",
    "                                 free_raw_data=False)\n",
    "    \n",
    "    return avg_log_loss_uma(preds,lgbm_test)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_binary_err_rate</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_binary_err_rate(y_true, y_pred):\n",
    "    errs = np.sum(binarize(y_pred) != y_true)\n",
    "    return errs/len(y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_roc_auc</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_roc_auc(y_true, y_pred):\n",
    "    return roc_auc_score(y_true=y_true, y_score=y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_specificity</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_specificity(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=y_true, y_pred=y_pred).ravel()\n",
    "\n",
    "    return tn/(tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_precision</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_precision(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    return precision_score(y_true=y_true, y_pred=y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_recall</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_recall(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    return recall_score(y_true=y_true, y_pred=y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_f1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_f1_micro(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    return f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "def eval_f1_macro(y_true, y_pred):\n",
    "    y_pred = binarize(y_pred)\n",
    "    return f1_score(y_true=y_true, y_pred=y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate each model w.r.t. _all_ evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def model_predict(model,test_set):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "\n",
    "    if isinstance(model, sklearn.ensemble.BaggingClassifier):\n",
    "        print (\"BaggingClassifier\")\n",
    "#         print ( np.min( model.predict_proba(X)[:,0] ), np.max( model.predict_proba(X)[:,0] ) )\n",
    "#         print ( np.min( model.predict_proba(X)[:,1] ), np.max( model.predict_proba(X)[:,1] ) )\n",
    "        return model.predict_proba(X)[:,1]\n",
    "        # return model.predict(X)\n",
    "    else:\n",
    "        print (\"LightGBM\")\n",
    "#        print (np.unique( model.predict(X) ) )\n",
    "#         lgbm_X = lightgbm.Dataset(data=test_set.iloc[:,:-1], \n",
    "#                                   label=test_set.iloc[:,-1])\n",
    "\n",
    "        return model.predict(test_set.iloc[:,:-1])\n",
    "\n",
    "def model_worst_predict(model, test_set, test_groups):\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    preds  = model_predict(model, test_set)\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = preds[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "\n",
    "    return np.array(true_labels), np.array(worst_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learned_models(eval_metrics, model, model_type, test, test_groups=None, budget=0):\n",
    "    # output dataframe\n",
    "    header = ['Model'] + ['Budget'] + [m.__name__.replace('eval_','').replace('_',' ').strip().title() \n",
    "                                       for m in eval_metrics]\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    first_row = [model_type] + [budget] + [None for m in eval_metrics]\n",
    "    df.loc[0] = first_row\n",
    "    \n",
    "    # predictions for plan and atk datasets\n",
    "    if test_groups is None: # NOT ATKed\n",
    "        y_true = test.iloc[:,-1].values\n",
    "        y_pred = model_predict(model, test)\n",
    "    else:\n",
    "        y_true, y_pred = model_worst_predict(model, test, test_groups)\n",
    "        \n",
    "    for eval_metric in eval_metrics:\n",
    "        res = eval_metric(y_true=y_true, y_pred=y_pred)\n",
    "        print(\"{} learning - {} = {:.5f}\"\n",
    "                  .format(model_type, eval_metric.__name__, res))\n",
    "        column_metric = eval_metric.__name__\n",
    "        df[column_metric.replace('eval_','').replace('_',' ').strip().title()] = res\n",
    "\n",
    "    print(\"******************************************************************************************************\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load attacked datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an attacked dataset with a specific budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attacked_dataset(budget):\n",
    "    # load train/valid/test (attacked)\n",
    "    train_att, valid_att, test_att = load_atk_train_valid_test(TRAINING_FILENAME_ATT.format(budget), \n",
    "                                                                  VALIDATION_FILENAME_ATT.format(budget), \n",
    "                                                                  TEST_FILENAME_ATT.format(budget))\n",
    "\n",
    "    test_groups = test_att['instance_id'].value_counts().sort_index().values\n",
    "    test_att = test_att.iloc[:, 1:]\n",
    "\n",
    "    valid_groups = valid_att['instance_id'].value_counts().sort_index().values\n",
    "    valid_att = valid_att.iloc[:, 1:]\n",
    "\n",
    "    train_groups = train_att['instance_id'].value_counts().sort_index().values\n",
    "    train_att = train_att.iloc[:, 1:]\n",
    "    \n",
    "    return train_att, train_groups, valid_att, valid_groups, test_att, test_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load _all_ the attacked datasets given a list of budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attacked_datasets(budgets):\n",
    "    att_datasets = {}\n",
    "    for b in budgets:\n",
    "        att_datasets[b] = load_attacked_dataset(b)\n",
    "    \n",
    "    return att_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all models w.r.t. standard metrics (i.e., attack-free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_name(model_filename):\n",
    "    model_fileroot = model_filename.split('/')[-1].split('.')[0]\n",
    "    model_name = model_fileroot.split('_')[0].title()\n",
    "    training_budget = ''\n",
    "    budget = model_fileroot.split('_B')[-1].split('_')[0]\n",
    "    try: \n",
    "        int(budget)\n",
    "        training_budget = ' [train budget={}]'.format(budget)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return model_name + training_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    model = None\n",
    "    try:\n",
    "        model = lightgbm.Booster(model_file=model_file)\n",
    "    except:\n",
    "        print(\"LightGBM loading exception\")\n",
    "        try:\n",
    "            with open(model_file, 'rb') as mf:\n",
    "                model = dill.load(mf)\n",
    "                print(model)\n",
    "                model.n_jobs = 16\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Dill loading exception\")\n",
    "            pass\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_models(eval_metrics, models_dir, test, model_filenames=None):\n",
    "    \n",
    "    if model_filenames is None:\n",
    "        model_csv = sorted(glob.glob(models_dir + \"/*.csv\"))\n",
    "        model_filenames = []\n",
    "\n",
    "        for m in model_csv:\n",
    "            model_df = pd.read_csv(m)\n",
    "            # print(model_df)\n",
    "            model_filenames.append(model_df.sort_values(by='metric')['filename'].iloc[0])\n",
    "    \n",
    "    print (\"### Evaluating Models:\", model_filenames)\n",
    "    \n",
    "    df = pd.concat([eval_learned_models(eval_metrics, \n",
    "                                        load_model(mf), \n",
    "                                        extract_model_name(mf), \n",
    "                                        test) for mf in model_filenames],\n",
    "                   axis=0,\n",
    "                   sort=False\n",
    "                  )\n",
    "    \n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_models_under_attack_budget(eval_metrics, models_dir, test, test_groups, budget, model_filenames=None):\n",
    "    \n",
    "    #model_filenames = sorted(glob.glob(models_dir + \"/*.model\"))\n",
    "    if model_filenames is None:\n",
    "        model_csv = sorted(glob.glob(models_dir + \"/*.csv\"))\n",
    "        model_filenames = []\n",
    "\n",
    "        for m in model_csv:\n",
    "            model_df = pd.read_csv(m)\n",
    "            model_filenames.append(model_df.sort_values(by='metric')['filename'].iloc[0])\n",
    "    \n",
    "    print (\"### Evaluating Models:\", model_filenames)\n",
    "\n",
    "    df = pd.concat([eval_learned_models(eval_metrics, \n",
    "                                        load_model(mf), \n",
    "                                        extract_model_name(mf), \n",
    "                                        test,\n",
    "                                        test_groups, \n",
    "                                        budget=budget\n",
    "                                       ) for mf in model_filenames],\n",
    "                   axis=0,\n",
    "                   sort=False\n",
    "                  )\n",
    "    \n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_models_under_attack(eval_metrics, models_dir, att_tests, budgets, model_filenames=None):\n",
    "    \n",
    "    eval_att_dfs = []\n",
    "\n",
    "    for b in budgets:\n",
    "        eval_att_dfs.append(\n",
    "            eval_all_models_under_attack_budget(eval_metrics, models_dir, att_tests[b][4], att_tests[b][5], \n",
    "                                                b, model_filenames))\n",
    "        \n",
    "        \n",
    "    eval_att_df = functools.reduce(lambda left,right: pd.merge(left,right,on=['Model', 'Budget']), eval_att_dfs)\n",
    "    eval_att_df = pd.concat(eval_att_dfs, axis=0, sort=False)\n",
    "    eval_att_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return eval_att_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRICS = [ #eval_log_loss, \n",
    "                eval_binary_err_rate,\n",
    "                #eval_specificity,\n",
    "                #eval_precision,\n",
    "                #eval_recall,\n",
    "                eval_f1_micro,\n",
    "                eval_f1_macro,\n",
    "                eval_roc_auc\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENSUS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"census\"\n",
    "TRAINING_BUDGETS= [30, 60,90,120]\n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "adv_models = [\"../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model\",\n",
    "              \"../out/models/census/adv-boosting_census_B60_T100_S0050_L256_R96.model\",\n",
    "              \"../out/models/census/adv-boosting_census_B90_T100_S0050_L256_R98.model\",\n",
    "              \"../out/models/census/adv-boosting_census_B120_T100_S0050_L256_R94.model\"\n",
    "             ]\n",
    "\n",
    "gdbt_models = [\"../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model\",\n",
    "               \"../out/models/census/std-gbdt_census_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "red_models = [\"../out/models/census/red-gbdt_census_T100_S0050_L24_R95.model\",\n",
    "             \"../out/models/census/red-gbdt_census_T100_S0050_L256_R93.model\"]\n",
    "\n",
    "rf_models = [\"../out/models/census/rf-gbdt_census_T100_S0050_L24_R100.model\",\n",
    "             \"../out/models/census/rf-gbdt_census_T100_S0050_L256_R92.model\"]\n",
    "\n",
    "\n",
    "\n",
    "robust_models = [\"../out/models/census/par-robust_census_B30_T100_D8_I20.model\",\n",
    "                 \"../out/models/census/par-robust_census_B60_T100_D8_I20.model\",\n",
    "                 \"../out/models/census/par-robust_census_B90_T100_D8_I20.model\",\n",
    "                 \"../out/models/census/par-robust_census_B120_T100_D8_I20.model\"\n",
    "                ]\n",
    "\n",
    "test_models = adv_models + gdbt_models + rf_models+ robust_models\n",
    "#test_models = adv_models + gdbt_models + rf_models \n",
    "\n",
    "# REDUCED are not working any more??!?\n",
    "#test_models = red_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/census/train.csv.bz2\n",
      "Loading: ../data/census/valid.csv.bz2\n",
      "Loading: ../data/census/test.csv.bz2\n",
      "Train/Valid/Test sizes: (27144, 14) (3017, 14) (15059, 14)\n",
      "Train/Valid/Test split: 0.60 0.07 0.33\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (27132, 14) (9044, 14) (9044, 14)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "### Evaluating Models: ['../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model', '../out/models/census/adv-boosting_census_B60_T100_S0050_L256_R96.model', '../out/models/census/adv-boosting_census_B90_T100_S0050_L256_R98.model', '../out/models/census/adv-boosting_census_B120_T100_S0050_L256_R94.model', '../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/std-gbdt_census_T100_S0050_L256_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L256_R92.model', '../out/models/census/par-robust_census_B30_T100_D8_I20.model', '../out/models/census/par-robust_census_B60_T100_D8_I20.model', '../out/models/census/par-robust_census_B90_T100_D8_I20.model', '../out/models/census/par-robust_census_B120_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.13523\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_micro = 0.86477\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_macro = 0.80623\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.91939\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=60] learning - eval_binary_err_rate = 0.13799\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_micro = 0.86201\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_macro = 0.79964\n",
      "Adv-Boosting [train budget=60] learning - eval_roc_auc = 0.91738\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=90] learning - eval_binary_err_rate = 0.13843\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_micro = 0.86157\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_macro = 0.79885\n",
      "Adv-Boosting [train budget=90] learning - eval_roc_auc = 0.91740\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=120] learning - eval_binary_err_rate = 0.13755\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_micro = 0.86245\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_macro = 0.79809\n",
      "Adv-Boosting [train budget=120] learning - eval_roc_auc = 0.91569\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.13058\n",
      "Std-Gbdt learning - eval_f1_micro = 0.86942\n",
      "Std-Gbdt learning - eval_f1_macro = 0.81110\n",
      "Std-Gbdt learning - eval_roc_auc = 0.92189\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.13125\n",
      "Std-Gbdt learning - eval_f1_micro = 0.86875\n",
      "Std-Gbdt learning - eval_f1_macro = 0.81007\n",
      "Std-Gbdt learning - eval_roc_auc = 0.92174\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.13722\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.86278\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.79388\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.90927\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.13490\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.86510\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.80007\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.91383\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.15049\n",
      "Par-Robust [train budget=30] learning - eval_f1_micro = 0.84951\n",
      "Par-Robust [train budget=30] learning - eval_f1_macro = 0.77281\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.89661\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n",
      "Par-Robust [train budget=60] learning - eval_binary_err_rate = 0.15137\n",
      "Par-Robust [train budget=60] learning - eval_f1_micro = 0.84863\n",
      "Par-Robust [train budget=60] learning - eval_f1_macro = 0.76995\n",
      "Par-Robust [train budget=60] learning - eval_roc_auc = 0.89750\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n",
      "Par-Robust [train budget=90] learning - eval_binary_err_rate = 0.15060\n",
      "Par-Robust [train budget=90] learning - eval_f1_micro = 0.84940\n",
      "Par-Robust [train budget=90] learning - eval_f1_macro = 0.77313\n",
      "Par-Robust [train budget=90] learning - eval_roc_auc = 0.89717\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n",
      "Par-Robust [train budget=120] learning - eval_binary_err_rate = 0.15314\n",
      "Par-Robust [train budget=120] learning - eval_f1_micro = 0.84686\n",
      "Par-Robust [train budget=120] learning - eval_f1_macro = 0.76808\n",
      "Par-Robust [train budget=120] learning - eval_roc_auc = 0.89230\n",
      "******************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Binary Err Rate</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135228</td>\n",
       "      <td>0.864772</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adv-Boosting [train budget=60]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137992</td>\n",
       "      <td>0.862008</td>\n",
       "      <td>0.799635</td>\n",
       "      <td>0.917376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adv-Boosting [train budget=90]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138434</td>\n",
       "      <td>0.861566</td>\n",
       "      <td>0.798849</td>\n",
       "      <td>0.917404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adv-Boosting [train budget=120]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137550</td>\n",
       "      <td>0.862450</td>\n",
       "      <td>0.798094</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130584</td>\n",
       "      <td>0.869416</td>\n",
       "      <td>0.811101</td>\n",
       "      <td>0.921891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131247</td>\n",
       "      <td>0.868753</td>\n",
       "      <td>0.810074</td>\n",
       "      <td>0.921738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137218</td>\n",
       "      <td>0.862782</td>\n",
       "      <td>0.793879</td>\n",
       "      <td>0.909271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134896</td>\n",
       "      <td>0.865104</td>\n",
       "      <td>0.800075</td>\n",
       "      <td>0.913827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150487</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.772810</td>\n",
       "      <td>0.896611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151371</td>\n",
       "      <td>0.848629</td>\n",
       "      <td>0.769953</td>\n",
       "      <td>0.897497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150597</td>\n",
       "      <td>0.849403</td>\n",
       "      <td>0.773127</td>\n",
       "      <td>0.897165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Par-Robust [train budget=120]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153140</td>\n",
       "      <td>0.846860</td>\n",
       "      <td>0.768083</td>\n",
       "      <td>0.892296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model Budget  Binary Err Rate  F1 Micro  \\\n",
       "0    Adv-Boosting [train budget=30]      0         0.135228  0.864772   \n",
       "1    Adv-Boosting [train budget=60]      0         0.137992  0.862008   \n",
       "2    Adv-Boosting [train budget=90]      0         0.138434  0.861566   \n",
       "3   Adv-Boosting [train budget=120]      0         0.137550  0.862450   \n",
       "4                          Std-Gbdt      0         0.130584  0.869416   \n",
       "5                          Std-Gbdt      0         0.131247  0.868753   \n",
       "6                           Rf-Gbdt      0         0.137218  0.862782   \n",
       "7                           Rf-Gbdt      0         0.134896  0.865104   \n",
       "8      Par-Robust [train budget=30]      0         0.150487  0.849513   \n",
       "9      Par-Robust [train budget=60]      0         0.151371  0.848629   \n",
       "10     Par-Robust [train budget=90]      0         0.150597  0.849403   \n",
       "11    Par-Robust [train budget=120]      0         0.153140  0.846860   \n",
       "\n",
       "    F1 Macro   Roc Auc  \n",
       "0   0.806233  0.919386  \n",
       "1   0.799635  0.917376  \n",
       "2   0.798849  0.917404  \n",
       "3   0.798094  0.915690  \n",
       "4   0.811101  0.921891  \n",
       "5   0.810074  0.921738  \n",
       "6   0.793879  0.909271  \n",
       "7   0.800075  0.913827  \n",
       "8   0.772810  0.896611  \n",
       "9   0.769953  0.897497  \n",
       "10  0.773127  0.897165  \n",
       "11  0.768083  0.892296  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/census/attacks/train_B30.atks.bz2\n",
      "Loading: ../data/census/attacks/valid_B30.atks.bz2\n",
      "Loading: ../data/census/attacks/test_B30.atks.bz2\n",
      "Train/Valid/Test sizes: (75287, 15) (8308, 15) (41872, 15)\n",
      "Train/Valid/Test split: 0.60 0.07 0.33\n",
      "   ... with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (75264, 15) (25084, 15) (25119, 15)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "Pre-processing original files...\n",
      "Loading: ../data/census/attacks/train_B60.atks.bz2\n",
      "Loading: ../data/census/attacks/valid_B60.atks.bz2\n",
      "Loading: ../data/census/attacks/test_B60.atks.bz2\n",
      "Train/Valid/Test sizes: (1088966, 15) (73446, 15) (693007, 15)\n",
      "Train/Valid/Test split: 0.59 0.04 0.37\n",
      "   ... with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (1088618, 15) (350982, 15) (415819, 15)\n",
      "Train/Valid/Test split: 0.59 0.19 0.22\n",
      "Saving processed files *.atks.bz2\n",
      "Pre-processing original files...\n",
      "Loading: ../data/census/attacks/train_B90.atks.bz2\n",
      "Loading: ../data/census/attacks/valid_B90.atks.bz2\n",
      "Loading: ../data/census/attacks/test_B90.atks.bz2\n",
      "Train/Valid/Test sizes: (1365600, 15) (91481, 15) (874638, 15)\n",
      "Train/Valid/Test split: 0.59 0.04 0.38\n",
      "   ... with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (1365167, 15) (442163, 15) (524389, 15)\n",
      "Train/Valid/Test split: 0.59 0.19 0.22\n",
      "Saving processed files *.atks.bz2\n",
      "Pre-processing original files...\n",
      "Loading: ../data/census/attacks/train_B120.atks.bz2\n",
      "Loading: ../data/census/attacks/valid_B120.atks.bz2\n",
      "Loading: ../data/census/attacks/test_B120.atks.bz2\n",
      "Train/Valid/Test sizes: (5540300, 15) (338511, 15) (3091326, 15)\n",
      "Train/Valid/Test split: 0.62 0.04 0.34\n",
      "   ... with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (5538485, 15) (1576260, 15) (1855392, 15)\n",
      "Train/Valid/Test split: 0.62 0.18 0.21\n",
      "Saving processed files *.atks.bz2\n",
      "### Evaluating Models: ['../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model', '../out/models/census/adv-boosting_census_B60_T100_S0050_L256_R96.model', '../out/models/census/adv-boosting_census_B90_T100_S0050_L256_R98.model', '../out/models/census/adv-boosting_census_B120_T100_S0050_L256_R94.model', '../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/std-gbdt_census_T100_S0050_L256_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L256_R92.model', '../out/models/census/par-robust_census_B30_T100_D8_I20.model', '../out/models/census/par-robust_census_B60_T100_D8_I20.model', '../out/models/census/par-robust_census_B90_T100_D8_I20.model', '../out/models/census/par-robust_census_B120_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.15004\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_micro = 0.84996\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_macro = 0.78280\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.90230\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=60] learning - eval_binary_err_rate = 0.16320\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_micro = 0.83680\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_macro = 0.75857\n",
      "Adv-Boosting [train budget=60] learning - eval_roc_auc = 0.88510\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=90] learning - eval_binary_err_rate = 0.16464\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_micro = 0.83536\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_macro = 0.75457\n",
      "Adv-Boosting [train budget=90] learning - eval_roc_auc = 0.88570\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=120] learning - eval_binary_err_rate = 0.16022\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_micro = 0.83978\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_macro = 0.75979\n",
      "Adv-Boosting [train budget=120] learning - eval_roc_auc = 0.88788\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.22081\n",
      "Std-Gbdt learning - eval_f1_micro = 0.77919\n",
      "Std-Gbdt learning - eval_f1_macro = 0.62118\n",
      "Std-Gbdt learning - eval_roc_auc = 0.81467\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.21926\n",
      "Std-Gbdt learning - eval_f1_micro = 0.78074\n",
      "Std-Gbdt learning - eval_f1_macro = 0.62639\n",
      "Std-Gbdt learning - eval_roc_auc = 0.81158\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.21771\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.78229\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.61545\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.79035\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.21992\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.78008\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.61451\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.79174\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.15049\n",
      "Par-Robust [train budget=30] learning - eval_f1_micro = 0.84951\n",
      "Par-Robust [train budget=30] learning - eval_f1_macro = 0.77281\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.89661\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par-Robust [train budget=60] learning - eval_binary_err_rate = 0.15137\n",
      "Par-Robust [train budget=60] learning - eval_f1_micro = 0.84863\n",
      "Par-Robust [train budget=60] learning - eval_f1_macro = 0.76995\n",
      "Par-Robust [train budget=60] learning - eval_roc_auc = 0.89750\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n",
      "Par-Robust [train budget=90] learning - eval_binary_err_rate = 0.15060\n",
      "Par-Robust [train budget=90] learning - eval_f1_micro = 0.84940\n",
      "Par-Robust [train budget=90] learning - eval_f1_macro = 0.77313\n",
      "Par-Robust [train budget=90] learning - eval_roc_auc = 0.89717\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par-Robust [train budget=120] learning - eval_binary_err_rate = 0.15314\n",
      "Par-Robust [train budget=120] learning - eval_f1_micro = 0.84686\n",
      "Par-Robust [train budget=120] learning - eval_f1_macro = 0.76808\n",
      "Par-Robust [train budget=120] learning - eval_roc_auc = 0.89230\n",
      "******************************************************************************************************\n",
      "### Evaluating Models: ['../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model', '../out/models/census/adv-boosting_census_B60_T100_S0050_L256_R96.model', '../out/models/census/adv-boosting_census_B90_T100_S0050_L256_R98.model', '../out/models/census/adv-boosting_census_B120_T100_S0050_L256_R94.model', '../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/std-gbdt_census_T100_S0050_L256_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L256_R92.model', '../out/models/census/par-robust_census_B30_T100_D8_I20.model', '../out/models/census/par-robust_census_B60_T100_D8_I20.model', '../out/models/census/par-robust_census_B90_T100_D8_I20.model', '../out/models/census/par-robust_census_B120_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.18675\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_micro = 0.81325\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_macro = 0.73033\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.83643\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=60] learning - eval_binary_err_rate = 0.21661\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_micro = 0.78339\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_macro = 0.69027\n",
      "Adv-Boosting [train budget=60] learning - eval_roc_auc = 0.82706\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=90] learning - eval_binary_err_rate = 0.20013\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_micro = 0.79987\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_macro = 0.70909\n",
      "Adv-Boosting [train budget=90] learning - eval_roc_auc = 0.82702\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=120] learning - eval_binary_err_rate = 0.19538\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_micro = 0.80462\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_macro = 0.71544\n",
      "Adv-Boosting [train budget=120] learning - eval_roc_auc = 0.81903\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.24303\n",
      "Std-Gbdt learning - eval_f1_micro = 0.75697\n",
      "Std-Gbdt learning - eval_f1_macro = 0.59550\n",
      "Std-Gbdt learning - eval_roc_auc = 0.73360\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.24502\n",
      "Std-Gbdt learning - eval_f1_micro = 0.75498\n",
      "Std-Gbdt learning - eval_f1_macro = 0.59445\n",
      "Std-Gbdt learning - eval_roc_auc = 0.67839\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.22954\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.77046\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.60454\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.76705\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.23187\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.76813\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.60318\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.77220\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.16132\n",
      "Par-Robust [train budget=30] learning - eval_f1_micro = 0.83868\n",
      "Par-Robust [train budget=30] learning - eval_f1_macro = 0.76095\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.88580\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=60] learning - eval_binary_err_rate = 0.15546\n",
      "Par-Robust [train budget=60] learning - eval_f1_micro = 0.84454\n",
      "Par-Robust [train budget=60] learning - eval_f1_macro = 0.76544\n",
      "Par-Robust [train budget=60] learning - eval_roc_auc = 0.89355\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=90] learning - eval_binary_err_rate = 0.15458\n",
      "Par-Robust [train budget=90] learning - eval_f1_micro = 0.84542\n",
      "Par-Robust [train budget=90] learning - eval_f1_macro = 0.76873\n",
      "Par-Robust [train budget=90] learning - eval_roc_auc = 0.89326\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=120] learning - eval_binary_err_rate = 0.15646\n",
      "Par-Robust [train budget=120] learning - eval_f1_micro = 0.84354\n",
      "Par-Robust [train budget=120] learning - eval_f1_macro = 0.76444\n",
      "Par-Robust [train budget=120] learning - eval_roc_auc = 0.88959\n",
      "******************************************************************************************************\n",
      "### Evaluating Models: ['../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model', '../out/models/census/adv-boosting_census_B60_T100_S0050_L256_R96.model', '../out/models/census/adv-boosting_census_B90_T100_S0050_L256_R98.model', '../out/models/census/adv-boosting_census_B120_T100_S0050_L256_R94.model', '../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/std-gbdt_census_T100_S0050_L256_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L256_R92.model', '../out/models/census/par-robust_census_B30_T100_D8_I20.model', '../out/models/census/par-robust_census_B60_T100_D8_I20.model', '../out/models/census/par-robust_census_B90_T100_D8_I20.model', '../out/models/census/par-robust_census_B120_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.18841\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_micro = 0.81159\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_macro = 0.72721\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.83296\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=60] learning - eval_binary_err_rate = 0.24171\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_micro = 0.75829\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_macro = 0.64015\n",
      "Adv-Boosting [train budget=60] learning - eval_roc_auc = 0.80206\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=90] learning - eval_binary_err_rate = 0.20212\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_micro = 0.79788\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_macro = 0.70535\n",
      "Adv-Boosting [train budget=90] learning - eval_roc_auc = 0.82465\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=120] learning - eval_binary_err_rate = 0.19748\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_micro = 0.80252\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_macro = 0.71171\n",
      "Adv-Boosting [train budget=120] learning - eval_roc_auc = 0.81633\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.24348\n",
      "Std-Gbdt learning - eval_f1_micro = 0.75652\n",
      "Std-Gbdt learning - eval_f1_macro = 0.59439\n",
      "Std-Gbdt learning - eval_roc_auc = 0.70589\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.24569\n",
      "Std-Gbdt learning - eval_f1_micro = 0.75431\n",
      "Std-Gbdt learning - eval_f1_macro = 0.59297\n",
      "Std-Gbdt learning - eval_roc_auc = 0.64253\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.22999\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.77001\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.60339\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.75907\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.23231\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.76769\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.60204\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.76625\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.16132\n",
      "Par-Robust [train budget=30] learning - eval_f1_micro = 0.83868\n",
      "Par-Robust [train budget=30] learning - eval_f1_macro = 0.76095\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.88580\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=60] learning - eval_binary_err_rate = 0.15546\n",
      "Par-Robust [train budget=60] learning - eval_f1_micro = 0.84454\n",
      "Par-Robust [train budget=60] learning - eval_f1_macro = 0.76544\n",
      "Par-Robust [train budget=60] learning - eval_roc_auc = 0.89355\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=90] learning - eval_binary_err_rate = 0.15458\n",
      "Par-Robust [train budget=90] learning - eval_f1_micro = 0.84542\n",
      "Par-Robust [train budget=90] learning - eval_f1_macro = 0.76873\n",
      "Par-Robust [train budget=90] learning - eval_roc_auc = 0.89326\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=120] learning - eval_binary_err_rate = 0.15646\n",
      "Par-Robust [train budget=120] learning - eval_f1_micro = 0.84354\n",
      "Par-Robust [train budget=120] learning - eval_f1_macro = 0.76444\n",
      "Par-Robust [train budget=120] learning - eval_roc_auc = 0.88959\n",
      "******************************************************************************************************\n",
      "### Evaluating Models: ['../out/models/census/adv-boosting_census_B30_T100_S0050_L256_R100.model', '../out/models/census/adv-boosting_census_B60_T100_S0050_L256_R96.model', '../out/models/census/adv-boosting_census_B90_T100_S0050_L256_R98.model', '../out/models/census/adv-boosting_census_B120_T100_S0050_L256_R94.model', '../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/std-gbdt_census_T100_S0050_L256_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L24_R100.model', '../out/models/census/rf-gbdt_census_T100_S0050_L256_R92.model', '../out/models/census/par-robust_census_B30_T100_D8_I20.model', '../out/models/census/par-robust_census_B60_T100_D8_I20.model', '../out/models/census/par-robust_census_B90_T100_D8_I20.model', '../out/models/census/par-robust_census_B120_T100_D8_I20.model']\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=30] learning - eval_binary_err_rate = 0.41464\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_micro = 0.58536\n",
      "Adv-Boosting [train budget=30] learning - eval_f1_macro = 0.47584\n",
      "Adv-Boosting [train budget=30] learning - eval_roc_auc = 0.51538\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=60] learning - eval_binary_err_rate = 0.30197\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_micro = 0.69803\n",
      "Adv-Boosting [train budget=60] learning - eval_f1_macro = 0.53141\n",
      "Adv-Boosting [train budget=60] learning - eval_roc_auc = 0.54289\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=90] learning - eval_binary_err_rate = 0.29633\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_micro = 0.70367\n",
      "Adv-Boosting [train budget=90] learning - eval_f1_macro = 0.54175\n",
      "Adv-Boosting [train budget=90] learning - eval_roc_auc = 0.58096\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Adv-Boosting [train budget=120] learning - eval_binary_err_rate = 0.21241\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_micro = 0.78759\n",
      "Adv-Boosting [train budget=120] learning - eval_f1_macro = 0.69350\n",
      "Adv-Boosting [train budget=120] learning - eval_roc_auc = 0.79336\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.37318\n",
      "Std-Gbdt learning - eval_f1_micro = 0.62682\n",
      "Std-Gbdt learning - eval_f1_macro = 0.50059\n",
      "Std-Gbdt learning - eval_roc_auc = 0.28425\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Std-Gbdt learning - eval_binary_err_rate = 0.43211\n",
      "Std-Gbdt learning - eval_f1_micro = 0.56789\n",
      "Std-Gbdt learning - eval_f1_macro = 0.46163\n",
      "Std-Gbdt learning - eval_roc_auc = 0.26406\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.23983\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.76017\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.59526\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.72515\n",
      "******************************************************************************************************\n",
      "LightGBM\n",
      "Rf-Gbdt learning - eval_binary_err_rate = 0.24469\n",
      "Rf-Gbdt learning - eval_f1_micro = 0.75531\n",
      "Rf-Gbdt learning - eval_f1_macro = 0.59189\n",
      "Rf-Gbdt learning - eval_roc_auc = 0.73115\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=30] learning - eval_binary_err_rate = 0.17238\n",
      "Par-Robust [train budget=30] learning - eval_f1_micro = 0.82762\n",
      "Par-Robust [train budget=30] learning - eval_f1_macro = 0.74921\n",
      "Par-Robust [train budget=30] learning - eval_roc_auc = 0.86373\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n",
      "Par-Robust [train budget=60] learning - eval_binary_err_rate = 0.16862\n",
      "Par-Robust [train budget=60] learning - eval_f1_micro = 0.83138\n",
      "Par-Robust [train budget=60] learning - eval_f1_macro = 0.75116\n",
      "Par-Robust [train budget=60] learning - eval_roc_auc = 0.87618\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=90] learning - eval_binary_err_rate = 0.16785\n",
      "Par-Robust [train budget=90] learning - eval_f1_micro = 0.83215\n",
      "Par-Robust [train budget=90] learning - eval_f1_macro = 0.75443\n",
      "Par-Robust [train budget=90] learning - eval_roc_auc = 0.87544\n",
      "******************************************************************************************************\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(attacker=None, feature_blacklist={}, max_depth=8,\n",
      "          max_features=0.8, max_samples=0.8, min_instances_per_node=20,\n",
      "          replace_features=False, replace_samples=False, seed=0,\n",
      "          split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.21.2 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier\n",
      "Par-Robust [train budget=120] learning - eval_binary_err_rate = 0.15845\n",
      "Par-Robust [train budget=120] learning - eval_f1_micro = 0.84155\n",
      "Par-Robust [train budget=120] learning - eval_f1_macro = 0.76226\n",
      "Par-Robust [train budget=120] learning - eval_roc_auc = 0.88691\n",
      "******************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Binary Err Rate</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135228</td>\n",
       "      <td>0.864772</td>\n",
       "      <td>0.806233</td>\n",
       "      <td>0.919386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adv-Boosting [train budget=60]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137992</td>\n",
       "      <td>0.862008</td>\n",
       "      <td>0.799635</td>\n",
       "      <td>0.917376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adv-Boosting [train budget=90]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138434</td>\n",
       "      <td>0.861566</td>\n",
       "      <td>0.798849</td>\n",
       "      <td>0.917404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adv-Boosting [train budget=120]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137550</td>\n",
       "      <td>0.862450</td>\n",
       "      <td>0.798094</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130584</td>\n",
       "      <td>0.869416</td>\n",
       "      <td>0.811101</td>\n",
       "      <td>0.921891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131247</td>\n",
       "      <td>0.868753</td>\n",
       "      <td>0.810074</td>\n",
       "      <td>0.921738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137218</td>\n",
       "      <td>0.862782</td>\n",
       "      <td>0.793879</td>\n",
       "      <td>0.909271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134896</td>\n",
       "      <td>0.865104</td>\n",
       "      <td>0.800075</td>\n",
       "      <td>0.913827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150487</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.772810</td>\n",
       "      <td>0.896611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151371</td>\n",
       "      <td>0.848629</td>\n",
       "      <td>0.769953</td>\n",
       "      <td>0.897497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150597</td>\n",
       "      <td>0.849403</td>\n",
       "      <td>0.773127</td>\n",
       "      <td>0.897165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Par-Robust [train budget=120]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153140</td>\n",
       "      <td>0.846860</td>\n",
       "      <td>0.768083</td>\n",
       "      <td>0.892296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.150044</td>\n",
       "      <td>0.849956</td>\n",
       "      <td>0.782796</td>\n",
       "      <td>0.902302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adv-Boosting [train budget=60]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.163202</td>\n",
       "      <td>0.836798</td>\n",
       "      <td>0.758574</td>\n",
       "      <td>0.885101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Adv-Boosting [train budget=90]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.164640</td>\n",
       "      <td>0.835360</td>\n",
       "      <td>0.754566</td>\n",
       "      <td>0.885699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adv-Boosting [train budget=120]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.160217</td>\n",
       "      <td>0.839783</td>\n",
       "      <td>0.759792</td>\n",
       "      <td>0.887885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>30</td>\n",
       "      <td>0.220809</td>\n",
       "      <td>0.779191</td>\n",
       "      <td>0.621180</td>\n",
       "      <td>0.814668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>30</td>\n",
       "      <td>0.219261</td>\n",
       "      <td>0.780739</td>\n",
       "      <td>0.626393</td>\n",
       "      <td>0.811581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>30</td>\n",
       "      <td>0.217713</td>\n",
       "      <td>0.782287</td>\n",
       "      <td>0.615453</td>\n",
       "      <td>0.790351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>30</td>\n",
       "      <td>0.219925</td>\n",
       "      <td>0.780075</td>\n",
       "      <td>0.614515</td>\n",
       "      <td>0.791739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.150487</td>\n",
       "      <td>0.849513</td>\n",
       "      <td>0.772810</td>\n",
       "      <td>0.896611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.151371</td>\n",
       "      <td>0.848629</td>\n",
       "      <td>0.769953</td>\n",
       "      <td>0.897497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.150597</td>\n",
       "      <td>0.849403</td>\n",
       "      <td>0.773127</td>\n",
       "      <td>0.897165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Par-Robust [train budget=120]</td>\n",
       "      <td>30</td>\n",
       "      <td>0.153140</td>\n",
       "      <td>0.846860</td>\n",
       "      <td>0.768083</td>\n",
       "      <td>0.892296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.186754</td>\n",
       "      <td>0.813246</td>\n",
       "      <td>0.730326</td>\n",
       "      <td>0.836427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Adv-Boosting [train budget=60]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.216608</td>\n",
       "      <td>0.783392</td>\n",
       "      <td>0.690271</td>\n",
       "      <td>0.827056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Adv-Boosting [train budget=90]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.200133</td>\n",
       "      <td>0.799867</td>\n",
       "      <td>0.709094</td>\n",
       "      <td>0.827023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Adv-Boosting [train budget=120]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.195378</td>\n",
       "      <td>0.804622</td>\n",
       "      <td>0.715442</td>\n",
       "      <td>0.819031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>60</td>\n",
       "      <td>0.243034</td>\n",
       "      <td>0.756966</td>\n",
       "      <td>0.595502</td>\n",
       "      <td>0.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>60</td>\n",
       "      <td>0.245024</td>\n",
       "      <td>0.754976</td>\n",
       "      <td>0.594448</td>\n",
       "      <td>0.678388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>60</td>\n",
       "      <td>0.229544</td>\n",
       "      <td>0.770456</td>\n",
       "      <td>0.604545</td>\n",
       "      <td>0.767048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>60</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.768134</td>\n",
       "      <td>0.603182</td>\n",
       "      <td>0.772198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.161322</td>\n",
       "      <td>0.838678</td>\n",
       "      <td>0.760954</td>\n",
       "      <td>0.885796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.844538</td>\n",
       "      <td>0.765435</td>\n",
       "      <td>0.893552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.154578</td>\n",
       "      <td>0.845422</td>\n",
       "      <td>0.768733</td>\n",
       "      <td>0.893256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Par-Robust [train budget=120]</td>\n",
       "      <td>60</td>\n",
       "      <td>0.156457</td>\n",
       "      <td>0.843543</td>\n",
       "      <td>0.764435</td>\n",
       "      <td>0.889587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.188412</td>\n",
       "      <td>0.811588</td>\n",
       "      <td>0.727206</td>\n",
       "      <td>0.832964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Adv-Boosting [train budget=60]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.241707</td>\n",
       "      <td>0.758293</td>\n",
       "      <td>0.640155</td>\n",
       "      <td>0.802062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Adv-Boosting [train budget=90]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.202123</td>\n",
       "      <td>0.797877</td>\n",
       "      <td>0.705353</td>\n",
       "      <td>0.824655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Adv-Boosting [train budget=120]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.197479</td>\n",
       "      <td>0.802521</td>\n",
       "      <td>0.711706</td>\n",
       "      <td>0.816326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>90</td>\n",
       "      <td>0.243476</td>\n",
       "      <td>0.756524</td>\n",
       "      <td>0.594388</td>\n",
       "      <td>0.705888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>90</td>\n",
       "      <td>0.245688</td>\n",
       "      <td>0.754312</td>\n",
       "      <td>0.592975</td>\n",
       "      <td>0.642532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>90</td>\n",
       "      <td>0.229987</td>\n",
       "      <td>0.770013</td>\n",
       "      <td>0.603391</td>\n",
       "      <td>0.759069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>90</td>\n",
       "      <td>0.232309</td>\n",
       "      <td>0.767691</td>\n",
       "      <td>0.602037</td>\n",
       "      <td>0.766254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.161322</td>\n",
       "      <td>0.838678</td>\n",
       "      <td>0.760954</td>\n",
       "      <td>0.885796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.844538</td>\n",
       "      <td>0.765435</td>\n",
       "      <td>0.893552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.154578</td>\n",
       "      <td>0.845422</td>\n",
       "      <td>0.768733</td>\n",
       "      <td>0.893256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Par-Robust [train budget=120]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.156457</td>\n",
       "      <td>0.843543</td>\n",
       "      <td>0.764435</td>\n",
       "      <td>0.889587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.414640</td>\n",
       "      <td>0.585360</td>\n",
       "      <td>0.475844</td>\n",
       "      <td>0.515379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Adv-Boosting [train budget=60]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.301968</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.531410</td>\n",
       "      <td>0.542887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Adv-Boosting [train budget=90]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.296329</td>\n",
       "      <td>0.703671</td>\n",
       "      <td>0.541752</td>\n",
       "      <td>0.580960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Adv-Boosting [train budget=120]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.212406</td>\n",
       "      <td>0.787594</td>\n",
       "      <td>0.693501</td>\n",
       "      <td>0.793357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.373176</td>\n",
       "      <td>0.626824</td>\n",
       "      <td>0.500587</td>\n",
       "      <td>0.284250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.432110</td>\n",
       "      <td>0.567890</td>\n",
       "      <td>0.461627</td>\n",
       "      <td>0.264057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.239828</td>\n",
       "      <td>0.760172</td>\n",
       "      <td>0.595257</td>\n",
       "      <td>0.725155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>0.755307</td>\n",
       "      <td>0.591887</td>\n",
       "      <td>0.731149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.172379</td>\n",
       "      <td>0.827621</td>\n",
       "      <td>0.749210</td>\n",
       "      <td>0.863734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.168620</td>\n",
       "      <td>0.831380</td>\n",
       "      <td>0.751161</td>\n",
       "      <td>0.876178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.167846</td>\n",
       "      <td>0.832154</td>\n",
       "      <td>0.754432</td>\n",
       "      <td>0.875442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Par-Robust [train budget=120]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.158448</td>\n",
       "      <td>0.841552</td>\n",
       "      <td>0.762263</td>\n",
       "      <td>0.886913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model Budget  Binary Err Rate  F1 Micro  \\\n",
       "0    Adv-Boosting [train budget=30]      0         0.135228  0.864772   \n",
       "1    Adv-Boosting [train budget=60]      0         0.137992  0.862008   \n",
       "2    Adv-Boosting [train budget=90]      0         0.138434  0.861566   \n",
       "3   Adv-Boosting [train budget=120]      0         0.137550  0.862450   \n",
       "4                          Std-Gbdt      0         0.130584  0.869416   \n",
       "5                          Std-Gbdt      0         0.131247  0.868753   \n",
       "6                           Rf-Gbdt      0         0.137218  0.862782   \n",
       "7                           Rf-Gbdt      0         0.134896  0.865104   \n",
       "8      Par-Robust [train budget=30]      0         0.150487  0.849513   \n",
       "9      Par-Robust [train budget=60]      0         0.151371  0.848629   \n",
       "10     Par-Robust [train budget=90]      0         0.150597  0.849403   \n",
       "11    Par-Robust [train budget=120]      0         0.153140  0.846860   \n",
       "12   Adv-Boosting [train budget=30]     30         0.150044  0.849956   \n",
       "13   Adv-Boosting [train budget=60]     30         0.163202  0.836798   \n",
       "14   Adv-Boosting [train budget=90]     30         0.164640  0.835360   \n",
       "15  Adv-Boosting [train budget=120]     30         0.160217  0.839783   \n",
       "16                         Std-Gbdt     30         0.220809  0.779191   \n",
       "17                         Std-Gbdt     30         0.219261  0.780739   \n",
       "18                          Rf-Gbdt     30         0.217713  0.782287   \n",
       "19                          Rf-Gbdt     30         0.219925  0.780075   \n",
       "20     Par-Robust [train budget=30]     30         0.150487  0.849513   \n",
       "21     Par-Robust [train budget=60]     30         0.151371  0.848629   \n",
       "22     Par-Robust [train budget=90]     30         0.150597  0.849403   \n",
       "23    Par-Robust [train budget=120]     30         0.153140  0.846860   \n",
       "24   Adv-Boosting [train budget=30]     60         0.186754  0.813246   \n",
       "25   Adv-Boosting [train budget=60]     60         0.216608  0.783392   \n",
       "26   Adv-Boosting [train budget=90]     60         0.200133  0.799867   \n",
       "27  Adv-Boosting [train budget=120]     60         0.195378  0.804622   \n",
       "28                         Std-Gbdt     60         0.243034  0.756966   \n",
       "29                         Std-Gbdt     60         0.245024  0.754976   \n",
       "30                          Rf-Gbdt     60         0.229544  0.770456   \n",
       "31                          Rf-Gbdt     60         0.231866  0.768134   \n",
       "32     Par-Robust [train budget=30]     60         0.161322  0.838678   \n",
       "33     Par-Robust [train budget=60]     60         0.155462  0.844538   \n",
       "34     Par-Robust [train budget=90]     60         0.154578  0.845422   \n",
       "35    Par-Robust [train budget=120]     60         0.156457  0.843543   \n",
       "36   Adv-Boosting [train budget=30]     90         0.188412  0.811588   \n",
       "37   Adv-Boosting [train budget=60]     90         0.241707  0.758293   \n",
       "38   Adv-Boosting [train budget=90]     90         0.202123  0.797877   \n",
       "39  Adv-Boosting [train budget=120]     90         0.197479  0.802521   \n",
       "40                         Std-Gbdt     90         0.243476  0.756524   \n",
       "41                         Std-Gbdt     90         0.245688  0.754312   \n",
       "42                          Rf-Gbdt     90         0.229987  0.770013   \n",
       "43                          Rf-Gbdt     90         0.232309  0.767691   \n",
       "44     Par-Robust [train budget=30]     90         0.161322  0.838678   \n",
       "45     Par-Robust [train budget=60]     90         0.155462  0.844538   \n",
       "46     Par-Robust [train budget=90]     90         0.154578  0.845422   \n",
       "47    Par-Robust [train budget=120]     90         0.156457  0.843543   \n",
       "48   Adv-Boosting [train budget=30]    120         0.414640  0.585360   \n",
       "49   Adv-Boosting [train budget=60]    120         0.301968  0.698032   \n",
       "50   Adv-Boosting [train budget=90]    120         0.296329  0.703671   \n",
       "51  Adv-Boosting [train budget=120]    120         0.212406  0.787594   \n",
       "52                         Std-Gbdt    120         0.373176  0.626824   \n",
       "53                         Std-Gbdt    120         0.432110  0.567890   \n",
       "54                          Rf-Gbdt    120         0.239828  0.760172   \n",
       "55                          Rf-Gbdt    120         0.244693  0.755307   \n",
       "56     Par-Robust [train budget=30]    120         0.172379  0.827621   \n",
       "57     Par-Robust [train budget=60]    120         0.168620  0.831380   \n",
       "58     Par-Robust [train budget=90]    120         0.167846  0.832154   \n",
       "59    Par-Robust [train budget=120]    120         0.158448  0.841552   \n",
       "\n",
       "    F1 Macro   Roc Auc  \n",
       "0   0.806233  0.919386  \n",
       "1   0.799635  0.917376  \n",
       "2   0.798849  0.917404  \n",
       "3   0.798094  0.915690  \n",
       "4   0.811101  0.921891  \n",
       "5   0.810074  0.921738  \n",
       "6   0.793879  0.909271  \n",
       "7   0.800075  0.913827  \n",
       "8   0.772810  0.896611  \n",
       "9   0.769953  0.897497  \n",
       "10  0.773127  0.897165  \n",
       "11  0.768083  0.892296  \n",
       "12  0.782796  0.902302  \n",
       "13  0.758574  0.885101  \n",
       "14  0.754566  0.885699  \n",
       "15  0.759792  0.887885  \n",
       "16  0.621180  0.814668  \n",
       "17  0.626393  0.811581  \n",
       "18  0.615453  0.790351  \n",
       "19  0.614515  0.791739  \n",
       "20  0.772810  0.896611  \n",
       "21  0.769953  0.897497  \n",
       "22  0.773127  0.897165  \n",
       "23  0.768083  0.892296  \n",
       "24  0.730326  0.836427  \n",
       "25  0.690271  0.827056  \n",
       "26  0.709094  0.827023  \n",
       "27  0.715442  0.819031  \n",
       "28  0.595502  0.733600  \n",
       "29  0.594448  0.678388  \n",
       "30  0.604545  0.767048  \n",
       "31  0.603182  0.772198  \n",
       "32  0.760954  0.885796  \n",
       "33  0.765435  0.893552  \n",
       "34  0.768733  0.893256  \n",
       "35  0.764435  0.889587  \n",
       "36  0.727206  0.832964  \n",
       "37  0.640155  0.802062  \n",
       "38  0.705353  0.824655  \n",
       "39  0.711706  0.816326  \n",
       "40  0.594388  0.705888  \n",
       "41  0.592975  0.642532  \n",
       "42  0.603391  0.759069  \n",
       "43  0.602037  0.766254  \n",
       "44  0.760954  0.885796  \n",
       "45  0.765435  0.893552  \n",
       "46  0.768733  0.893256  \n",
       "47  0.764435  0.889587  \n",
       "48  0.475844  0.515379  \n",
       "49  0.531410  0.542887  \n",
       "50  0.541752  0.580960  \n",
       "51  0.693501  0.793357  \n",
       "52  0.500587  0.284250  \n",
       "53  0.461627  0.264057  \n",
       "54  0.595257  0.725155  \n",
       "55  0.591887  0.731149  \n",
       "56  0.749210  0.863734  \n",
       "57  0.751161  0.876178  \n",
       "58  0.754432  0.875442  \n",
       "59  0.762263  0.886913  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture tests\n",
    "\n",
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Binary Err Rate</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>90</td>\n",
       "      <td>0.229987</td>\n",
       "      <td>0.770013</td>\n",
       "      <td>0.603391</td>\n",
       "      <td>0.759069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>90</td>\n",
       "      <td>0.232309</td>\n",
       "      <td>0.767691</td>\n",
       "      <td>0.602037</td>\n",
       "      <td>0.766254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.161322</td>\n",
       "      <td>0.838678</td>\n",
       "      <td>0.760954</td>\n",
       "      <td>0.885796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.844538</td>\n",
       "      <td>0.765435</td>\n",
       "      <td>0.893552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.154578</td>\n",
       "      <td>0.845422</td>\n",
       "      <td>0.768733</td>\n",
       "      <td>0.893256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Par-Robust [train budget=120]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.156457</td>\n",
       "      <td>0.843543</td>\n",
       "      <td>0.764435</td>\n",
       "      <td>0.889587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Adv-Boosting [train budget=30]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.414640</td>\n",
       "      <td>0.585360</td>\n",
       "      <td>0.475844</td>\n",
       "      <td>0.515379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Adv-Boosting [train budget=60]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.301968</td>\n",
       "      <td>0.698032</td>\n",
       "      <td>0.531410</td>\n",
       "      <td>0.542887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Adv-Boosting [train budget=90]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.296329</td>\n",
       "      <td>0.703671</td>\n",
       "      <td>0.541752</td>\n",
       "      <td>0.580960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Adv-Boosting [train budget=120]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.212406</td>\n",
       "      <td>0.787594</td>\n",
       "      <td>0.693501</td>\n",
       "      <td>0.793357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.373176</td>\n",
       "      <td>0.626824</td>\n",
       "      <td>0.500587</td>\n",
       "      <td>0.284250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Std-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.432110</td>\n",
       "      <td>0.567890</td>\n",
       "      <td>0.461627</td>\n",
       "      <td>0.264057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.239828</td>\n",
       "      <td>0.760172</td>\n",
       "      <td>0.595257</td>\n",
       "      <td>0.725155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Rf-Gbdt</td>\n",
       "      <td>120</td>\n",
       "      <td>0.244693</td>\n",
       "      <td>0.755307</td>\n",
       "      <td>0.591887</td>\n",
       "      <td>0.731149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Par-Robust [train budget=30]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.172379</td>\n",
       "      <td>0.827621</td>\n",
       "      <td>0.749210</td>\n",
       "      <td>0.863734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Par-Robust [train budget=60]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.168620</td>\n",
       "      <td>0.831380</td>\n",
       "      <td>0.751161</td>\n",
       "      <td>0.876178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Par-Robust [train budget=90]</td>\n",
       "      <td>120</td>\n",
       "      <td>0.167846</td>\n",
       "      <td>0.832154</td>\n",
       "      <td>0.754432</td>\n",
       "      <td>0.875442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model Budget  Binary Err Rate  F1 Micro  \\\n",
       "42                          Rf-Gbdt     90         0.229987  0.770013   \n",
       "43                          Rf-Gbdt     90         0.232309  0.767691   \n",
       "44     Par-Robust [train budget=30]     90         0.161322  0.838678   \n",
       "45     Par-Robust [train budget=60]     90         0.155462  0.844538   \n",
       "46     Par-Robust [train budget=90]     90         0.154578  0.845422   \n",
       "47    Par-Robust [train budget=120]     90         0.156457  0.843543   \n",
       "48   Adv-Boosting [train budget=30]    120         0.414640  0.585360   \n",
       "49   Adv-Boosting [train budget=60]    120         0.301968  0.698032   \n",
       "50   Adv-Boosting [train budget=90]    120         0.296329  0.703671   \n",
       "51  Adv-Boosting [train budget=120]    120         0.212406  0.787594   \n",
       "52                         Std-Gbdt    120         0.373176  0.626824   \n",
       "53                         Std-Gbdt    120         0.432110  0.567890   \n",
       "54                          Rf-Gbdt    120         0.239828  0.760172   \n",
       "55                          Rf-Gbdt    120         0.244693  0.755307   \n",
       "56     Par-Robust [train budget=30]    120         0.172379  0.827621   \n",
       "57     Par-Robust [train budget=60]    120         0.168620  0.831380   \n",
       "58     Par-Robust [train budget=90]    120         0.167846  0.832154   \n",
       "\n",
       "    F1 Macro   Roc Auc  \n",
       "42  0.603391  0.759069  \n",
       "43  0.602037  0.766254  \n",
       "44  0.760954  0.885796  \n",
       "45  0.765435  0.893552  \n",
       "46  0.768733  0.893256  \n",
       "47  0.764435  0.889587  \n",
       "48  0.475844  0.515379  \n",
       "49  0.531410  0.542887  \n",
       "50  0.541752  0.580960  \n",
       "51  0.693501  0.793357  \n",
       "52  0.500587  0.284250  \n",
       "53  0.461627  0.264057  \n",
       "54  0.595257  0.725155  \n",
       "55  0.591887  0.731149  \n",
       "56  0.749210  0.863734  \n",
       "57  0.751161  0.876178  \n",
       "58  0.754432  0.875442  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df[42:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WINE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "TRAINING_BUDGETS= [20, 100] #,30,40,50,60] \n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 lucchese lucchese 3421316 Jun 21 17:52 ../out/models/wine/icml2019_wine_B100_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 3168548 Jun 21 17:40 ../out/models/wine/icml2019_wine_B80_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2103202 Jun 21 17:28 ../out/models/wine/icml2019_wine_B60_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2175566 Jun 21 17:16 ../out/models/wine/icml2019_wine_B40_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2939045 Jun 21 17:04 ../out/models/wine/icml2019_wine_B20_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese    6161 Jun 21 15:12 ../out/models/wine/icml2019_wine_B120_T1_D4_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese    2296 Jun 21 14:58 ../out/models/wine/icml2019_wine_B120_T1_D1_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese   32479 Jun 21 11:38 ../out/models/wine/icml2019_wine_B120_T1_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese   30943 Jun 21 11:22 ../out/models/wine/par-robust_wine_B120_T1_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese    2741 Jun 21 11:10 ../out/models/wine/par-robust_wine_B120_T1_D2_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese    2741 Jun 21 11:10 ../out/models/wine/icml2019_wine_B120_T1_D2_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese    2741 Jun 21 11:07 ../out/models/wine/par-robust_wine_B80_T1_D2_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese   29078 Jun 21 11:05 ../out/models/wine/par-robust_wine_B20_T1_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  658441 Jun 21 10:30 ../out/models/wine/adv-boosting_wine_B120_T100_S0050_L256_R100.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  646122 Jun 21 10:22 ../out/models/wine/adv-boosting_wine_B100_T100_S0050_L256_R100.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2833058 Jun 21 09:47 ../out/models/wine/par-robust_wine_B120_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2832025 Jun 21 09:32 ../out/models/wine/par-robust_wine_B100_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2783163 Jun 20 17:56 ../out/models/wine/par-robust_wine_B80_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2851620 Jun 20 17:42 ../out/models/wine/par-robust_wine_B60_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2815294 Jun 20 17:29 ../out/models/wine/par-robust_wine_B40_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2672392 Jun 20 17:14 ../out/models/wine/par-robust_wine_B20_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  624038 Jun 20 16:55 ../out/models/wine/adv-boosting_wine_B80_T100_S0050_L256_R100.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  616505 Jun 20 16:50 ../out/models/wine/adv-boosting_wine_B60_T100_S0050_L256_R99.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  668506 Jun 20 16:46 ../out/models/wine/adv-boosting_wine_B40_T100_S0050_L256_R100.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  612998 Jun 20 16:42 ../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R99.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  610613 Jun 20 16:34 ../out/models/wine/rf-gbdt_wine_T100_S0050_L256_R68.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  475663 Jun 20 16:33 ../out/models/wine/std-gbdt_wine_T100_S0050_L256_R100.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2804657 Jun 15 13:34 ../out/models/wine/par-robust_wine_B30_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese 2816870 Jun 15 13:20 ../out/models/wine/par-robust_wine_B10_T100_D8_I20.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  476150 Jun 15 12:59 ../out/models/wine/adv-boosting_wine_B60_T100_S0050_L256_R65.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  618335 Jun 15 12:36 ../out/models/wine/adv-boosting_wine_B40_T100_S0050_L256_R97.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  623252 Jun 15 12:27 ../out/models/wine/adv-boosting_wine_B30_T100_S0050_L256_R98.model\r\n",
      "-rw-rw-r-- 1 lucchese lucchese  644372 Jun 15 12:22 ../out/models/wine/adv-boosting_wine_B10_T100_S0050_L256_R100.model\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lt ../out/models/wine/*.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "adv_models = [  \"../out/models/wine/adv-boosting_wine_B20_T100_S0050_L256_R99.model\",\n",
    "                \"../out/models/wine/adv-boosting_wine_B40_T100_S0050_L256_R100.model\",\n",
    "                \"../out/models/wine/adv-boosting_wine_B60_T100_S0050_L256_R99.model\",\n",
    "                \"../out/models/wine/adv-boosting_wine_B80_T100_S0050_L256_R100.model\",\n",
    "                \"../out/models/wine/adv-boosting_wine_B100_T100_S0050_L256_R100.model\",\n",
    "                \"../out/models/wine/adv-boosting_wine_B120_T100_S0050_L256_R100.model\"\n",
    "             ]\n",
    "\n",
    "gdbt_models = [\"../out/models/wine/std-gbdt_wine_T100_S0050_L256_R100.model\" ]\n",
    "\n",
    "#red_models = [\"../out/models/wine/red-gbdt_wine_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "rf_models = [\"../out/models/wine/rf-gbdt_wine_T100_S0050_L256_R68.model\"]\n",
    "\n",
    "robust_models = [   \"../out/models/wine/par-robust_wine_B20_T100_D8_I20.model\",\n",
    "                    \"../out/models/wine/par-robust_wine_B40_T100_D8_I20.model\",\n",
    "                    \"../out/models/wine/par-robust_wine_B60_T100_D8_I20.model\",\n",
    "                    \"../out/models/wine/par-robust_wine_B80_T100_D8_I20.model\",\n",
    "                    \"../out/models/wine/par-robust_wine_B100_T100_D8_I20.model\",\n",
    "                    \"../out/models/wine/par-robust_wine_B120_T100_D8_I20.model\"]\n",
    "\n",
    "icml_models = [\"../out/models/wine/icml2019_wine_B20_T100_D8_I20.model\",\n",
    "               \"../out/models/wine/icml2019_wine_B100_T100_D8_I20.model\"\n",
    "              ]\n",
    "\n",
    "test_models = adv_models + gdbt_models + rf_models + robust_models\n",
    "\n",
    "test_models = icml_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/train.csv.bz2\n",
      "Loading: ../data/wine/valid.csv.bz2\n",
      "Loading: ../data/wine/test.csv.bz2\n",
      "Train/Valid/Test sizes: (4547, 13) (650, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (3898, 13) (1299, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "### Evaluating Models: ['../out/models/wine/icml2019_wine_B20_T100_D8_I20.model', '../out/models/wine/icml2019_wine_B100_T100_D8_I20.model']\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None, feature_blacklist={},\n",
      "          max_depth=8, max_features=0.8, max_samples=0.8,\n",
      "          min_instances_per_node=20, replace_features=False,\n",
      "          replace_samples=False, seed=0, split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n",
      "Icml2019 [train budget=20] learning - eval_binary_err_rate = 0.24538\n",
      "Icml2019 [train budget=20] learning - eval_f1_micro = 0.75462\n",
      "Icml2019 [train budget=20] learning - eval_f1_macro = 0.73311\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-d288f5c9747d>\u001b[0m in \u001b[0;36meval_all_models\u001b[0;34m(eval_metrics, models_dir, test, model_filenames)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                         \u001b[0mextract_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                         test) for mf in model_filenames],\n\u001b[0m\u001b[1;32m     18\u001b[0m                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                    \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-d288f5c9747d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                         \u001b[0mextract_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                         test) for mf in model_filenames],\n\u001b[0m\u001b[1;32m     18\u001b[0m                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                    \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5b0a1449f968>\u001b[0m in \u001b[0;36meval_learned_models\u001b[0;34m(eval_metrics, model, model_type, test, test_groups, budget)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meval_metric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         print(\"{} learning - {} = {:.5f}\"\n\u001b[1;32m     19\u001b[0m                   .format(model_type, eval_metric.__name__, res))\n",
      "\u001b[0;32m<ipython-input-11-7d668a47171a>\u001b[0m in \u001b[0;36meval_roc_auc\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_roc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 328\u001b[0;31m                                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \"\"\"\n\u001b[1;32m    617\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 618\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B20.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B20.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B20.atks.bz2\n",
      "Train/Valid/Test sizes: (21361, 14) (2933, 14) (6176, 14)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (18278, 14) (6016, 14) (6176, 14)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.atks.bz2\n",
      "Pre-processing original files...\n",
      "Loading: ../data/wine/attacks/train_B100.atks.bz2\n",
      "Loading: ../data/wine/attacks/valid_B100.atks.bz2\n",
      "Loading: ../data/wine/attacks/test_B100.atks.bz2\n",
      "Train/Valid/Test sizes: (1465269, 14) (196232, 14) (430155, 14)\n",
      "Train/Valid/Test split: 0.70 0.09 0.21\n",
      "   ... with instance ids\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (1253941, 14) (407560, 14) (430155, 14)\n",
      "Train/Valid/Test split: 0.60 0.19 0.21\n",
      "Saving processed files *.atks.bz2\n",
      "### Evaluating Models: ['../out/models/wine/icml2019_wine_B20_T100_D8_I20.model', '../out/models/wine/icml2019_wine_B100_T100_D8_I20.model']\n",
      "LightGBM loading exception\n",
      "BaggingClassifier(base_estimator=RobustDecisionTree(affine=None, attacker=None, feature_blacklist={},\n",
      "          max_depth=8, max_features=0.8, max_samples=0.8,\n",
      "          min_instances_per_node=20, replace_features=False,\n",
      "          replace_samples=False, seed=0, split_optimizer=None, tree_id=0),\n",
      "         bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=100, n_jobs=None, oob_score=False,\n",
      "         random_state=None, verbose=0, warm_start=False)\n",
      "BaggingClassifier\n",
      "Icml2019 [train budget=20] learning - eval_binary_err_rate = 0.27769\n",
      "Icml2019 [train budget=20] learning - eval_f1_micro = 0.72231\n",
      "Icml2019 [train budget=20] learning - eval_f1_macro = 0.69769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucchese/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8ba6b6e6ae6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n\u001b[0;32m----> 5\u001b[0;31m                                            test_models)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m overall_df = pd.concat([eval_std_df, eval_att_df], \n",
      "\u001b[0;32m<ipython-input-24-97f42efefee8>\u001b[0m in \u001b[0;36meval_all_models_under_attack\u001b[0;34m(eval_metrics, models_dir, att_tests, budgets, model_filenames)\u001b[0m\n\u001b[1;32m      6\u001b[0m         eval_att_dfs.append(\n\u001b[1;32m      7\u001b[0m             eval_all_models_under_attack_budget(eval_metrics, models_dir, att_tests[b][4], att_tests[b][5], \n\u001b[0;32m----> 8\u001b[0;31m                                                 b, model_filenames))\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-4ee08d4e5170>\u001b[0m in \u001b[0;36meval_all_models_under_attack_budget\u001b[0;34m(eval_metrics, models_dir, test, test_groups, budget, model_filenames)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                         \u001b[0mtest_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                         \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                        ) for mf in model_filenames],\n\u001b[0m\u001b[1;32m     21\u001b[0m                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                    \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-4ee08d4e5170>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                         \u001b[0mtest_groups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                         \u001b[0mbudget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                        ) for mf in model_filenames],\n\u001b[0m\u001b[1;32m     21\u001b[0m                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                    \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5b0a1449f968>\u001b[0m in \u001b[0;36meval_learned_models\u001b[0;34m(eval_metrics, model, model_type, test, test_groups, budget)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meval_metric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         print(\"{} learning - {} = {:.5f}\"\n\u001b[1;32m     19\u001b[0m                   .format(model_type, eval_metric.__name__, res))\n",
      "\u001b[0;32m<ipython-input-11-7d668a47171a>\u001b[0m in \u001b[0;36meval_roc_auc\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_roc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 328\u001b[0;31m                                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \"\"\"\n\u001b[1;32m    617\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 618\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"spam\"\n",
    "TRAINING_BUDGETS= [30, 60] \n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "#adv_models = [\n",
    "#              \"../out/models/spam/adv-boosting_spam_B30_T100_S0050_L256_R100.model\",\n",
    "              \n",
    "#             \"../out/models/spam/adv-boosting_spam_B60_T100_S0050_L256_R85.model\"\n",
    "#             ]\n",
    "#\n",
    "#gdbt_models = [\n",
    "#               \"../out/models/spam/std-gbdt_spam_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "#red_models = [\n",
    "#             \"../out/models/spam/red-gbdt_spam_T100_S0050_L256_R100.model\"]\n",
    "\n",
    "#rf_models = [\n",
    "#             \"../out/models/spam/rf-gbdt_spam_T100_S0050_L256_R98.model\"]\n",
    "\n",
    "robust_models = [\n",
    "                \"../out/models/spam/par-robust_spam_B30_T100_D8_I20.model\"]\n",
    "\n",
    "test_models = robust_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"credit\"\n",
    "TRAINING_BUDGETS= [10,30,40,60] \n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "adv_models = [\"../out/models/credit/adv-boosting_credit_B10_T100_S0050_L256_R56.model\",\n",
    "              \"../out/models/credit/adv-boosting_credit_B30_T100_S0050_L256_R40.model\",\n",
    "              \"../out/models/credit/adv-boosting_credit_B40_T100_S0050_L256_R56.model\",              \n",
    "              \"../out/models/credit/adv-boosting_credit_B60_T100_S0050_L256_R50.model\"\n",
    "             ]\n",
    "\n",
    "gdbt_models = [\"../out/models/credit/std-gbdt_credit_T100_S0050_L256_R81.model\"]\n",
    "\n",
    "#red_models = [\"../out/models/credit/red-gbdt_credit_T100_S0050_L256_R39.model\"]\n",
    "\n",
    "rf_models = [\"../out/models/credit/rf-gbdt_credit_T100_S0050_L256_R37.model\"]\n",
    "\n",
    "robust_models = [\"../out/models/credit/par-robust_credit_B10_T100_D8_I20.model\",\n",
    "                 \"../out/models/credit/par-robust_credit_B30_T100_D8_I20.model\",\n",
    "                 \"../out/models/credit/par-robust_credit_B40_T100_D8_I20.model\",\n",
    "                 \"../out/models/credit/par-robust_credit_B60_T100_D8_I20.model\"\n",
    "                ]\n",
    "\n",
    "test_models =  adv_models +gdbt_models + rf_models + robust_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEBSITES Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"websites\"\n",
    "TRAINING_BUDGETS= [10,30] \n",
    "\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "OUTPUT_FILENAME=\"../out/results/{}\".format(DATASET_NAME)\n",
    "\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "TRAINING_FILENAME_ATT=ATK_DIR + \"/\" + \"train_B{}.atks.bz2\"\n",
    "\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "VALIDATION_FILENAME_ATT=ATK_DIR + \"/\" + \"valid_B{}.atks.bz2\"\n",
    "\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "TEST_FILENAME_ATT=ATK_DIR + \"/\" + \"test_B{}.atks.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "adv_models = [\"../out/models/websites/adv-boosting_websites_B10_T100_S0050_L256_R8.model\",\n",
    "              \"../out/models/websites/adv-boosting_websites_B30_T100_S0050_L256_R7.model\"]\n",
    "\n",
    "gdbt_models = [\"../out/models/websites/std-gbdt_websites_T100_S0050_L256_R6.model\"]\n",
    "\n",
    "red_models = [\"../out/models/websites/red-gbdt_websites_T100_S0050_L256_R39.model\"]\n",
    "\n",
    "rf_models = [\"../out/models/websites/rf-gbdt_websites_T100_S0050_L256_R1.model\"]\n",
    "\n",
    "robust_models = [\"../out/models/websites/par-robust_websites_B0_T100_D8_I20.model\",\n",
    "                \"../out/models/websites/par-robust_websites_B60_T100_D8_I20.model\",\n",
    "                \"../out/models/websites/par-robust_websites_B30_T100_D8_I20.model\"]\n",
    "\n",
    "test_models = adv_models + gdbt_models + rf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without attacks\n",
    "TRAIN, VALID, TEST = load_atk_train_valid_test(TRAINING_FILENAME, VALIDATION_FILENAME, TEST_FILENAME)\n",
    "\n",
    "eval_std_df = eval_all_models(EVAL_METRICS, MODELS_DIR, TEST, test_models)\n",
    "eval_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With attacks\n",
    "att_datasets = load_attacked_datasets(TRAINING_BUDGETS)\n",
    "\n",
    "eval_att_df = eval_all_models_under_attack(EVAL_METRICS, MODELS_DIR, att_datasets, TRAINING_BUDGETS,\n",
    "                                           test_models)\n",
    "\n",
    "overall_df = pd.concat([eval_std_df, eval_att_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)\n",
    "overall_df.to_csv(OUTPUT_FILENAME + \".csv\", sep=\",\", index=False)\n",
    "\n",
    "overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune Robust models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_pruned_models = [\"../out/models/census/robust_census_B0_T100_D8_I20_20.tmp\"]\n",
    "\n",
    "for m in to_be_pruned_models:\n",
    "    prune_trained_model(m, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune LGBM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_lgbm(in_file, out_file, n):\n",
    "    model = lightgbm.Booster(model_file=in_file)\n",
    "    model.save_model(out_file, num_iteration=n)\n",
    "    print (\"saved.\")\n",
    "    \n",
    "prune_lgbm(\"../out/models/wine/std-gbdt_wine_T200_S0050_L24_R199.model\",\n",
    "           \"../out/models/wine/std-gbdt_wine_T200_S0050_L24_R199.T10.model\",\n",
    "           10)\n",
    "# prune_lgbm(\"../out/models/census/adv-boosting_census_B60_T200_S0050_L24_R200.model\",\n",
    "#            \"../out/models/census/adv-boosting_census_B60_T200_S0050_L24_R200.T20.model\",\n",
    "#            20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../out/models/wine/par-robust_wine_B0_T100_D8_I20.model\", 'rb') as f:\n",
    "    model = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pretty_print(node, out=sys.stdout, tabs=''):\n",
    "\n",
    "    leaf_txt = \"{}Prediction: {}; Score: {:.5f}; N. instances: {}; Loss: {:.5f}\".format(tabs,\n",
    "                                                                                        node.get_node_prediction()[\n",
    "                                                                                            0],\n",
    "                                                                                        node.get_node_prediction()[\n",
    "                                                                                            1],\n",
    "                                                                                        node.values,\n",
    "                                                                                        node.loss_value)\n",
    "    internal_node_txt = \"{}Feature ID: {}; Threshold: {}; N. instances: {}\".format(tabs,\n",
    "                                                                                   node.best_split_feature_id,\n",
    "                                                                                   node.best_split_feature_value,\n",
    "                                                                                   node.values\n",
    "                                                                                   )\n",
    "\n",
    "    if node.is_leaf():  # base case\n",
    "        out.write(leaf_txt + \"\\n\")\n",
    "    else:  # recursive case\n",
    "        out.write(internal_node_txt + \"\\n\")\n",
    "        node.left.pretty_print(out, tabs + \"\\t\")\n",
    "        node.right.pretty_print(out, tabs + \"\\t\")\n",
    "\n",
    "pretty_print(model.estimators_[0].root )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(model.estimators_[1].root )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fx_imp(model, colnames):\n",
    "    fx_uses = model.feature_importance(importance_type='split')\n",
    "    fx_gain = model.feature_importance(importance_type='gain')\n",
    "\n",
    "    for i,f in enumerate(np.argsort(fx_gain)[::-1]):\n",
    "        print (\"{:2d} {:20s} {:.3f} {:4d}\".format(i, colnames[f], fx_gain[f], fx_uses[f]))\n",
    "\n",
    "print(\"-- GDBT --\")    \n",
    "#gbdt = lightgbm.Booster(model_file=\"../out/models/census/std-gbdt_census_T100_S0050_L24_R100.model\")\n",
    "gbdt = lightgbm.Booster(model_file=\"../out/models/credit/std-gbdt_credit_T100_S0050_L256_R37.model\")\n",
    "print(gbdt.num_trees())\n",
    "print_fx_imp(gbdt, TRAIN.columns)\n",
    "\n",
    "# print(\" -- Reduced GDBT --\")    \n",
    "# #redf = lightgbm.Booster(model_file=\"../out/models/census/red-gbdt_census_T100_S0050_L24_R98.model\")\n",
    "# redf = lightgbm.Booster(model_file=\"../out/models/credit/red-gbdt_credit_T100_S0050_L256_R37.model\")\n",
    "# print(redf.num_trees())\n",
    "# print_fx_imp(redf, TRAIN.drop(columns=[\"workclass\", \n",
    "#                                        \"marital_status\", \n",
    "#                                        \"occupation\", \n",
    "#                                        \"education_num\", \n",
    "#                                        \"hours_per_week\", \n",
    "#                                        \"capital_gain\"\n",
    "#                                       ]).columns) \n",
    "\n",
    "\n",
    "# print(\"-- Adv. Boosting --\")    \n",
    "# advb = lightgbm.Booster(model_file=\"../out/models/census/adv-boosting_census_B30_T100_S0050_L24_R100.model\")\n",
    "# print(advb.num_trees())\n",
    "# print_fx_imp(advb, TRAIN.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN[['PAY_0', 'BILL_AMT1', 'PAY_AMT3', 'PAY_AMT2', 'PAY_AMT6', 'PAY_2', 'LIMIT_BAL', 'AGE']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = 40\n",
    "eval_learned_models(lightgbm.Booster(model_file=\"../out/models/wine2/red-gbdt_wine2_T500_S0050_L24_R281.model\"), \n",
    "                                        extract_model_name(\"../out/models/wine2/red-gbdt_wine2_T500_S0050_L24_R281.model\"), \n",
    "                                        att_datasets[bb][4].drop(columns=[\"alcohol\", \"residual_sugar\", \"volatile_acidity\"]), \n",
    "                                        att_datasets[bb][5], \n",
    "                                        budget=bb\n",
    "                                       ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../out/models/census/par-robust_census_B0_T100_D8_I20.model | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git commit -am \"calza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
