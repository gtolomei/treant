{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import pickle\n",
    "import json\n",
    "import functools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nilib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gradient_boosting_baseline(train_file, valid_file, test_file, output_model_file, drop_cols=None):\n",
    "    \n",
    "    exp = pd.DataFrame(columns=['num_trees', 'learning_rate', 'num_leaves', 'best_round', 'metric', 'filename'])\n",
    "    \n",
    "    # load train/valid/test\n",
    "    train, valid, test, cat_fx = load_atk_train_valid_test(train_file, valid_file, test_file)\n",
    "    \n",
    "    assert \"instance_id\" not in train.columns.values, \"Wrong training set file for GBDT\"\n",
    "\n",
    "    # dropping some of the columns\n",
    "    if drop_cols is not None:\n",
    "        print (\"Dropping columns:\", drop_cols)\n",
    "        train.drop(columns=drop_cols, inplace=True)\n",
    "        valid.drop(columns=drop_cols, inplace=True)\n",
    "        test.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "    \n",
    "    # get index of categorical features \n",
    "    cat_fx = np.where(train.columns.isin(cat_fx))[0]\n",
    "    cat_fx = list([int(x) for x in cat_fx])  \n",
    "    print(\"CatFX:\", train.columns.values[cat_fx])\n",
    "    \n",
    "\n",
    "    for num_trees in [100]:\n",
    "        for learning_rate in [0.05]: #[0.01, 0.05]:\n",
    "            for num_leaves in [24]: #[16, 24]:\n",
    "                # datasets\n",
    "                lgbm_train = lightgbm.Dataset(data=train.iloc[:,:-1].values, \n",
    "                                              label=train.iloc[:,-1].values,\n",
    "                                              categorical_feature = cat_fx)\n",
    "\n",
    "                lgbm_valid = lightgbm.Dataset(data=valid.iloc[:,:-1].values, \n",
    "                                              label=valid.iloc[:,-1].values,\n",
    "                                              categorical_feature = cat_fx)\n",
    "\n",
    "                # run train\n",
    "                lgbm_params = { 'learning_rate': learning_rate, \n",
    "                                'num_leaves': num_leaves,\n",
    "                                'objective': 'regression'\n",
    "                              } \n",
    "                lgbm_info = {}\n",
    "                lgbm_model = lightgbm.train(lgbm_params, lgbm_train, \n",
    "                                            num_boost_round = num_trees,\n",
    "#                                             fobj            = optimize_log_loss, \n",
    "#                                             feval           = avg_log_loss,\n",
    "                                            evals_result    = lgbm_info,\n",
    "                                            valid_sets      = [lgbm_train, lgbm_valid], \n",
    "                                            valid_names     = ['train', 'valid'],\n",
    "                                            verbose_eval    = 50)\n",
    "                \n",
    "                best_valid_iter = np.argmin(lgbm_info['valid']['l2'])\n",
    "                \n",
    "                model_file_name = \"{:s}_T{:d}_S{:04d}_L{:d}_R{:d}.model\".format(output_model_file,\n",
    "                                                                            num_trees,\n",
    "                                                                            int(learning_rate*1000),\n",
    "                                                                            num_leaves,\n",
    "                                                                            best_valid_iter + 1\n",
    "                                                                           )\n",
    "                \n",
    "                # update experimental results\n",
    "                exp = exp.append({'num_trees': num_trees, \n",
    "                                  'learning_rate':learning_rate,\n",
    "                                  'num_leaves':num_leaves, \n",
    "                                  'best_round':best_valid_iter+1, \n",
    "                                  'metric':lgbm_info['valid']['l2'][best_valid_iter],\n",
    "                                  'filename':model_file_name},\n",
    "                                 ignore_index=True)\n",
    "                \n",
    "        \n",
    "                lgbm_model.save_model(model_file_name)\n",
    "                print(\"Model saved to\", model_file_name)\n",
    "\n",
    "    \n",
    "    return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WINE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"wine\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/train.csv.bz2\n",
      "Loading: ../data/wine/valid.csv.bz2\n",
      "Loading: ../data/wine/test.csv.bz2\n",
      "Train/Valid/Test sizes: (4547, 13) (650, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (3898, 13) (1299, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "CatFX: []\n",
      "[50]\ttrain's l2: 0.387329\tvalid's l2: 0.455517\n",
      "[100]\ttrain's l2: 0.312616\tvalid's l2: 0.427861\n",
      "Model saved to ../out/models/wine/std-gbdt_wine_T100_S0050_L24_R100.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05         24        100  0.427861   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/std-gbdt_wine_T100_S0050_L2...  \n",
      "best model is: ../out/models/wine/std-gbdt_wine_T100_S0050_L24_R100.model\n"
     ]
    }
   ],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/wine/train.csv.bz2\n",
      "Loading: ../data/wine/valid.csv.bz2\n",
      "Loading: ../data/wine/test.csv.bz2\n",
      "Train/Valid/Test sizes: (4547, 13) (650, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.70 0.10 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (3898, 13) (1299, 13) (1300, 13)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "Dropping columns: ['alcohol', 'residual_sugar', 'volatile_acidity']\n",
      "CatFX: []\n",
      "[50]\ttrain's l2: 0.433816\tvalid's l2: 0.513682\n",
      "[100]\ttrain's l2: 0.360147\tvalid's l2: 0.486498\n",
      "Model saved to ../out/models/wine/red-gbdt_wine_T100_S0050_L24_R100.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05         24        100  0.486498   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/wine/red-gbdt_wine_T100_S0050_L2...  \n",
      "best model is: ../out/models/wine/red-gbdt_wine_T100_S0050_L24_R100.model\n"
     ]
    }
   ],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=[\"alcohol\", \"residual_sugar\", \"volatile_acidity\"]\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENSUS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"census\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=['workclass','marital_status',\n",
    "                                                          'occupation', 'education_num',\n",
    "                                                          'hours_per_week','capital_gain' ]\n",
    "                                              )\n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME=\"spam\"\n",
    "DATASET_DIR=\"../data/{}\".format(DATASET_NAME)\n",
    "ATK_DIR=DATASET_DIR + \"/attacks\"\n",
    "MODELS_DIR=\"../out/models/{}\".format(DATASET_NAME)\n",
    "TRAINING_FILENAME=DATASET_DIR + \"/\" + \"train.csv.bz2\"\n",
    "VALIDATION_FILENAME=DATASET_DIR + \"/\" + \"valid.csv.bz2\"\n",
    "TEST_FILENAME=DATASET_DIR + \"/\" + \"test.csv.bz2\"\n",
    "MODEL_FILENAME=MODELS_DIR + \"/std-gbdt_{}\".format(DATASET_NAME)\n",
    "RED_MODEL_FILENAME=MODELS_DIR + \"/red-gbdt_{}\".format(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/spam/train.csv.bz2\n",
      "Loading: ../data/spam/valid.csv.bz2\n",
      "Loading: ../data/spam/test.csv.bz2\n",
      "Train/Valid/Test sizes: (2760, 58) (921, 58) (920, 58)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (2760, 58) (920, 58) (921, 58)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "CatFX: []\n",
      "[50]\ttrain's l2: 0.0348443\tvalid's l2: 0.0558493\n",
      "[100]\ttrain's l2: 0.0233714\tvalid's l2: 0.0484396\n",
      "Model saved to ../out/models/spam/std-gbdt_spam_T100_S0050_L24_R99.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05         24         99  0.048388   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/spam/std-gbdt_spam_T100_S0050_L2...  \n",
      "best model is: ../out/models/spam/std-gbdt_spam_T100_S0050_L24_R99.model\n"
     ]
    }
   ],
   "source": [
    "# FULL GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               MODEL_FILENAME\n",
    "                                              )  \n",
    "\n",
    "experiments.to_csv(MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/spam/train.csv.bz2\n",
      "Loading: ../data/spam/valid.csv.bz2\n",
      "Loading: ../data/spam/test.csv.bz2\n",
      "Train/Valid/Test sizes: (2760, 58) (921, 58) (920, 58)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (2760, 58) (920, 58) (921, 58)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "Dropping columns: ['char_freq_!', 'word_freq_remove', 'char_freq_$', 'capital_run_length_average', 'capital_run_length_total', 'word_freq_hp']\n",
      "CatFX: []\n",
      "[50]\ttrain's l2: 0.0434418\tvalid's l2: 0.0624735\n",
      "[100]\ttrain's l2: 0.0310334\tvalid's l2: 0.0554811\n",
      "Model saved to ../out/models/spam/red-gbdt_spam_T100_S0050_L24_R92.model\n",
      "  num_trees  learning_rate num_leaves best_round    metric  \\\n",
      "0       100           0.05         24         92  0.055465   \n",
      "\n",
      "                                            filename  \n",
      "0  ../out/models/spam/red-gbdt_spam_T100_S0050_L2...  \n",
      "best model is: ../out/models/spam/red-gbdt_spam_T100_S0050_L24_R92.model\n"
     ]
    }
   ],
   "source": [
    "# REDUCED GDBT\n",
    "\n",
    "experiments = train_gradient_boosting_baseline(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME,\n",
    "                                               RED_MODEL_FILENAME,\n",
    "                                               drop_cols=['char_freq_!', 'word_freq_remove',\n",
    "                                                          'char_freq_$', 'capital_run_length_average',\n",
    "                                                          'capital_run_length_total', 'word_freq_hp' ]\n",
    "                                              )\n",
    "\n",
    "experiments.to_csv(RED_MODEL_FILENAME + \".csv\", index=False)\n",
    "\n",
    "print(experiments)\n",
    "print ('best model is:', experiments.sort_values('metric').iloc[0]['filename'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/spam/train.csv.bz2\n",
      "Loading: ../data/spam/valid.csv.bz2\n",
      "Loading: ../data/spam/test.csv.bz2\n",
      "Train/Valid/Test sizes: (2760, 58) (921, 58) (920, 58)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "CatFX: []\n",
      "Train/Valid/Test sizes: (2760, 58) (920, 58) (921, 58)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "Index(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
      "       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n",
      "       'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
      "       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n",
      "       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
      "       'word_freq_business', 'word_freq_email', 'word_freq_you',\n",
      "       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n",
      "       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n",
      "       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
      "       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
      "       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n",
      "       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n",
      "       'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
      "       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
      "       'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n",
      "       'char_freq_$', 'char_freq_#', 'capital_run_length_average',\n",
      "       'capital_run_length_longest', 'capital_run_length_total', 'spam'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "TRAIN, _, _, _ = load_atk_train_valid_test(TRAINING_FILENAME, \n",
    "                                               VALIDATION_FILENAME,\n",
    "                                               TEST_FILENAME)\n",
    "print (TRAIN.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    417.000000\n",
       "mean       3.370048\n",
       "std        3.132073\n",
       "min        1.000000\n",
       "25%        1.610000\n",
       "50%        2.320000\n",
       "75%        3.520000\n",
       "max       20.830000\n",
       "Name: word_freq_hp, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN[TRAIN['word_freq_hp']>=1]['word_freq_hp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- GDBT --\n",
      "100\n",
      " 0 char_freq_!          1675.403  179\n",
      " 1 word_freq_remove     898.772   68\n",
      " 2 char_freq_$          884.417   72\n",
      " 3 capital_run_length_average 417.196  172\n",
      " 4 capital_run_length_total 340.651  163\n",
      " 5 word_freq_hp         336.482  104\n",
      " 6 word_freq_free       180.480   90\n",
      " 7 word_freq_money      175.816   25\n",
      " 8 capital_run_length_longest 171.871  158\n",
      " 9 word_freq_your       158.627  106\n",
      "10 word_freq_our        151.961  110\n",
      "11 word_freq_edu        128.443   74\n",
      "12 word_freq_george     92.992   75\n",
      "13 word_freq_you        72.602  124\n",
      "14 word_freq_business   64.007   47\n",
      "15 word_freq_000        41.320   34\n",
      "16 word_freq_re         32.453   54\n",
      "17 char_freq_(          31.598   76\n",
      "18 word_freq_will       26.902   70\n",
      "19 word_freq_1999       26.525   35\n",
      "20 word_freq_hpl        20.583    6\n",
      "21 word_freq_internet   20.143   23\n",
      "22 word_freq_meeting    18.177   39\n",
      "23 word_freq_technology 13.427   16\n",
      "24 char_freq_#          13.078   27\n",
      "25 word_freq_over       12.347   44\n",
      "26 word_freq_font       12.131   18\n",
      "27 word_freq_email      8.869   31\n",
      "28 word_freq_report     7.253   17\n",
      "29 word_freq_all        7.104   20\n",
      "30 word_freq_mail       6.733   27\n",
      "31 char_freq_;          6.293   28\n",
      "32 word_freq_credit     5.472   23\n",
      "33 word_freq_pm         5.030   16\n",
      "34 word_freq_650        4.456   13\n",
      "35 word_freq_address    4.314   18\n",
      "36 word_freq_receive    3.982   20\n",
      "37 char_freq_[          3.809    7\n",
      "38 word_freq_people     3.258    5\n",
      "39 word_freq_85         2.734    8\n",
      "40 word_freq_labs       2.278    9\n",
      "41 word_freq_data       1.682    7\n",
      "42 word_freq_conference 1.411    9\n",
      "43 word_freq_order      1.170    7\n",
      "44 word_freq_project    0.795    7\n",
      "45 word_freq_make       0.730    2\n",
      "46 word_freq_addresses  0.663    3\n",
      "47 word_freq_lab        0.636    4\n",
      "48 word_freq_cs         0.490    5\n",
      "49 word_freq_telnet     0.412    1\n",
      "50 word_freq_direct     0.341    3\n",
      "51 word_freq_original   0.165    1\n",
      "52 word_freq_857        0.000    0\n",
      "53 word_freq_415        0.000    0\n",
      "54 word_freq_parts      0.000    0\n",
      "55 word_freq_3d         0.000    0\n",
      "56 word_freq_table      0.000    0\n",
      " -- Reduced GDBT --\n",
      "100\n",
      " 0 word_freq_your       1318.561  110\n",
      " 1 word_freq_free       712.253  112\n",
      " 2 capital_run_length_longest 589.497  235\n",
      " 3 word_freq_george     535.560   93\n",
      " 4 word_freq_hpl        478.317   84\n",
      " 5 word_freq_edu        375.266   96\n",
      " 6 word_freq_000        340.826   55\n",
      " 7 word_freq_money      208.530   36\n",
      " 8 word_freq_our        203.616   98\n",
      " 9 word_freq_1999       160.003   81\n",
      "10 word_freq_you        149.951  199\n",
      "11 word_freq_will       137.315  130\n",
      "12 word_freq_re         89.231   83\n",
      "13 char_freq_(          59.900  108\n",
      "14 word_freq_meeting    55.440   46\n",
      "15 word_freq_business   48.224   66\n",
      "16 word_freq_email      37.043   38\n",
      "17 word_freq_credit     31.561   17\n",
      "18 char_freq_#          30.104   46\n",
      "19 word_freq_over       29.639   37\n",
      "20 word_freq_650        28.562   26\n",
      "21 char_freq_;          28.018   71\n",
      "22 word_freq_receive    24.422   40\n",
      "23 word_freq_all        23.418   46\n",
      "24 word_freq_internet   22.534   17\n",
      "25 word_freq_85         21.483   15\n",
      "26 word_freq_labs       19.359   15\n",
      "27 word_freq_mail       15.842   37\n",
      "28 word_freq_telnet     13.342   17\n",
      "29 word_freq_font       12.361   26\n",
      "30 word_freq_pm         11.154   29\n",
      "31 word_freq_technology 10.128   18\n",
      "32 word_freq_people     9.151   14\n",
      "33 word_freq_order      7.203   15\n",
      "34 word_freq_cs         6.766   13\n",
      "35 char_freq_[          6.397   24\n",
      "36 word_freq_project    6.072   22\n",
      "37 word_freq_lab        5.272   16\n",
      "38 word_freq_make       4.464   14\n",
      "39 word_freq_address    4.159   16\n",
      "40 word_freq_data       3.562   11\n",
      "41 word_freq_report     2.791    7\n",
      "42 word_freq_addresses  1.620    7\n",
      "43 word_freq_conference 1.180    9\n",
      "44 word_freq_original   1.067    3\n",
      "45 word_freq_direct     0.426    2\n",
      "46 word_freq_3d         0.000    0\n",
      "47 word_freq_857        0.000    0\n",
      "48 word_freq_parts      0.000    0\n",
      "49 word_freq_415        0.000    0\n",
      "50 word_freq_table      0.000    0\n"
     ]
    }
   ],
   "source": [
    "###------------_####\n",
    "def print_fx_imp(model, colnames):\n",
    "    fx_uses = model.feature_importance(importance_type='split')\n",
    "    fx_gain = model.feature_importance(importance_type='gain')\n",
    "\n",
    "    for i,f in enumerate(np.argsort(fx_gain)[::-1]):\n",
    "        print (\"{:2d} {:20s} {:.3f} {:4d}\".format(i, colnames[f], fx_gain[f], fx_uses[f]))\n",
    "\n",
    "        \n",
    "\n",
    "print(\" -- GDBT --\")    \n",
    "gbdt = lightgbm.Booster(model_file=\"../out/models/spam/std-gbdt_spam_T100_S0050_L24_R99.model\")\n",
    "print(gbdt.num_trees())\n",
    "print_fx_imp(gbdt, TRAIN.columns)\n",
    "\n",
    "print(\" -- Reduced GDBT --\")    \n",
    "redf = lightgbm.Booster(model_file=\"../out/models/spam/red-gbdt_spam_T100_S0050_L24_R92.model\")\n",
    "print(redf.num_trees())\n",
    "print_fx_imp(redf, TRAIN.drop(columns=['char_freq_!', 'word_freq_remove',\n",
    "                                                          'char_freq_$', 'capital_run_length_average',\n",
    "                                                          'capital_run_length_total', 'word_freq_hp' ]).columns\n",
    "            )\n",
    "\n",
    "\n",
    "# print(\" -- Adv. Boosting --\")    \n",
    "# advb = lightgbm.Booster(model_file=\"../out/models/census/adv-boosting_census_B30_T100_S0050_L24_R100.model\")\n",
    "# print(advb.num_trees())\n",
    "# print_fx_imp(advb, TRAIN.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
