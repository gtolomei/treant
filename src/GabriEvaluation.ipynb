{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models\n",
    "\n",
    "This notebook contains the code used for evaluating the following learning models:\n",
    "\n",
    "-  **Standard GBDT** (_baseline 1_)\n",
    "-  **Adversarial Boosting** (_baseline 2_)\n",
    "-  **Non-Interferent GBDT** (our proposal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    " - http://lightgbm.readthedocs.io/en/latest/\n",
    " - http://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n",
    " - https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriele/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm\n",
    "import functools\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "# Adding the following line, allows Jupyter Notebook to visualize plots\n",
    "# produced by matplotlib directly below the code cell which generated those.\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard evaluation metric\n",
    "\n",
    "The following function is the one used for evaluating the quality of the learned model (either _standard_, _adversarial-boosting_, or _non-interferent_). This is the standard <code>avg_log_loss</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    return np.log(p/(1-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss(preds, train_data):\n",
    "    \n",
    "    labels = train_data.get_label()\n",
    "    losses = np.log(1.0 + np.exp(-preds*labels))\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    return 'avg_binary_log_loss', avg_loss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_log_loss(model, test, test_groups=None, svm=False):\n",
    "    \n",
    "    lgbm_test = lightgbm.Dataset(data=test.iloc[:,:-1].values, \n",
    "                                 label=test.iloc[:,-1].values,\n",
    "                                 free_raw_data=False)\n",
    "    \n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        return avg_log_loss(logit(model.predict_proba(test.iloc[:,:-1].values)[:,1]), lgbm_test)[1]\n",
    "    \n",
    "    return avg_log_loss(model.predict(test.iloc[:,:-1].values), lgbm_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom evaluation metric\n",
    "\n",
    "Similarly to what we have done for <code>fobj</code>, <code>feval</code> can be computed from a weighted combination of two evaluation metrics:\n",
    "\n",
    "-  <code>avg_log_loss</code> (standard, defined above);\n",
    "-  <code>avg_log_loss_uma</code> (custom, defined below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>avg_log_loss_uma</code>\n",
    "\n",
    "This is the binary log loss yet modified to operate on groups of perturbed instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom metric\n",
    "\n",
    "def binary_log_loss(pred, true_label):\n",
    "\n",
    "    return np.log(1.0 + np.exp(-pred * true_label))\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def avg_log_loss_uma(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    attack_lens = train_data.get_group()\n",
    "    \n",
    "    offset = 0\n",
    "    max_logloss = []\n",
    "    avg_max_logloss = 0.0\n",
    "    \n",
    "    if attack_lens is not None:\n",
    "    \n",
    "        for atk in attack_lens:\n",
    "            losses = [binary_log_loss(h,t) for h,t in zip(preds[offset:offset+atk], labels[offset:offset+atk])]\n",
    "            max_logloss.append(max(losses))\n",
    "\n",
    "            offset += atk\n",
    "        \n",
    "        avg_max_logloss = np.mean(max_logloss)  \n",
    "\n",
    "    return 'avg_binary_log_loss_under_max_attack', avg_max_logloss, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_log_loss_uma(model, test, test_groups=None, svm=False):\n",
    "    \n",
    "    lgbm_test = lightgbm.Dataset(data=test.iloc[:,:-1].values, \n",
    "                                 label=test.iloc[:,-1].values,\n",
    "                                 group=test_groups,\n",
    "                                 free_raw_data=False)\n",
    "    \n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        return avg_log_loss_uma(logit(model.predict_proba(test.iloc[:,:-1].values)[:,1]), \n",
    "                                               lgbm_test)[1]\n",
    "    \n",
    "    return avg_log_loss_uma(model.predict(test.iloc[:,:-1].values), \n",
    "                                               lgbm_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>feval=avg_non_interferent_log_loss</code>\n",
    "\n",
    "Used for measuring the validity of any model (either _standard_, _baseline_, or _non-interferent_). More precisely, <code>avg_non_interferent_log_loss</code> is the weighted sum of the binary log loss and the binary log loss under maximal attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM takes lambda x,y: avg_weighted_sum_log_loss_log_loss_uma(preds, train_data, alpha=0.5)\n",
    "\n",
    "def avg_non_interferent_log_loss(preds, train_data, alpha=1.0):\n",
    "    \n",
    "    # binary logloss under maximal attack\n",
    "    _, loss_uma, _    = avg_log_loss_uma(preds, train_data)\n",
    "    \n",
    "    # binary logloss (plain)\n",
    "    # _, loss_plain, _  = avg_log_loss(preds, train_data)\n",
    "    \n",
    "    ids = []\n",
    "    attack_lens = train_data.get_group()\n",
    "    \n",
    "    if attack_lens is not None:\n",
    "        offset=0\n",
    "        for atk in attack_lens:\n",
    "            ids += [offset]\n",
    "            offset += atk      \n",
    "            \n",
    "    ids = np.array(ids)\n",
    "    labels = train_data.get_label()\n",
    "    losses = np.log(1.0 + np.exp(-preds[ids]*labels[ids]))\n",
    "    loss_plain = np.mean(losses)\n",
    "\n",
    "    # combine the above two losses together\n",
    "    weighted_loss = alpha*loss_uma + (1.0-alpha)*loss_plain\n",
    "\n",
    "    return 'avg_non_interferent_log_loss [alpha={:.2f}]'.format(alpha), weighted_loss, False\n",
    "\n",
    "def eval_non_interferent_log_loss(model, test, test_groups=None, svm=False, alpha=1.0):\n",
    "    \n",
    "    lgbm_test = lightgbm.Dataset(data=test.iloc[:,:-1].values, \n",
    "                                 label=test.iloc[:,-1].values,\n",
    "                                 group=test_groups,\n",
    "                                 free_raw_data=False)\n",
    "    \n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        return avg_non_interferent_log_loss(logit(model.predict_proba(test.iloc[:,:-1].values)[:,1]), \n",
    "                                                  lgbm_test,\n",
    "                                                  alpha=alpha\n",
    "                                                 )[1]\n",
    "    \n",
    "    return avg_non_interferent_log_loss(model.predict(test.iloc[:,:-1].values), \n",
    "                                                  lgbm_test,\n",
    "                                                  alpha=alpha\n",
    "                                                 )[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional validity measures\n",
    "\n",
    "In addition to the evaluation metrics defined above (used for training), we also consider the following **4** measures of validity to compare the performance of each learned model:\n",
    "\n",
    "-  <code>eval_binary_err_rate</code>: This is the traditional binary error rate (1-accuracy);\n",
    "-  <code>eval_binary_err_rate_uma</code>: This is the binary error rate modified to operate on groups of perturbed instances under maximal attack.\n",
    "-  <code>eval_roc_auc</code>: This is the classical ROC AUC score;\n",
    "-  <code>eval_roc_auc_uma</code>: This is the ROC AUC score modified to operate on groups of perturbed instances under maximal attack.\n",
    "\n",
    "Again, note that those are **not** metrics used at training time (i.e., they do not define any <code>feval</code>), rather they are used to assess the (offline) quality of each learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_binary_err_rate</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_binary_err_rate(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    errs = 0\n",
    "    for p,l in zip(predictions,labels):\n",
    "        if p != l:\n",
    "            errs += 1\n",
    "    return errs/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_binary_err_rate_uma</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_binary_err_rate_uma(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    offset = 0\n",
    "    errs = 0\n",
    "\n",
    "    for g in test_groups:\n",
    "        predictions_att = predictions[offset:offset+g]\n",
    "        true_label = labels[offset]\n",
    "        if np.any([p != true_label for p in predictions_att]):\n",
    "            errs += 1\n",
    "        offset += g\n",
    "\n",
    "    return errs/len(test_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_roc_auc</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_roc_auc(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "        \n",
    "    \n",
    "    return roc_auc_score(y_true=labels, y_score=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_roc_auc_uma</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_roc_auc_uma(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        predictions = model.predict(X)\n",
    "    \n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        \n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = predictions[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "        \n",
    "    return roc_auc_score(y_true=true_labels, y_score=worst_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_specificity</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_specificity(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "\n",
    "    return tn/(tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_specificity_uma</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_specificity_uma(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = predictions[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, worst_predictions).ravel()\n",
    "\n",
    "    return tn/(tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_precision</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_precision(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "\n",
    "    return tp/(tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_precision_uma</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_precision_uma(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = predictions[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, worst_predictions).ravel()\n",
    "    \n",
    "    return tp/(tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_recall</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_recall(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "\n",
    "    return tp/(tp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_recall_uma</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_recall_uma(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = predictions[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, worst_predictions).ravel()\n",
    "    \n",
    "    return tp/(tp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_npv</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_npv(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "\n",
    "    return tn/(tn + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_npv_uma</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_npv_uma(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = predictions[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, worst_predictions).ravel()\n",
    "    \n",
    "    return tn/(tn + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_f1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_f1(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    return f1_score(y_true=labels, y_pred=predictions, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <code>eval_f1_uma</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_f1_uma(model, test_set, test_groups=None, svm=False):\n",
    "    X = test_set.iloc[:,:-1].values\n",
    "    labels = test_set.iloc[:,-1].values\n",
    "    \n",
    "    model_predictions = []\n",
    "    if svm: # no trees have been generated (used for evaluating other non-tree-based models like SVM)\n",
    "        # use the logit function (i.e., the inverse of the logistic function) to map probabilities output\n",
    "        # by sklearn's predict_proba in the range [0,1] to a real number in the range [-inf, +inf]\n",
    "        model_predictions = logit(model.predict_proba(X)[:,1])\n",
    "    else:\n",
    "        model_predictions = model.predict(X)\n",
    "        \n",
    "    predictions = [1 if p > 0 else -1 for p in model_predictions]\n",
    "    \n",
    "    offset = 0\n",
    "    true_labels = []\n",
    "    worst_predictions = []\n",
    "    \n",
    "    for g in test_groups:\n",
    "        true_label = labels[offset]\n",
    "        true_labels.append(true_label)\n",
    "        predictions_att = predictions[offset:offset+g]\n",
    "        if true_label == 1:\n",
    "            worst_predictions.append(np.min(predictions_att))\n",
    "        else:\n",
    "            worst_predictions.append(np.max(predictions_att))\n",
    "    \n",
    "        offset += g\n",
    "        \n",
    "    return f1_score(y_true=true_labels, y_pred=worst_predictions, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_METRICS = [eval_log_loss, \n",
    "                eval_binary_err_rate,\n",
    "                eval_specificity,\n",
    "                eval_precision,\n",
    "                eval_recall,\n",
    "                eval_npv,\n",
    "                eval_f1,\n",
    "                eval_roc_auc\n",
    "               ]\n",
    "\n",
    "EVAL_METRICS_UNDER_MAX_ATTACK = [eval_log_loss_uma,\n",
    "                                 eval_binary_err_rate_uma,\n",
    "                                 eval_specificity_uma,\n",
    "                                 eval_precision_uma,\n",
    "                                 eval_recall_uma,\n",
    "                                 eval_f1_uma,\n",
    "                                 eval_roc_auc_uma\n",
    "                                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate each model w.r.t. _all_ evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learned_model(model, eval_metric, test, test_groups=None, svm=False):\n",
    "    return eval_metric(model, test, test_groups=test_groups, svm=svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learned_models(model, model_type, test, test_groups=None, budget=0):\n",
    "\n",
    "    eval_metrics = EVAL_METRICS\n",
    "    d_test = \"D_test\"\n",
    "    if test_groups is not None:\n",
    "        eval_metrics = EVAL_METRICS_UNDER_MAX_ATTACK\n",
    "        d_test = \"D_test_att\"\n",
    "    \n",
    "    header = ['Model'] + ['Budget'] + [m.__name__.replace('eval_','').replace('_',' ').strip().title() for m in EVAL_METRICS]\n",
    "    df = pd.DataFrame(columns=header)\n",
    "    first_row = [model_type] + [budget] + [None for m in EVAL_METRICS]\n",
    "    df.loc[0] = first_row\n",
    "    \n",
    "    svm = False\n",
    "    if model_type == \"SVM\":\n",
    "        svm = True\n",
    "\n",
    "    for eval_metric in eval_metrics:\n",
    "        res = eval_learned_model(model, eval_metric, test, test_groups=test_groups, svm=svm)\n",
    "        print(\"{} learning - {} on {} = {:.5f}\"\n",
    "                  .format(model_type, eval_metric.__name__, d_test, res))\n",
    "        column_metric = eval_metric.__name__\n",
    "        if eval_metric.__name__.endswith(\"uma\"):\n",
    "            column_metric = eval_metric.__name__.replace('uma', '')\n",
    "        df[column_metric.replace('eval_','').replace('_',' ').strip().title()] = res\n",
    "\n",
    "    print(\"******************************************************************************************************\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(dataset, categorical_features):\n",
    "    dataset_le = dataset.copy()\n",
    "    for column in dataset_le.columns:\n",
    "        if column in categorical_features:\n",
    "            dataset_le[column] = dataset_le[column].astype('category')\n",
    "            dataset_le[column] = dataset_le[column].cat.codes.astype(np.int32)\n",
    "    return dataset_le\n",
    "\n",
    "def load_atk_train_valid_test(atk_train_file, atk_valid_file, atk_test_file, \n",
    "                              train_split=0.6, valid_split=0.2, force=False):\n",
    "    \n",
    "    \n",
    "    if  (force or \n",
    "          not os.path.exists(atk_train_file+\".cat.bz2\") or\n",
    "          not os.path.exists(atk_valid_file+\".cat.bz2\") or\n",
    "          not os.path.exists(atk_test_file+\".cat.bz2\") or \n",
    "          not os.path.exists(atk_train_file+\".cat.json\") ):\n",
    "    \n",
    "        print (\"Pre-processing original files...\")\n",
    "\n",
    "        print (\"Loading:\", atk_train_file)\n",
    "        print (\"Loading:\", atk_valid_file)\n",
    "        print (\"Loading:\", atk_test_file)\n",
    "\n",
    "        train = pd.read_csv(atk_train_file)\n",
    "        valid = pd.read_csv(atk_valid_file)\n",
    "        test  = pd.read_csv(atk_test_file)\n",
    "        \n",
    "        print (\"Train/Valid/Test sizes:\", train.shape, valid.shape, test.shape)\n",
    "        print (\"Train/Valid/Test split: {:.2f} {:.2f} {:.2f}\"\n",
    "                   .format( train.shape[0]/(train.shape[0]+valid.shape[0]+test.shape[0]),\n",
    "                            valid.shape[0]/(train.shape[0]+valid.shape[0]+test.shape[0]),\n",
    "                            test.shape[0] /(train.shape[0]+valid.shape[0]+test.shape[0]) ) )\n",
    "\n",
    "\n",
    "        # split-back into train valid test\n",
    "        if 'instance_id' in train.columns.values:\n",
    "            print ('with instance ids')\n",
    "            valid['instance_id'] += train.iloc[-1,0]\n",
    "            test['instance_id']  += valid.iloc[-1,0]\n",
    "            \n",
    "            groups = np.concatenate( [ train['instance_id'].value_counts().sort_index().values,\n",
    "                                       valid['instance_id'].value_counts().sort_index().values,\n",
    "                                       test['instance_id'].value_counts().sort_index().values ] )\n",
    "            \n",
    "            num_train_groups = int( len(groups)*train_split )\n",
    "            train_size = sum(groups[:num_train_groups])\n",
    "            num_valid_groups = int( len(groups)*valid_split )\n",
    "            valid_size = sum(groups[num_train_groups:num_train_groups+num_valid_groups])\n",
    "        else:\n",
    "            full_size = len(train) + len(valid) + len(test)\n",
    "            train_size = int( full_size*train_split )\n",
    "            valid_size = int( full_size*valid_split )\n",
    "        \n",
    "        # concat to process correctly label encoding\n",
    "        full = pd.concat( [train, valid, test] )\n",
    "\n",
    "        # get index of categorical features (-1 because of instance_id)\n",
    "        cat_fx = full.columns.values[np.where(full.dtypes=='object')[0]]\n",
    "        cat_fx = list(cat_fx)    \n",
    "        full = label_encode(full, cat_fx)\n",
    "        with open(atk_train_file+\".cat.json\", 'w') as fp:\n",
    "            json.dump(cat_fx, fp)\n",
    "        print (\"CatFX:\", cat_fx)\n",
    "\n",
    "        train_cat = full.iloc[0:train_size,:]\n",
    "        valid_cat = full.iloc[train_size:train_size+valid_size,:]\n",
    "        test_cat  = full.iloc[train_size+valid_size:,:]    \n",
    "\n",
    "        print (\"Train/Valid/Test sizes:\", train_cat.shape, valid_cat.shape, test_cat.shape)\n",
    "        print (\"Train/Valid/Test split: {:.2f} {:.2f} {:.2f}\"\n",
    "                   .format( train_cat.shape[0]/(train_cat.shape[0]+valid_cat.shape[0]+test_cat.shape[0]),\n",
    "                            valid_cat.shape[0]/(train_cat.shape[0]+valid_cat.shape[0]+test_cat.shape[0]),\n",
    "                            test_cat.shape[0] /(train_cat.shape[0]+valid_cat.shape[0]+test_cat.shape[0]) ) )\n",
    "\n",
    "        # save to file\n",
    "        print (\"Saving processed files *.cat.bz2\")\n",
    "        train_cat.to_csv(atk_train_file+\".cat.bz2\", compression=\"bz2\", index=False)\n",
    "        valid_cat.to_csv(atk_valid_file+\".cat.bz2\", compression=\"bz2\", index=False)\n",
    "        test_cat.to_csv (atk_test_file+\".cat.bz2\",  compression=\"bz2\", index=False)\n",
    "        \n",
    "    else:\n",
    "        print (\"Loading pre-processed files...\")\n",
    "\n",
    "        train_cat = pd.read_csv(atk_train_file+\".cat.bz2\")\n",
    "        valid_cat = pd.read_csv(atk_valid_file+\".cat.bz2\")\n",
    "        test_cat  = pd.read_csv(atk_test_file+\".cat.bz2\")\n",
    "        \n",
    "        with open(atk_train_file+\".cat.json\", 'r') as fp:\n",
    "            cat_fx = json.load(fp)\n",
    "    \n",
    "    # return data\n",
    "    return train_cat, valid_cat, test_cat, cat_fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve all model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = \"../out/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard SVM\n",
    "svm = None \n",
    "with open(join(MODELS_PATH, \"svm_census_C1000.model\"), 'rb') as svm_file:\n",
    "    svm = pickle.load(svm_file)\n",
    "### Standard GBDT\n",
    "std_gbdt = lightgbm.Booster(model_file=join(MODELS_PATH, \"std_gbdt_census_T500_S0100_L24_R234.model\"))\n",
    "### Adversarial Boosting\n",
    "# budget=5\n",
    "adv_boost_b5 = lightgbm.Booster(model_file=join(MODELS_PATH, \"adv_boosting_census_B5_T500_S0100_L24_R492.model\"))\n",
    "# budget=15\n",
    "adv_boost_b15 = lightgbm.Booster(model_file=join(MODELS_PATH, \"adv_boosting_census_B15_T500_S0100_L24_R450.model\"))\n",
    "# budget=150\n",
    "adv_boost_b150 = lightgbm.Booster(model_file=join(MODELS_PATH, \"adv_boosting_census_B150_T500_S0100_L24_R465.model\"))\n",
    "# budget=300\n",
    "adv_boost_b300 = lightgbm.Booster(model_file=join(MODELS_PATH, \"adv_boosting_census_B300_T500_S0100_L24_R498.model\"))\n",
    "### Non-Interferent\n",
    "# budget=5\n",
    "non_interf_b5 = lightgbm.Booster(model_file=join(MODELS_PATH, \"non_interferent_census_B5_T500_S0050_L24_A050_R356.model\")) #\"non_interferent_census_B5_T500_S0100_L24_A050_R157.model\"))\n",
    "# budget=15\n",
    "non_interf_b15 = lightgbm.Booster(model_file=join(MODELS_PATH, \"non_interferent_census_B15_T500_S0050_L24_A050_R335.model\")) #\"non_interferent_census_B15_T500_S0100_L24_A050_R156.model\"))\n",
    "# budget=150\n",
    "non_interf_b150 = lightgbm.Booster(model_file=join(MODELS_PATH, \"non_interferent_census_B150_T500_S0050_L24_A050_R292.model\")) #\"non_interferent_census_B150_T500_S0100_L24_A050_R135.model\"))\n",
    "# budget=300\n",
    "non_interf_b300 = lightgbm.Booster(model_file=join(MODELS_PATH, \"non_interferent_census_B300_T500_S0050_L24_A050_R340.model\")) #\"non_interferent_census_B300_T500_S0100_L24_A050_R134.model\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = (std_gbdt,\n",
    "          adv_boost_b5, \n",
    "          adv_boost_b15, \n",
    "          adv_boost_b150, \n",
    "          adv_boost_b300, \n",
    "          non_interf_b5,\n",
    "          non_interf_b15,\n",
    "          non_interf_b150,\n",
    "          non_interf_b300\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-processed files...\n"
     ]
    }
   ],
   "source": [
    "# load train/valid/test\n",
    "train, valid, test, _ = load_atk_train_valid_test(\"../data/census/train_ori.csv.bz2\", \n",
    "                                                       \"../data/census/valid_ori.csv.bz2\", \n",
    "                                                       \"../data/census/test_ori.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attacked_dataset(budget):\n",
    "    # load train/valid/test\n",
    "    train_att, valid_att, test_att, _ = load_atk_train_valid_test(\"../data/census/train_B{}.csv.bz2\".format(budget), \n",
    "                                                           \"../data/census/valid_B{}.csv.bz2\".format(budget), \n",
    "                                                           \"../data/census/test_B{}.csv.bz2\".format(budget))\n",
    "\n",
    "    test_groups = test_att['instance_id'].value_counts().sort_index().values\n",
    "    test_att = test_att.iloc[:, 1:]\n",
    "\n",
    "    valid_groups = valid_att['instance_id'].value_counts().sort_index().values\n",
    "    valid_att = valid_att.iloc[:, 1:]\n",
    "\n",
    "    train_groups = train_att['instance_id'].value_counts().sort_index().values\n",
    "    train_att = train_att.iloc[:, 1:]\n",
    "    \n",
    "    return train_att, train_groups, valid_att, valid_groups, test_att, test_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attacked_datasets():\n",
    "    att_datasets = {}\n",
    "    for b in [5, 15, 150, 300]:\n",
    "        att_datasets[b] = load_attacked_dataset(b)\n",
    "    \n",
    "    return att_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline [GBDT] learning - eval_log_loss on D_test = 0.30008\n",
      "Baseline [GBDT] learning - eval_binary_err_rate on D_test = 0.13787\n",
      "Baseline [GBDT] learning - eval_specificity on D_test = 0.93585\n",
      "Baseline [GBDT] learning - eval_precision on D_test = 0.76273\n",
      "Baseline [GBDT] learning - eval_recall on D_test = 0.63509\n",
      "Baseline [GBDT] learning - eval_npv on D_test = 0.88762\n",
      "Baseline [GBDT] learning - eval_f1 on D_test = 0.80209\n",
      "Baseline [GBDT] learning - eval_roc_auc on D_test = 0.91673\n",
      "******************************************************************************************************\n",
      "Adversarial-Boosting [b=5] learning - eval_log_loss on D_test = 0.31726\n",
      "Adversarial-Boosting [b=5] learning - eval_binary_err_rate on D_test = 0.14417\n",
      "Adversarial-Boosting [b=5] learning - eval_specificity on D_test = 0.96602\n",
      "Adversarial-Boosting [b=5] learning - eval_precision on D_test = 0.83152\n",
      "Adversarial-Boosting [b=5] learning - eval_recall on D_test = 0.51646\n",
      "Adversarial-Boosting [b=5] learning - eval_npv on D_test = 0.86020\n",
      "Adversarial-Boosting [b=5] learning - eval_f1 on D_test = 0.77361\n",
      "Adversarial-Boosting [b=5] learning - eval_roc_auc on D_test = 0.91320\n",
      "******************************************************************************************************\n",
      "Adversarial-Boosting [b=15] learning - eval_log_loss on D_test = 0.31817\n",
      "Adversarial-Boosting [b=15] learning - eval_binary_err_rate on D_test = 0.14461\n",
      "Adversarial-Boosting [b=15] learning - eval_specificity on D_test = 0.96793\n",
      "Adversarial-Boosting [b=15] learning - eval_precision on D_test = 0.83742\n",
      "Adversarial-Boosting [b=15] learning - eval_recall on D_test = 0.50880\n",
      "Adversarial-Boosting [b=15] learning - eval_npv on D_test = 0.85853\n",
      "Adversarial-Boosting [b=15] learning - eval_f1 on D_test = 0.77148\n",
      "Adversarial-Boosting [b=15] learning - eval_roc_auc on D_test = 0.91347\n",
      "******************************************************************************************************\n",
      "Adversarial-Boosting [b=150] learning - eval_log_loss on D_test = 0.31868\n",
      "Adversarial-Boosting [b=150] learning - eval_binary_err_rate on D_test = 0.14483\n",
      "Adversarial-Boosting [b=150] learning - eval_specificity on D_test = 0.96822\n",
      "Adversarial-Boosting [b=150] learning - eval_precision on D_test = 0.83818\n",
      "Adversarial-Boosting [b=150] learning - eval_recall on D_test = 0.50699\n",
      "Adversarial-Boosting [b=150] learning - eval_npv on D_test = 0.85813\n",
      "Adversarial-Boosting [b=150] learning - eval_f1 on D_test = 0.77083\n",
      "Adversarial-Boosting [b=150] learning - eval_roc_auc on D_test = 0.91325\n",
      "******************************************************************************************************\n",
      "Adversarial-Boosting [b=300] learning - eval_log_loss on D_test = 0.31838\n",
      "Adversarial-Boosting [b=300] learning - eval_binary_err_rate on D_test = 0.14450\n",
      "Adversarial-Boosting [b=300] learning - eval_specificity on D_test = 0.96910\n",
      "Adversarial-Boosting [b=300] learning - eval_precision on D_test = 0.84159\n",
      "Adversarial-Boosting [b=300] learning - eval_recall on D_test = 0.50564\n",
      "Adversarial-Boosting [b=300] learning - eval_npv on D_test = 0.85790\n",
      "Adversarial-Boosting [b=300] learning - eval_f1 on D_test = 0.77092\n",
      "Adversarial-Boosting [b=300] learning - eval_roc_auc on D_test = 0.91369\n",
      "******************************************************************************************************\n",
      "Non-Interferent [b=5] learning - eval_log_loss on D_test = 0.28831\n",
      "Non-Interferent [b=5] learning - eval_binary_err_rate on D_test = 0.13444\n",
      "Non-Interferent [b=5] learning - eval_specificity on D_test = 0.93307\n",
      "Non-Interferent [b=5] learning - eval_precision on D_test = 0.76136\n",
      "Non-Interferent [b=5] learning - eval_recall on D_test = 0.65765\n",
      "Non-Interferent [b=5] learning - eval_npv on D_test = 0.89355\n",
      "Non-Interferent [b=5] learning - eval_f1 on D_test = 0.80930\n",
      "Non-Interferent [b=5] learning - eval_roc_auc on D_test = 0.92313\n",
      "******************************************************************************************************\n",
      "Non-Interferent [b=15] learning - eval_log_loss on D_test = 0.28817\n",
      "Non-Interferent [b=15] learning - eval_binary_err_rate on D_test = 0.13333\n",
      "Non-Interferent [b=15] learning - eval_specificity on D_test = 0.93395\n",
      "Non-Interferent [b=15] learning - eval_precision on D_test = 0.76424\n",
      "Non-Interferent [b=15] learning - eval_recall on D_test = 0.65945\n",
      "Non-Interferent [b=15] learning - eval_npv on D_test = 0.89414\n",
      "Non-Interferent [b=15] learning - eval_f1 on D_test = 0.81080\n",
      "Non-Interferent [b=15] learning - eval_roc_auc on D_test = 0.92315\n",
      "******************************************************************************************************\n",
      "Non-Interferent [b=150] learning - eval_log_loss on D_test = 0.28788\n",
      "Non-Interferent [b=150] learning - eval_binary_err_rate on D_test = 0.13300\n",
      "Non-Interferent [b=150] learning - eval_specificity on D_test = 0.93366\n",
      "Non-Interferent [b=150] learning - eval_precision on D_test = 0.76406\n",
      "Non-Interferent [b=150] learning - eval_recall on D_test = 0.66171\n",
      "Non-Interferent [b=150] learning - eval_npv on D_test = 0.89474\n",
      "Non-Interferent [b=150] learning - eval_f1 on D_test = 0.81150\n",
      "Non-Interferent [b=150] learning - eval_roc_auc on D_test = 0.92335\n",
      "******************************************************************************************************\n",
      "Non-Interferent [b=300] learning - eval_log_loss on D_test = 0.28821\n",
      "Non-Interferent [b=300] learning - eval_binary_err_rate on D_test = 0.13311\n",
      "Non-Interferent [b=300] learning - eval_specificity on D_test = 0.93322\n",
      "Non-Interferent [b=300] learning - eval_precision on D_test = 0.76312\n",
      "Non-Interferent [b=300] learning - eval_recall on D_test = 0.66261\n",
      "Non-Interferent [b=300] learning - eval_npv on D_test = 0.89494\n",
      "Non-Interferent [b=300] learning - eval_f1 on D_test = 0.81150\n",
      "Non-Interferent [b=300] learning - eval_roc_auc on D_test = 0.92335\n",
      "******************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "#svm_df = eval_learned_models(svm, \"SVM\", test)\n",
    "std_gbdt_df = eval_learned_models(std_gbdt, \"Baseline [GBDT]\", test)\n",
    "adv_boost_df_b5 = eval_learned_models(adv_boost_b5, \"Adversarial-Boosting [b=5]\", test)\n",
    "adv_boost_df_b15 = eval_learned_models(adv_boost_b15, \"Adversarial-Boosting [b=15]\", test)\n",
    "adv_boost_df_b150 = eval_learned_models(adv_boost_b150, \"Adversarial-Boosting [b=150]\", test)\n",
    "adv_boost_df_b300 = eval_learned_models(adv_boost_b300, \"Adversarial-Boosting [b=300]\", test)\n",
    "non_interf_df_b5 = eval_learned_models(non_interf_b5, \"Non-Interferent [b=5]\", test)\n",
    "non_interf_df_b15 = eval_learned_models(non_interf_b15, \"Non-Interferent [b=15]\", test)\n",
    "non_interf_df_b150 = eval_learned_models(non_interf_b150, \"Non-Interferent [b=150]\", test)\n",
    "non_interf_df_b300 = eval_learned_models(non_interf_b300, \"Non-Interferent [b=300]\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing original files...\n",
      "Loading: ../data/census/train_B5.csv.bz2\n",
      "Loading: ../data/census/valid_B5.csv.bz2\n",
      "Loading: ../data/census/test_B5.csv.bz2\n",
      "Train/Valid/Test sizes: (206443, 15) (22601, 15) (114789, 15)\n",
      "Train/Valid/Test split: 0.60 0.07 0.33\n",
      "with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (206334, 15) (68498, 15) (69001, 15)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "Pre-processing original files...\n",
      "Loading: ../data/census/train_B15.csv.bz2\n",
      "Loading: ../data/census/valid_B15.csv.bz2\n",
      "Loading: ../data/census/test_B15.csv.bz2\n",
      "Train/Valid/Test sizes: (418102, 15) (45598, 15) (232444, 15)\n",
      "Train/Valid/Test split: 0.60 0.07 0.33\n",
      "with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (417875, 15) (138526, 15) (139743, 15)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "Pre-processing original files...\n",
      "Loading: ../data/census/train_B150.csv.bz2\n",
      "Loading: ../data/census/valid_B150.csv.bz2\n",
      "Loading: ../data/census/test_B150.csv.bz2\n",
      "Train/Valid/Test sizes: (1261180, 15) (137558, 15) (701292, 15)\n",
      "Train/Valid/Test split: 0.60 0.07 0.33\n",
      "with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (1260493, 15) (417914, 15) (421623, 15)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n",
      "Pre-processing original files...\n",
      "Loading: ../data/census/train_B300.csv.bz2\n",
      "Loading: ../data/census/valid_B300.csv.bz2\n",
      "Loading: ../data/census/test_B300.csv.bz2\n",
      "Train/Valid/Test sizes: (2474827, 15) (269833, 15) (1376164, 15)\n",
      "Train/Valid/Test split: 0.60 0.07 0.33\n",
      "with instance ids\n",
      "CatFX: ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "Train/Valid/Test sizes: (2473475, 15) (819976, 15) (827373, 15)\n",
      "Train/Valid/Test split: 0.60 0.20 0.20\n",
      "Saving processed files *.cat.bz2\n"
     ]
    }
   ],
   "source": [
    "att_datasets = load_attacked_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_att_b5 = att_datasets[5][4]\n",
    "test_groups_b5 = att_datasets[5][5]\n",
    "test_att_b15 = att_datasets[15][4]\n",
    "test_groups_b15 = att_datasets[15][5]\n",
    "test_att_b150 = att_datasets[150][4]\n",
    "test_groups_b150 = att_datasets[150][5]\n",
    "test_att_b300 = att_datasets[300][4]\n",
    "test_groups_b300 = att_datasets[300][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_models_under_attack(models):\n",
    "    \n",
    "    std_gbdt, adv_boost_b5, adv_boost_b15, adv_boost_b150, adv_boost_b300, non_interf_b5, non_interf_b15, non_interf_b150, non_interf_b300 = models\n",
    "    \n",
    "    dfs = []\n",
    "    for b in [5, 15, 150, 300]:\n",
    "        \n",
    "        print(\"==> Evaluating Standard GBDT under attack [b={}]\".format(b))\n",
    "        std_gbdt_df_att = eval_learned_models(std_gbdt, \n",
    "                                              \"Baseline [GBDT]\", \n",
    "                                              att_datasets[b][4], \n",
    "                                              att_datasets[b][5], \n",
    "                                              budget=b)\n",
    "        \n",
    "        print(\"==> Evaluating Adversarial Boosting [b_train={}] under attack [b={}]\".format(5, b))\n",
    "        adv_boost_df_att_b5 = eval_learned_models(adv_boost_b5, \n",
    "                                                  \"Adversarial-Boosting [b=5]\", \n",
    "                                                  att_datasets[b][4], \n",
    "                                                  att_datasets[b][5], \n",
    "                                                  budget=b)\n",
    "        print(\"==> Evaluating Adversarial Boosting [b_train={}] under attack [b={}]\".format(15, b))\n",
    "        adv_boost_df_att_b15 = eval_learned_models(adv_boost_b15, \n",
    "                                                   \"Adversarial-Boosting [b=15]\", \n",
    "                                                   att_datasets[b][4], \n",
    "                                                   att_datasets[b][5], \n",
    "                                                   budget=b)\n",
    "        print(\"==> Evaluating Adversarial Boosting [b_train={}] under attack [b={}]\".format(150, b))\n",
    "        adv_boost_df_att_b150 = eval_learned_models(adv_boost_b150, \n",
    "                                                    \"Adversarial-Boosting [b=150]\", \n",
    "                                                    att_datasets[b][4], \n",
    "                                                    att_datasets[b][5], \n",
    "                                                    budget=b)\n",
    "        print(\"==> Evaluating Adversarial Boosting [b_train={}] under attack [b={}]\".format(300, b))\n",
    "        adv_boost_df_att_b300 = eval_learned_models(adv_boost_b300, \n",
    "                                                    \"Adversarial-Boosting [b=300]\", \n",
    "                                                    att_datasets[b][4], \n",
    "                                                    att_datasets[b][5], \n",
    "                                                    budget=b)\n",
    "        \n",
    "        print(\"==> Evaluating Non-Interferent [b_train={}] under attack [b={}]\".format(5, b))\n",
    "        non_interf_df_att_b5 = eval_learned_models(non_interf_b5, \n",
    "                                                  \"Non-Interferent [b=5]\", \n",
    "                                                  att_datasets[b][4], \n",
    "                                                  att_datasets[b][5], \n",
    "                                                  budget=b)\n",
    "        print(\"==> Evaluating Non-Interferent [b_train={}] under attack [b={}]\".format(15, b))\n",
    "        non_interf_df_att_b15 = eval_learned_models(non_interf_b15, \n",
    "                                                   \"Non-Interferent [b=15]\", \n",
    "                                                   att_datasets[b][4], \n",
    "                                                   att_datasets[b][5], \n",
    "                                                   budget=b)\n",
    "        print(\"==> Evaluating Non-Interferent [b_train={}] under attack [b={}]\".format(150, b))\n",
    "        non_interf_df_att_b150 = eval_learned_models(non_interf_b150, \n",
    "                                                    \"Non-Interferent [b=150]\", \n",
    "                                                    att_datasets[b][4], \n",
    "                                                    att_datasets[b][5], \n",
    "                                                    budget=b)\n",
    "        print(\"==> Evaluating Non-Interferent [b_train={}] under attack [b={}]\".format(300, b))\n",
    "        non_interf_df_att_b300 = eval_learned_models(non_interf_b300, \n",
    "                                                    \"Non-Interferent [b=300]\", \n",
    "                                                    att_datasets[b][4], \n",
    "                                                    att_datasets[b][5], \n",
    "                                                    budget=b)\n",
    "        \n",
    "        df_b = pd.concat([std_gbdt_df_att, \n",
    "                          adv_boost_df_att_b5, \n",
    "                          adv_boost_df_att_b15, \n",
    "                          adv_boost_df_att_b150, \n",
    "                          adv_boost_df_att_b300, \n",
    "                          non_interf_df_att_b5,\n",
    "                          non_interf_df_att_b15,\n",
    "                          non_interf_df_att_b150,\n",
    "                          non_interf_df_att_b300\n",
    "                         ], \n",
    "                         axis=0, \n",
    "                         sort=False)\n",
    "\n",
    "        df_b.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        dfs.append(df_b)\n",
    "        \n",
    "    #df = functools.reduce(lambda left,right: pd.merge(left,right,on=['Model', 'Budget']), dfs)\n",
    "    df = pd.concat(dfs, axis=0, sort=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Evaluating Standard GBDT under attack [b=5]\n",
      "Baseline [GBDT] learning - eval_log_loss_uma on D_test_att = 0.33052\n",
      "Baseline [GBDT] learning - eval_binary_err_rate_uma on D_test_att = 0.15556\n",
      "Baseline [GBDT] learning - eval_specificity_uma on D_test_att = 0.91242\n",
      "Baseline [GBDT] learning - eval_precision_uma on D_test_att = 0.70189\n",
      "Baseline [GBDT] learning - eval_recall_uma on D_test_att = 0.63509\n",
      "Baseline [GBDT] learning - eval_f1_uma on D_test_att = 0.78268\n",
      "Baseline [GBDT] learning - eval_roc_auc_uma on D_test_att = 0.89767\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=5] under attack [b=5]\n",
      "Adversarial-Boosting [b=5] learning - eval_log_loss_uma on D_test_att = 0.32008\n",
      "Adversarial-Boosting [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.14516\n",
      "Adversarial-Boosting [b=5] learning - eval_specificity_uma on D_test_att = 0.96470\n",
      "Adversarial-Boosting [b=5] learning - eval_precision_uma on D_test_att = 0.82612\n",
      "Adversarial-Boosting [b=5] learning - eval_recall_uma on D_test_att = 0.51646\n",
      "Adversarial-Boosting [b=5] learning - eval_f1_uma on D_test_att = 0.77247\n",
      "Adversarial-Boosting [b=5] learning - eval_roc_auc_uma on D_test_att = 0.91054\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=15] under attack [b=5]\n",
      "Adversarial-Boosting [b=15] learning - eval_log_loss_uma on D_test_att = 0.32065\n",
      "Adversarial-Boosting [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.14572\n",
      "Adversarial-Boosting [b=15] learning - eval_specificity_uma on D_test_att = 0.96646\n",
      "Adversarial-Boosting [b=15] learning - eval_precision_uma on D_test_att = 0.83125\n",
      "Adversarial-Boosting [b=15] learning - eval_recall_uma on D_test_att = 0.50880\n",
      "Adversarial-Boosting [b=15] learning - eval_f1_uma on D_test_att = 0.77021\n",
      "Adversarial-Boosting [b=15] learning - eval_roc_auc_uma on D_test_att = 0.91108\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=150] under attack [b=5]\n",
      "Adversarial-Boosting [b=150] learning - eval_log_loss_uma on D_test_att = 0.32108\n",
      "Adversarial-Boosting [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.14572\n",
      "Adversarial-Boosting [b=150] learning - eval_specificity_uma on D_test_att = 0.96705\n",
      "Adversarial-Boosting [b=150] learning - eval_precision_uma on D_test_att = 0.83321\n",
      "Adversarial-Boosting [b=150] learning - eval_recall_uma on D_test_att = 0.50699\n",
      "Adversarial-Boosting [b=150] learning - eval_f1_uma on D_test_att = 0.76983\n",
      "Adversarial-Boosting [b=150] learning - eval_roc_auc_uma on D_test_att = 0.91090\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=300] under attack [b=5]\n",
      "Adversarial-Boosting [b=300] learning - eval_log_loss_uma on D_test_att = 0.32071\n",
      "Adversarial-Boosting [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.14549\n",
      "Adversarial-Boosting [b=300] learning - eval_specificity_uma on D_test_att = 0.96778\n",
      "Adversarial-Boosting [b=300] learning - eval_precision_uma on D_test_att = 0.83594\n",
      "Adversarial-Boosting [b=300] learning - eval_recall_uma on D_test_att = 0.50564\n",
      "Adversarial-Boosting [b=300] learning - eval_f1_uma on D_test_att = 0.76979\n",
      "Adversarial-Boosting [b=300] learning - eval_roc_auc_uma on D_test_att = 0.91142\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=5] under attack [b=5]\n",
      "Non-Interferent [b=5] learning - eval_log_loss_uma on D_test_att = 0.31310\n",
      "Non-Interferent [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.14428\n",
      "Non-Interferent [b=5] learning - eval_specificity_uma on D_test_att = 0.92004\n",
      "Non-Interferent [b=5] learning - eval_precision_uma on D_test_att = 0.72754\n",
      "Non-Interferent [b=5] learning - eval_recall_uma on D_test_att = 0.65765\n",
      "Non-Interferent [b=5] learning - eval_f1_uma on D_test_att = 0.79837\n",
      "Non-Interferent [b=5] learning - eval_roc_auc_uma on D_test_att = 0.90857\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=15] under attack [b=5]\n",
      "Non-Interferent [b=15] learning - eval_log_loss_uma on D_test_att = 0.31345\n",
      "Non-Interferent [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.14461\n",
      "Non-Interferent [b=15] learning - eval_specificity_uma on D_test_att = 0.91901\n",
      "Non-Interferent [b=15] learning - eval_precision_uma on D_test_att = 0.72556\n",
      "Non-Interferent [b=15] learning - eval_recall_uma on D_test_att = 0.65945\n",
      "Non-Interferent [b=15] learning - eval_f1_uma on D_test_att = 0.79827\n",
      "Non-Interferent [b=15] learning - eval_roc_auc_uma on D_test_att = 0.90851\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=150] under attack [b=5]\n",
      "Non-Interferent [b=150] learning - eval_log_loss_uma on D_test_att = 0.31314\n",
      "Non-Interferent [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.14538\n",
      "Non-Interferent [b=150] learning - eval_specificity_uma on D_test_att = 0.91725\n",
      "Non-Interferent [b=150] learning - eval_precision_uma on D_test_att = 0.72195\n",
      "Non-Interferent [b=150] learning - eval_recall_uma on D_test_att = 0.66171\n",
      "Non-Interferent [b=150] learning - eval_f1_uma on D_test_att = 0.79775\n",
      "Non-Interferent [b=150] learning - eval_roc_auc_uma on D_test_att = 0.90870\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=300] under attack [b=5]\n",
      "Non-Interferent [b=300] learning - eval_log_loss_uma on D_test_att = 0.31280\n",
      "Non-Interferent [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.14406\n",
      "Non-Interferent [b=300] learning - eval_specificity_uma on D_test_att = 0.91872\n",
      "Non-Interferent [b=300] learning - eval_precision_uma on D_test_att = 0.72579\n",
      "Non-Interferent [b=300] learning - eval_recall_uma on D_test_att = 0.66261\n",
      "Non-Interferent [b=300] learning - eval_f1_uma on D_test_att = 0.79934\n",
      "Non-Interferent [b=300] learning - eval_roc_auc_uma on D_test_att = 0.90897\n",
      "******************************************************************************************************\n",
      "==> Evaluating Standard GBDT under attack [b=15]\n",
      "Baseline [GBDT] learning - eval_log_loss_uma on D_test_att = 0.34517\n",
      "Baseline [GBDT] learning - eval_binary_err_rate_uma on D_test_att = 0.16274\n",
      "Baseline [GBDT] learning - eval_specificity_uma on D_test_att = 0.90290\n",
      "Baseline [GBDT] learning - eval_precision_uma on D_test_att = 0.67986\n",
      "Baseline [GBDT] learning - eval_recall_uma on D_test_att = 0.63509\n",
      "Baseline [GBDT] learning - eval_f1_uma on D_test_att = 0.77503\n",
      "Baseline [GBDT] learning - eval_roc_auc_uma on D_test_att = 0.88804\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=5] under attack [b=15]\n",
      "Adversarial-Boosting [b=5] learning - eval_log_loss_uma on D_test_att = 0.33279\n",
      "Adversarial-Boosting [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.14981\n",
      "Adversarial-Boosting [b=5] learning - eval_specificity_uma on D_test_att = 0.95855\n",
      "Adversarial-Boosting [b=5] learning - eval_precision_uma on D_test_att = 0.80182\n",
      "Adversarial-Boosting [b=5] learning - eval_recall_uma on D_test_att = 0.51646\n",
      "Adversarial-Boosting [b=5] learning - eval_f1_uma on D_test_att = 0.76723\n",
      "Adversarial-Boosting [b=5] learning - eval_roc_auc_uma on D_test_att = 0.89813\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=15] under attack [b=15]\n",
      "Adversarial-Boosting [b=15] learning - eval_log_loss_uma on D_test_att = 0.32239\n",
      "Adversarial-Boosting [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.14616\n",
      "Adversarial-Boosting [b=15] learning - eval_specificity_uma on D_test_att = 0.96588\n",
      "Adversarial-Boosting [b=15] learning - eval_precision_uma on D_test_att = 0.82880\n",
      "Adversarial-Boosting [b=15] learning - eval_recall_uma on D_test_att = 0.50880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial-Boosting [b=15] learning - eval_f1_uma on D_test_att = 0.76971\n",
      "Adversarial-Boosting [b=15] learning - eval_roc_auc_uma on D_test_att = 0.90923\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=150] under attack [b=15]\n",
      "Adversarial-Boosting [b=150] learning - eval_log_loss_uma on D_test_att = 0.32279\n",
      "Adversarial-Boosting [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.14605\n",
      "Adversarial-Boosting [b=150] learning - eval_specificity_uma on D_test_att = 0.96661\n",
      "Adversarial-Boosting [b=150] learning - eval_precision_uma on D_test_att = 0.83136\n",
      "Adversarial-Boosting [b=150] learning - eval_recall_uma on D_test_att = 0.50699\n",
      "Adversarial-Boosting [b=150] learning - eval_f1_uma on D_test_att = 0.76945\n",
      "Adversarial-Boosting [b=150] learning - eval_roc_auc_uma on D_test_att = 0.90907\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=300] under attack [b=15]\n",
      "Adversarial-Boosting [b=300] learning - eval_log_loss_uma on D_test_att = 0.32243\n",
      "Adversarial-Boosting [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.14572\n",
      "Adversarial-Boosting [b=300] learning - eval_specificity_uma on D_test_att = 0.96749\n",
      "Adversarial-Boosting [b=300] learning - eval_precision_uma on D_test_att = 0.83470\n",
      "Adversarial-Boosting [b=300] learning - eval_recall_uma on D_test_att = 0.50564\n",
      "Adversarial-Boosting [b=300] learning - eval_f1_uma on D_test_att = 0.76953\n",
      "Adversarial-Boosting [b=300] learning - eval_roc_auc_uma on D_test_att = 0.90957\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=5] under attack [b=15]\n",
      "Non-Interferent [b=5] learning - eval_log_loss_uma on D_test_att = 0.32720\n",
      "Non-Interferent [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.14925\n",
      "Non-Interferent [b=5] learning - eval_specificity_uma on D_test_att = 0.91344\n",
      "Non-Interferent [b=5] learning - eval_precision_uma on D_test_att = 0.71157\n",
      "Non-Interferent [b=5] learning - eval_recall_uma on D_test_att = 0.65765\n",
      "Non-Interferent [b=5] learning - eval_f1_uma on D_test_att = 0.79294\n",
      "Non-Interferent [b=5] learning - eval_roc_auc_uma on D_test_att = 0.89986\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=15] under attack [b=15]\n",
      "Non-Interferent [b=15] learning - eval_log_loss_uma on D_test_att = 0.32768\n",
      "Non-Interferent [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.14959\n",
      "Non-Interferent [b=15] learning - eval_specificity_uma on D_test_att = 0.91242\n",
      "Non-Interferent [b=15] learning - eval_precision_uma on D_test_att = 0.70971\n",
      "Non-Interferent [b=15] learning - eval_recall_uma on D_test_att = 0.65945\n",
      "Non-Interferent [b=15] learning - eval_f1_uma on D_test_att = 0.79285\n",
      "Non-Interferent [b=15] learning - eval_roc_auc_uma on D_test_att = 0.89987\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=150] under attack [b=15]\n",
      "Non-Interferent [b=150] learning - eval_log_loss_uma on D_test_att = 0.32790\n",
      "Non-Interferent [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.15191\n",
      "Non-Interferent [b=150] learning - eval_specificity_uma on D_test_att = 0.90861\n",
      "Non-Interferent [b=150] learning - eval_precision_uma on D_test_att = 0.70158\n",
      "Non-Interferent [b=150] learning - eval_recall_uma on D_test_att = 0.66171\n",
      "Non-Interferent [b=150] learning - eval_f1_uma on D_test_att = 0.79068\n",
      "Non-Interferent [b=150] learning - eval_roc_auc_uma on D_test_att = 0.89967\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=300] under attack [b=15]\n",
      "Non-Interferent [b=300] learning - eval_log_loss_uma on D_test_att = 0.32644\n",
      "Non-Interferent [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.14870\n",
      "Non-Interferent [b=300] learning - eval_specificity_uma on D_test_att = 0.91257\n",
      "Non-Interferent [b=300] learning - eval_precision_uma on D_test_att = 0.71104\n",
      "Non-Interferent [b=300] learning - eval_recall_uma on D_test_att = 0.66261\n",
      "Non-Interferent [b=300] learning - eval_f1_uma on D_test_att = 0.79428\n",
      "Non-Interferent [b=300] learning - eval_roc_auc_uma on D_test_att = 0.90063\n",
      "******************************************************************************************************\n",
      "==> Evaluating Standard GBDT under attack [b=150]\n",
      "Baseline [GBDT] learning - eval_log_loss_uma on D_test_att = 0.37034\n",
      "Baseline [GBDT] learning - eval_binary_err_rate_uma on D_test_att = 0.17501\n",
      "Baseline [GBDT] learning - eval_specificity_uma on D_test_att = 0.88664\n",
      "Baseline [GBDT] learning - eval_precision_uma on D_test_att = 0.64528\n",
      "Baseline [GBDT] learning - eval_recall_uma on D_test_att = 0.63509\n",
      "Baseline [GBDT] learning - eval_f1_uma on D_test_att = 0.76226\n",
      "Baseline [GBDT] learning - eval_roc_auc_uma on D_test_att = 0.87695\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=5] under attack [b=150]\n",
      "Adversarial-Boosting [b=5] learning - eval_log_loss_uma on D_test_att = 0.35171\n",
      "Adversarial-Boosting [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.15744\n",
      "Adversarial-Boosting [b=5] learning - eval_specificity_uma on D_test_att = 0.94845\n",
      "Adversarial-Boosting [b=5] learning - eval_precision_uma on D_test_att = 0.76486\n",
      "Adversarial-Boosting [b=5] learning - eval_recall_uma on D_test_att = 0.51646\n",
      "Adversarial-Boosting [b=5] learning - eval_f1_uma on D_test_att = 0.75877\n",
      "Adversarial-Boosting [b=5] learning - eval_roc_auc_uma on D_test_att = 0.88803\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=15] under attack [b=150]\n",
      "Adversarial-Boosting [b=15] learning - eval_log_loss_uma on D_test_att = 0.34074\n",
      "Adversarial-Boosting [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.15390\n",
      "Adversarial-Boosting [b=15] learning - eval_specificity_uma on D_test_att = 0.95562\n",
      "Adversarial-Boosting [b=15] learning - eval_precision_uma on D_test_att = 0.78826\n",
      "Adversarial-Boosting [b=15] learning - eval_recall_uma on D_test_att = 0.50880\n",
      "Adversarial-Boosting [b=15] learning - eval_f1_uma on D_test_att = 0.76102\n",
      "Adversarial-Boosting [b=15] learning - eval_roc_auc_uma on D_test_att = 0.89910\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=150] under attack [b=150]\n",
      "Adversarial-Boosting [b=150] learning - eval_log_loss_uma on D_test_att = 0.32763\n",
      "Adversarial-Boosting [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.14771\n",
      "Adversarial-Boosting [b=150] learning - eval_specificity_uma on D_test_att = 0.96441\n",
      "Adversarial-Boosting [b=150] learning - eval_precision_uma on D_test_att = 0.82224\n",
      "Adversarial-Boosting [b=150] learning - eval_recall_uma on D_test_att = 0.50699\n",
      "Adversarial-Boosting [b=150] learning - eval_f1_uma on D_test_att = 0.76757\n",
      "Adversarial-Boosting [b=150] learning - eval_roc_auc_uma on D_test_att = 0.90693\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=300] under attack [b=150]\n",
      "Adversarial-Boosting [b=300] learning - eval_log_loss_uma on D_test_att = 0.32626\n",
      "Adversarial-Boosting [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.14715\n",
      "Adversarial-Boosting [b=300] learning - eval_specificity_uma on D_test_att = 0.96558\n",
      "Adversarial-Boosting [b=300] learning - eval_precision_uma on D_test_att = 0.82670\n",
      "Adversarial-Boosting [b=300] learning - eval_recall_uma on D_test_att = 0.50564\n",
      "Adversarial-Boosting [b=300] learning - eval_f1_uma on D_test_att = 0.76790\n",
      "Adversarial-Boosting [b=300] learning - eval_roc_auc_uma on D_test_att = 0.90759\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=5] under attack [b=150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Interferent [b=5] learning - eval_log_loss_uma on D_test_att = 0.36046\n",
      "Non-Interferent [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.16108\n",
      "Non-Interferent [b=5] learning - eval_specificity_uma on D_test_att = 0.89777\n",
      "Non-Interferent [b=5] learning - eval_precision_uma on D_test_att = 0.67625\n",
      "Non-Interferent [b=5] learning - eval_recall_uma on D_test_att = 0.65765\n",
      "Non-Interferent [b=5] learning - eval_f1_uma on D_test_att = 0.78030\n",
      "Non-Interferent [b=5] learning - eval_roc_auc_uma on D_test_att = 0.88855\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=15] under attack [b=150]\n",
      "Non-Interferent [b=15] learning - eval_log_loss_uma on D_test_att = 0.36138\n",
      "Non-Interferent [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.16097\n",
      "Non-Interferent [b=15] learning - eval_specificity_uma on D_test_att = 0.89733\n",
      "Non-Interferent [b=15] learning - eval_precision_uma on D_test_att = 0.67591\n",
      "Non-Interferent [b=15] learning - eval_recall_uma on D_test_att = 0.65945\n",
      "Non-Interferent [b=15] learning - eval_f1_uma on D_test_att = 0.78069\n",
      "Non-Interferent [b=15] learning - eval_roc_auc_uma on D_test_att = 0.88844\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=150] under attack [b=150]\n",
      "Non-Interferent [b=150] learning - eval_log_loss_uma on D_test_att = 0.36220\n",
      "Non-Interferent [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.16363\n",
      "Non-Interferent [b=150] learning - eval_specificity_uma on D_test_att = 0.89309\n",
      "Non-Interferent [b=150] learning - eval_precision_uma on D_test_att = 0.66773\n",
      "Non-Interferent [b=150] learning - eval_recall_uma on D_test_att = 0.66171\n",
      "Non-Interferent [b=150] learning - eval_f1_uma on D_test_att = 0.77824\n",
      "Non-Interferent [b=150] learning - eval_roc_auc_uma on D_test_att = 0.88826\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=300] under attack [b=150]\n",
      "Non-Interferent [b=300] learning - eval_log_loss_uma on D_test_att = 0.36158\n",
      "Non-Interferent [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.16064\n",
      "Non-Interferent [b=300] learning - eval_specificity_uma on D_test_att = 0.89675\n",
      "Non-Interferent [b=300] learning - eval_precision_uma on D_test_att = 0.67571\n",
      "Non-Interferent [b=300] learning - eval_recall_uma on D_test_att = 0.66261\n",
      "Non-Interferent [b=300] learning - eval_f1_uma on D_test_att = 0.78151\n",
      "Non-Interferent [b=300] learning - eval_roc_auc_uma on D_test_att = 0.88892\n",
      "******************************************************************************************************\n",
      "==> Evaluating Standard GBDT under attack [b=300]\n",
      "Baseline [GBDT] learning - eval_log_loss_uma on D_test_att = 0.39553\n",
      "Baseline [GBDT] learning - eval_binary_err_rate_uma on D_test_att = 0.18264\n",
      "Baseline [GBDT] learning - eval_specificity_uma on D_test_att = 0.87654\n",
      "Baseline [GBDT] learning - eval_precision_uma on D_test_att = 0.62550\n",
      "Baseline [GBDT] learning - eval_recall_uma on D_test_att = 0.63509\n",
      "Baseline [GBDT] learning - eval_f1_uma on D_test_att = 0.75449\n",
      "Baseline [GBDT] learning - eval_roc_auc_uma on D_test_att = 0.86917\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=5] under attack [b=300]\n",
      "Adversarial-Boosting [b=5] learning - eval_log_loss_uma on D_test_att = 0.37174\n",
      "Adversarial-Boosting [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.16540\n",
      "Adversarial-Boosting [b=5] learning - eval_specificity_uma on D_test_att = 0.93790\n",
      "Adversarial-Boosting [b=5] learning - eval_precision_uma on D_test_att = 0.72976\n",
      "Adversarial-Boosting [b=5] learning - eval_recall_uma on D_test_att = 0.51646\n",
      "Adversarial-Boosting [b=5] learning - eval_f1_uma on D_test_att = 0.75014\n",
      "Adversarial-Boosting [b=5] learning - eval_roc_auc_uma on D_test_att = 0.88059\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=15] under attack [b=300]\n",
      "Adversarial-Boosting [b=15] learning - eval_log_loss_uma on D_test_att = 0.35941\n",
      "Adversarial-Boosting [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.16130\n",
      "Adversarial-Boosting [b=15] learning - eval_specificity_uma on D_test_att = 0.94581\n",
      "Adversarial-Boosting [b=15] learning - eval_precision_uma on D_test_att = 0.75300\n",
      "Adversarial-Boosting [b=15] learning - eval_recall_uma on D_test_att = 0.50880\n",
      "Adversarial-Boosting [b=15] learning - eval_f1_uma on D_test_att = 0.75289\n",
      "Adversarial-Boosting [b=15] learning - eval_roc_auc_uma on D_test_att = 0.89194\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=150] under attack [b=300]\n",
      "Adversarial-Boosting [b=150] learning - eval_log_loss_uma on D_test_att = 0.34061\n",
      "Adversarial-Boosting [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.15323\n",
      "Adversarial-Boosting [b=150] learning - eval_specificity_uma on D_test_att = 0.95709\n",
      "Adversarial-Boosting [b=150] learning - eval_precision_uma on D_test_att = 0.79323\n",
      "Adversarial-Boosting [b=150] learning - eval_recall_uma on D_test_att = 0.50699\n",
      "Adversarial-Boosting [b=150] learning - eval_f1_uma on D_test_att = 0.76136\n",
      "Adversarial-Boosting [b=150] learning - eval_roc_auc_uma on D_test_att = 0.90139\n",
      "******************************************************************************************************\n",
      "==> Evaluating Adversarial Boosting [b_train=300] under attack [b=300]\n",
      "Adversarial-Boosting [b=300] learning - eval_log_loss_uma on D_test_att = 0.32844\n",
      "Adversarial-Boosting [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.14804\n",
      "Adversarial-Boosting [b=300] learning - eval_specificity_uma on D_test_att = 0.96441\n",
      "Adversarial-Boosting [b=300] learning - eval_precision_uma on D_test_att = 0.82185\n",
      "Adversarial-Boosting [b=300] learning - eval_recall_uma on D_test_att = 0.50564\n",
      "Adversarial-Boosting [b=300] learning - eval_f1_uma on D_test_att = 0.76690\n",
      "Adversarial-Boosting [b=300] learning - eval_roc_auc_uma on D_test_att = 0.90642\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=5] under attack [b=300]\n",
      "Non-Interferent [b=5] learning - eval_log_loss_uma on D_test_att = 0.39558\n",
      "Non-Interferent [b=5] learning - eval_binary_err_rate_uma on D_test_att = 0.16915\n",
      "Non-Interferent [b=5] learning - eval_specificity_uma on D_test_att = 0.88708\n",
      "Non-Interferent [b=5] learning - eval_precision_uma on D_test_att = 0.65410\n",
      "Non-Interferent [b=5] learning - eval_recall_uma on D_test_att = 0.65765\n",
      "Non-Interferent [b=5] learning - eval_f1_uma on D_test_att = 0.77187\n",
      "Non-Interferent [b=5] learning - eval_roc_auc_uma on D_test_att = 0.88059\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=15] under attack [b=300]\n",
      "Non-Interferent [b=15] learning - eval_log_loss_uma on D_test_att = 0.39726\n",
      "Non-Interferent [b=15] learning - eval_binary_err_rate_uma on D_test_att = 0.16893\n",
      "Non-Interferent [b=15] learning - eval_specificity_uma on D_test_att = 0.88679\n",
      "Non-Interferent [b=15] learning - eval_precision_uma on D_test_att = 0.65414\n",
      "Non-Interferent [b=15] learning - eval_recall_uma on D_test_att = 0.65945\n",
      "Non-Interferent [b=15] learning - eval_f1_uma on D_test_att = 0.77237\n",
      "Non-Interferent [b=15] learning - eval_roc_auc_uma on D_test_att = 0.88056\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=150] under attack [b=300]\n",
      "Non-Interferent [b=150] learning - eval_log_loss_uma on D_test_att = 0.39842\n",
      "Non-Interferent [b=150] learning - eval_binary_err_rate_uma on D_test_att = 0.17192\n",
      "Non-Interferent [b=150] learning - eval_specificity_uma on D_test_att = 0.88210\n",
      "Non-Interferent [b=150] learning - eval_precision_uma on D_test_att = 0.64569\n",
      "Non-Interferent [b=150] learning - eval_recall_uma on D_test_att = 0.66171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Interferent [b=150] learning - eval_f1_uma on D_test_att = 0.76963\n",
      "Non-Interferent [b=150] learning - eval_roc_auc_uma on D_test_att = 0.88028\n",
      "******************************************************************************************************\n",
      "==> Evaluating Non-Interferent [b_train=300] under attack [b=300]\n",
      "Non-Interferent [b=300] learning - eval_log_loss_uma on D_test_att = 0.39731\n",
      "Non-Interferent [b=300] learning - eval_binary_err_rate_uma on D_test_att = 0.16882\n",
      "Non-Interferent [b=300] learning - eval_specificity_uma on D_test_att = 0.88591\n",
      "Non-Interferent [b=300] learning - eval_precision_uma on D_test_att = 0.65347\n",
      "Non-Interferent [b=300] learning - eval_recall_uma on D_test_att = 0.66261\n",
      "Non-Interferent [b=300] learning - eval_f1_uma on D_test_att = 0.77297\n",
      "Non-Interferent [b=300] learning - eval_roc_auc_uma on D_test_att = 0.88095\n",
      "******************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "eval_under_attack_df = eval_all_models_under_attack(MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Binary Err Rate</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Npv</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.330521</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.701894</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.782680</td>\n",
       "      <td>0.897666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>0.964704</td>\n",
       "      <td>0.826118</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772474</td>\n",
       "      <td>0.910535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.320650</td>\n",
       "      <td>0.145716</td>\n",
       "      <td>0.966462</td>\n",
       "      <td>0.831245</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770215</td>\n",
       "      <td>0.911083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.321078</td>\n",
       "      <td>0.145716</td>\n",
       "      <td>0.967047</td>\n",
       "      <td>0.833210</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769826</td>\n",
       "      <td>0.910905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.320714</td>\n",
       "      <td>0.145495</td>\n",
       "      <td>0.967780</td>\n",
       "      <td>0.835943</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.911422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313097</td>\n",
       "      <td>0.144279</td>\n",
       "      <td>0.920035</td>\n",
       "      <td>0.727545</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798368</td>\n",
       "      <td>0.908567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313453</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.919010</td>\n",
       "      <td>0.725558</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798270</td>\n",
       "      <td>0.908511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313141</td>\n",
       "      <td>0.145384</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.721949</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.797754</td>\n",
       "      <td>0.908698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.312803</td>\n",
       "      <td>0.144057</td>\n",
       "      <td>0.918717</td>\n",
       "      <td>0.725791</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.799337</td>\n",
       "      <td>0.908974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.162742</td>\n",
       "      <td>0.902900</td>\n",
       "      <td>0.679865</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.775033</td>\n",
       "      <td>0.888038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.332794</td>\n",
       "      <td>0.149807</td>\n",
       "      <td>0.958553</td>\n",
       "      <td>0.801821</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767227</td>\n",
       "      <td>0.898126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.322390</td>\n",
       "      <td>0.146158</td>\n",
       "      <td>0.965876</td>\n",
       "      <td>0.828802</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769711</td>\n",
       "      <td>0.909228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>0.146048</td>\n",
       "      <td>0.966608</td>\n",
       "      <td>0.831361</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769448</td>\n",
       "      <td>0.909069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.322429</td>\n",
       "      <td>0.145716</td>\n",
       "      <td>0.967487</td>\n",
       "      <td>0.834698</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769533</td>\n",
       "      <td>0.909572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.327203</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.913445</td>\n",
       "      <td>0.711567</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.792944</td>\n",
       "      <td>0.899859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.327680</td>\n",
       "      <td>0.149585</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.709709</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.792853</td>\n",
       "      <td>0.899865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.327902</td>\n",
       "      <td>0.151907</td>\n",
       "      <td>0.908612</td>\n",
       "      <td>0.701578</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.790682</td>\n",
       "      <td>0.899674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.326442</td>\n",
       "      <td>0.148701</td>\n",
       "      <td>0.912566</td>\n",
       "      <td>0.711036</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.794277</td>\n",
       "      <td>0.900631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.370344</td>\n",
       "      <td>0.175014</td>\n",
       "      <td>0.886643</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.762261</td>\n",
       "      <td>0.876950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.351710</td>\n",
       "      <td>0.157435</td>\n",
       "      <td>0.948448</td>\n",
       "      <td>0.764863</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.758766</td>\n",
       "      <td>0.888028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.340737</td>\n",
       "      <td>0.153897</td>\n",
       "      <td>0.955624</td>\n",
       "      <td>0.788260</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761018</td>\n",
       "      <td>0.899099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.327628</td>\n",
       "      <td>0.147706</td>\n",
       "      <td>0.964411</td>\n",
       "      <td>0.822238</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767566</td>\n",
       "      <td>0.906929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.326260</td>\n",
       "      <td>0.147153</td>\n",
       "      <td>0.965583</td>\n",
       "      <td>0.826696</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767899</td>\n",
       "      <td>0.907591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.360459</td>\n",
       "      <td>0.161083</td>\n",
       "      <td>0.897774</td>\n",
       "      <td>0.676252</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.780300</td>\n",
       "      <td>0.888552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.361381</td>\n",
       "      <td>0.160973</td>\n",
       "      <td>0.897335</td>\n",
       "      <td>0.675913</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.780690</td>\n",
       "      <td>0.888442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.362202</td>\n",
       "      <td>0.163626</td>\n",
       "      <td>0.893087</td>\n",
       "      <td>0.667729</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.778242</td>\n",
       "      <td>0.888264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.361584</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>0.896749</td>\n",
       "      <td>0.675713</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.781515</td>\n",
       "      <td>0.888915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.395533</td>\n",
       "      <td>0.182642</td>\n",
       "      <td>0.876538</td>\n",
       "      <td>0.625500</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.754493</td>\n",
       "      <td>0.869172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.371742</td>\n",
       "      <td>0.165395</td>\n",
       "      <td>0.937903</td>\n",
       "      <td>0.729764</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>0.880591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.359406</td>\n",
       "      <td>0.161305</td>\n",
       "      <td>0.945811</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.752886</td>\n",
       "      <td>0.891943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.340607</td>\n",
       "      <td>0.153234</td>\n",
       "      <td>0.957088</td>\n",
       "      <td>0.793225</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761362</td>\n",
       "      <td>0.901390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.328444</td>\n",
       "      <td>0.148038</td>\n",
       "      <td>0.964411</td>\n",
       "      <td>0.821848</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.766897</td>\n",
       "      <td>0.906424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.395583</td>\n",
       "      <td>0.169154</td>\n",
       "      <td>0.887083</td>\n",
       "      <td>0.654105</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.771867</td>\n",
       "      <td>0.880590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.168933</td>\n",
       "      <td>0.886790</td>\n",
       "      <td>0.654139</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772372</td>\n",
       "      <td>0.880555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.398422</td>\n",
       "      <td>0.171918</td>\n",
       "      <td>0.882103</td>\n",
       "      <td>0.645687</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.880275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.397313</td>\n",
       "      <td>0.168823</td>\n",
       "      <td>0.885911</td>\n",
       "      <td>0.653470</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772967</td>\n",
       "      <td>0.880949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Budget  Log Loss  Binary Err Rate  \\\n",
       "0               Baseline [GBDT]      5  0.330521         0.155556   \n",
       "1    Adversarial-Boosting [b=5]      5  0.320084         0.145163   \n",
       "2   Adversarial-Boosting [b=15]      5  0.320650         0.145716   \n",
       "3  Adversarial-Boosting [b=150]      5  0.321078         0.145716   \n",
       "4  Adversarial-Boosting [b=300]      5  0.320714         0.145495   \n",
       "5         Non-Interferent [b=5]      5  0.313097         0.144279   \n",
       "6        Non-Interferent [b=15]      5  0.313453         0.144610   \n",
       "7       Non-Interferent [b=150]      5  0.313141         0.145384   \n",
       "8       Non-Interferent [b=300]      5  0.312803         0.144057   \n",
       "0               Baseline [GBDT]     15  0.345171         0.162742   \n",
       "1    Adversarial-Boosting [b=5]     15  0.332794         0.149807   \n",
       "2   Adversarial-Boosting [b=15]     15  0.322390         0.146158   \n",
       "3  Adversarial-Boosting [b=150]     15  0.322785         0.146048   \n",
       "4  Adversarial-Boosting [b=300]     15  0.322429         0.145716   \n",
       "5         Non-Interferent [b=5]     15  0.327203         0.149254   \n",
       "6        Non-Interferent [b=15]     15  0.327680         0.149585   \n",
       "7       Non-Interferent [b=150]     15  0.327902         0.151907   \n",
       "8       Non-Interferent [b=300]     15  0.326442         0.148701   \n",
       "0               Baseline [GBDT]    150  0.370344         0.175014   \n",
       "1    Adversarial-Boosting [b=5]    150  0.351710         0.157435   \n",
       "2   Adversarial-Boosting [b=15]    150  0.340737         0.153897   \n",
       "3  Adversarial-Boosting [b=150]    150  0.327628         0.147706   \n",
       "4  Adversarial-Boosting [b=300]    150  0.326260         0.147153   \n",
       "5         Non-Interferent [b=5]    150  0.360459         0.161083   \n",
       "6        Non-Interferent [b=15]    150  0.361381         0.160973   \n",
       "7       Non-Interferent [b=150]    150  0.362202         0.163626   \n",
       "8       Non-Interferent [b=300]    150  0.361584         0.160641   \n",
       "0               Baseline [GBDT]    300  0.395533         0.182642   \n",
       "1    Adversarial-Boosting [b=5]    300  0.371742         0.165395   \n",
       "2   Adversarial-Boosting [b=15]    300  0.359406         0.161305   \n",
       "3  Adversarial-Boosting [b=150]    300  0.340607         0.153234   \n",
       "4  Adversarial-Boosting [b=300]    300  0.328444         0.148038   \n",
       "5         Non-Interferent [b=5]    300  0.395583         0.169154   \n",
       "6        Non-Interferent [b=15]    300  0.397260         0.168933   \n",
       "7       Non-Interferent [b=150]    300  0.398422         0.171918   \n",
       "8       Non-Interferent [b=300]    300  0.397313         0.168823   \n",
       "\n",
       "   Specificity  Precision    Recall   Npv        F1   Roc Auc  \n",
       "0     0.912419   0.701894  0.635092  None  0.782680  0.897666  \n",
       "1     0.964704   0.826118  0.516464  None  0.772474  0.910535  \n",
       "2     0.966462   0.831245  0.508796  None  0.770215  0.911083  \n",
       "3     0.967047   0.833210  0.506991  None  0.769826  0.910905  \n",
       "4     0.967780   0.835943  0.505638  None  0.769785  0.911422  \n",
       "5     0.920035   0.727545  0.657645  None  0.798368  0.908567  \n",
       "6     0.919010   0.725558  0.659450  None  0.798270  0.908511  \n",
       "7     0.917252   0.721949  0.661705  None  0.797754  0.908698  \n",
       "8     0.918717   0.725791  0.662607  None  0.799337  0.908974  \n",
       "0     0.902900   0.679865  0.635092  None  0.775033  0.888038  \n",
       "1     0.958553   0.801821  0.516464  None  0.767227  0.898126  \n",
       "2     0.965876   0.828802  0.508796  None  0.769711  0.909228  \n",
       "3     0.966608   0.831361  0.506991  None  0.769448  0.909069  \n",
       "4     0.967487   0.834698  0.505638  None  0.769533  0.909572  \n",
       "5     0.913445   0.711567  0.657645  None  0.792944  0.899859  \n",
       "6     0.912419   0.709709  0.659450  None  0.792853  0.899865  \n",
       "7     0.908612   0.701578  0.661705  None  0.790682  0.899674  \n",
       "8     0.912566   0.711036  0.662607  None  0.794277  0.900631  \n",
       "0     0.886643   0.645280  0.635092  None  0.762261  0.876950  \n",
       "1     0.948448   0.764863  0.516464  None  0.758766  0.888028  \n",
       "2     0.955624   0.788260  0.508796  None  0.761018  0.899099  \n",
       "3     0.964411   0.822238  0.506991  None  0.767566  0.906929  \n",
       "4     0.965583   0.826696  0.505638  None  0.767899  0.907591  \n",
       "5     0.897774   0.676252  0.657645  None  0.780300  0.888552  \n",
       "6     0.897335   0.675913  0.659450  None  0.780690  0.888442  \n",
       "7     0.893087   0.667729  0.661705  None  0.778242  0.888264  \n",
       "8     0.896749   0.675713  0.662607  None  0.781515  0.888915  \n",
       "0     0.876538   0.625500  0.635092  None  0.754493  0.869172  \n",
       "1     0.937903   0.729764  0.516464  None  0.750137  0.880591  \n",
       "2     0.945811   0.753004  0.508796  None  0.752886  0.891943  \n",
       "3     0.957088   0.793225  0.506991  None  0.761362  0.901390  \n",
       "4     0.964411   0.821848  0.505638  None  0.766897  0.906424  \n",
       "5     0.887083   0.654105  0.657645  None  0.771867  0.880590  \n",
       "6     0.886790   0.654139  0.659450  None  0.772372  0.880555  \n",
       "7     0.882103   0.645687  0.661705  None  0.769634  0.880275  \n",
       "8     0.885911   0.653470  0.662607  None  0.772967  0.880949  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_under_attack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = pd.concat([std_gbdt_df,\n",
    "                        adv_boost_df_b5,\n",
    "                        adv_boost_df_b15,\n",
    "                        adv_boost_df_b150,\n",
    "                        adv_boost_df_b300,\n",
    "                        non_interf_df_b5,\n",
    "                        non_interf_df_b15,\n",
    "                        non_interf_df_b150,\n",
    "                        non_interf_df_b300,\n",
    "                        eval_under_attack_df], \n",
    "                       axis=0, \n",
    "                       sort=False)\n",
    "overall_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Binary Err Rate</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Npv</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300081</td>\n",
       "      <td>0.137866</td>\n",
       "      <td>0.935852</td>\n",
       "      <td>0.762730</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>0.887623</td>\n",
       "      <td>0.802092</td>\n",
       "      <td>0.916728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317257</td>\n",
       "      <td>0.144168</td>\n",
       "      <td>0.966022</td>\n",
       "      <td>0.831518</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>0.860198</td>\n",
       "      <td>0.773609</td>\n",
       "      <td>0.913199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318171</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.967926</td>\n",
       "      <td>0.837416</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>0.858535</td>\n",
       "      <td>0.771476</td>\n",
       "      <td>0.913467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318685</td>\n",
       "      <td>0.144831</td>\n",
       "      <td>0.968219</td>\n",
       "      <td>0.838180</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>0.858126</td>\n",
       "      <td>0.770835</td>\n",
       "      <td>0.913253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318377</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>0.969098</td>\n",
       "      <td>0.841592</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>0.857902</td>\n",
       "      <td>0.770922</td>\n",
       "      <td>0.913692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288309</td>\n",
       "      <td>0.134439</td>\n",
       "      <td>0.933070</td>\n",
       "      <td>0.761358</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>0.893548</td>\n",
       "      <td>0.809297</td>\n",
       "      <td>0.923131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288172</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.933948</td>\n",
       "      <td>0.764245</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>0.894139</td>\n",
       "      <td>0.810800</td>\n",
       "      <td>0.923153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287877</td>\n",
       "      <td>0.133002</td>\n",
       "      <td>0.933656</td>\n",
       "      <td>0.764062</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.811496</td>\n",
       "      <td>0.923354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288208</td>\n",
       "      <td>0.133112</td>\n",
       "      <td>0.933216</td>\n",
       "      <td>0.763117</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.894944</td>\n",
       "      <td>0.811499</td>\n",
       "      <td>0.923355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.330521</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.701894</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.782680</td>\n",
       "      <td>0.897666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>0.964704</td>\n",
       "      <td>0.826118</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772474</td>\n",
       "      <td>0.910535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.320650</td>\n",
       "      <td>0.145716</td>\n",
       "      <td>0.966462</td>\n",
       "      <td>0.831245</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.770215</td>\n",
       "      <td>0.911083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.321078</td>\n",
       "      <td>0.145716</td>\n",
       "      <td>0.967047</td>\n",
       "      <td>0.833210</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769826</td>\n",
       "      <td>0.910905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.320714</td>\n",
       "      <td>0.145495</td>\n",
       "      <td>0.967780</td>\n",
       "      <td>0.835943</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.911422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313097</td>\n",
       "      <td>0.144279</td>\n",
       "      <td>0.920035</td>\n",
       "      <td>0.727545</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798368</td>\n",
       "      <td>0.908567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313453</td>\n",
       "      <td>0.144610</td>\n",
       "      <td>0.919010</td>\n",
       "      <td>0.725558</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.798270</td>\n",
       "      <td>0.908511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.313141</td>\n",
       "      <td>0.145384</td>\n",
       "      <td>0.917252</td>\n",
       "      <td>0.721949</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.797754</td>\n",
       "      <td>0.908698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.312803</td>\n",
       "      <td>0.144057</td>\n",
       "      <td>0.918717</td>\n",
       "      <td>0.725791</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.799337</td>\n",
       "      <td>0.908974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.162742</td>\n",
       "      <td>0.902900</td>\n",
       "      <td>0.679865</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.775033</td>\n",
       "      <td>0.888038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.332794</td>\n",
       "      <td>0.149807</td>\n",
       "      <td>0.958553</td>\n",
       "      <td>0.801821</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767227</td>\n",
       "      <td>0.898126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.322390</td>\n",
       "      <td>0.146158</td>\n",
       "      <td>0.965876</td>\n",
       "      <td>0.828802</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769711</td>\n",
       "      <td>0.909228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.322785</td>\n",
       "      <td>0.146048</td>\n",
       "      <td>0.966608</td>\n",
       "      <td>0.831361</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769448</td>\n",
       "      <td>0.909069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.322429</td>\n",
       "      <td>0.145716</td>\n",
       "      <td>0.967487</td>\n",
       "      <td>0.834698</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769533</td>\n",
       "      <td>0.909572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.327203</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.913445</td>\n",
       "      <td>0.711567</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.792944</td>\n",
       "      <td>0.899859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.327680</td>\n",
       "      <td>0.149585</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.709709</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.792853</td>\n",
       "      <td>0.899865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.327902</td>\n",
       "      <td>0.151907</td>\n",
       "      <td>0.908612</td>\n",
       "      <td>0.701578</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.790682</td>\n",
       "      <td>0.899674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.326442</td>\n",
       "      <td>0.148701</td>\n",
       "      <td>0.912566</td>\n",
       "      <td>0.711036</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.794277</td>\n",
       "      <td>0.900631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.370344</td>\n",
       "      <td>0.175014</td>\n",
       "      <td>0.886643</td>\n",
       "      <td>0.645280</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.762261</td>\n",
       "      <td>0.876950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.351710</td>\n",
       "      <td>0.157435</td>\n",
       "      <td>0.948448</td>\n",
       "      <td>0.764863</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.758766</td>\n",
       "      <td>0.888028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.340737</td>\n",
       "      <td>0.153897</td>\n",
       "      <td>0.955624</td>\n",
       "      <td>0.788260</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761018</td>\n",
       "      <td>0.899099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.327628</td>\n",
       "      <td>0.147706</td>\n",
       "      <td>0.964411</td>\n",
       "      <td>0.822238</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767566</td>\n",
       "      <td>0.906929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.326260</td>\n",
       "      <td>0.147153</td>\n",
       "      <td>0.965583</td>\n",
       "      <td>0.826696</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.767899</td>\n",
       "      <td>0.907591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.360459</td>\n",
       "      <td>0.161083</td>\n",
       "      <td>0.897774</td>\n",
       "      <td>0.676252</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.780300</td>\n",
       "      <td>0.888552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.361381</td>\n",
       "      <td>0.160973</td>\n",
       "      <td>0.897335</td>\n",
       "      <td>0.675913</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.780690</td>\n",
       "      <td>0.888442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.362202</td>\n",
       "      <td>0.163626</td>\n",
       "      <td>0.893087</td>\n",
       "      <td>0.667729</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.778242</td>\n",
       "      <td>0.888264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>150</td>\n",
       "      <td>0.361584</td>\n",
       "      <td>0.160641</td>\n",
       "      <td>0.896749</td>\n",
       "      <td>0.675713</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.781515</td>\n",
       "      <td>0.888915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Baseline [GBDT]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.395533</td>\n",
       "      <td>0.182642</td>\n",
       "      <td>0.876538</td>\n",
       "      <td>0.625500</td>\n",
       "      <td>0.635092</td>\n",
       "      <td>None</td>\n",
       "      <td>0.754493</td>\n",
       "      <td>0.869172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Adversarial-Boosting [b=5]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.371742</td>\n",
       "      <td>0.165395</td>\n",
       "      <td>0.937903</td>\n",
       "      <td>0.729764</td>\n",
       "      <td>0.516464</td>\n",
       "      <td>None</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>0.880591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Adversarial-Boosting [b=15]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.359406</td>\n",
       "      <td>0.161305</td>\n",
       "      <td>0.945811</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>None</td>\n",
       "      <td>0.752886</td>\n",
       "      <td>0.891943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Adversarial-Boosting [b=150]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.340607</td>\n",
       "      <td>0.153234</td>\n",
       "      <td>0.957088</td>\n",
       "      <td>0.793225</td>\n",
       "      <td>0.506991</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761362</td>\n",
       "      <td>0.901390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Adversarial-Boosting [b=300]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.328444</td>\n",
       "      <td>0.148038</td>\n",
       "      <td>0.964411</td>\n",
       "      <td>0.821848</td>\n",
       "      <td>0.505638</td>\n",
       "      <td>None</td>\n",
       "      <td>0.766897</td>\n",
       "      <td>0.906424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Non-Interferent [b=5]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.395583</td>\n",
       "      <td>0.169154</td>\n",
       "      <td>0.887083</td>\n",
       "      <td>0.654105</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>None</td>\n",
       "      <td>0.771867</td>\n",
       "      <td>0.880590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Non-Interferent [b=15]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.168933</td>\n",
       "      <td>0.886790</td>\n",
       "      <td>0.654139</td>\n",
       "      <td>0.659450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772372</td>\n",
       "      <td>0.880555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Non-Interferent [b=150]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.398422</td>\n",
       "      <td>0.171918</td>\n",
       "      <td>0.882103</td>\n",
       "      <td>0.645687</td>\n",
       "      <td>0.661705</td>\n",
       "      <td>None</td>\n",
       "      <td>0.769634</td>\n",
       "      <td>0.880275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Non-Interferent [b=300]</td>\n",
       "      <td>300</td>\n",
       "      <td>0.397313</td>\n",
       "      <td>0.168823</td>\n",
       "      <td>0.885911</td>\n",
       "      <td>0.653470</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>None</td>\n",
       "      <td>0.772967</td>\n",
       "      <td>0.880949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model Budget  Log Loss  Binary Err Rate  \\\n",
       "0                Baseline [GBDT]      0  0.300081         0.137866   \n",
       "1     Adversarial-Boosting [b=5]      0  0.317257         0.144168   \n",
       "2    Adversarial-Boosting [b=15]      0  0.318171         0.144610   \n",
       "3   Adversarial-Boosting [b=150]      0  0.318685         0.144831   \n",
       "4   Adversarial-Boosting [b=300]      0  0.318377         0.144500   \n",
       "5          Non-Interferent [b=5]      0  0.288309         0.134439   \n",
       "6         Non-Interferent [b=15]      0  0.288172         0.133333   \n",
       "7        Non-Interferent [b=150]      0  0.287877         0.133002   \n",
       "8        Non-Interferent [b=300]      0  0.288208         0.133112   \n",
       "9                Baseline [GBDT]      5  0.330521         0.155556   \n",
       "10    Adversarial-Boosting [b=5]      5  0.320084         0.145163   \n",
       "11   Adversarial-Boosting [b=15]      5  0.320650         0.145716   \n",
       "12  Adversarial-Boosting [b=150]      5  0.321078         0.145716   \n",
       "13  Adversarial-Boosting [b=300]      5  0.320714         0.145495   \n",
       "14         Non-Interferent [b=5]      5  0.313097         0.144279   \n",
       "15        Non-Interferent [b=15]      5  0.313453         0.144610   \n",
       "16       Non-Interferent [b=150]      5  0.313141         0.145384   \n",
       "17       Non-Interferent [b=300]      5  0.312803         0.144057   \n",
       "18               Baseline [GBDT]     15  0.345171         0.162742   \n",
       "19    Adversarial-Boosting [b=5]     15  0.332794         0.149807   \n",
       "20   Adversarial-Boosting [b=15]     15  0.322390         0.146158   \n",
       "21  Adversarial-Boosting [b=150]     15  0.322785         0.146048   \n",
       "22  Adversarial-Boosting [b=300]     15  0.322429         0.145716   \n",
       "23         Non-Interferent [b=5]     15  0.327203         0.149254   \n",
       "24        Non-Interferent [b=15]     15  0.327680         0.149585   \n",
       "25       Non-Interferent [b=150]     15  0.327902         0.151907   \n",
       "26       Non-Interferent [b=300]     15  0.326442         0.148701   \n",
       "27               Baseline [GBDT]    150  0.370344         0.175014   \n",
       "28    Adversarial-Boosting [b=5]    150  0.351710         0.157435   \n",
       "29   Adversarial-Boosting [b=15]    150  0.340737         0.153897   \n",
       "30  Adversarial-Boosting [b=150]    150  0.327628         0.147706   \n",
       "31  Adversarial-Boosting [b=300]    150  0.326260         0.147153   \n",
       "32         Non-Interferent [b=5]    150  0.360459         0.161083   \n",
       "33        Non-Interferent [b=15]    150  0.361381         0.160973   \n",
       "34       Non-Interferent [b=150]    150  0.362202         0.163626   \n",
       "35       Non-Interferent [b=300]    150  0.361584         0.160641   \n",
       "36               Baseline [GBDT]    300  0.395533         0.182642   \n",
       "37    Adversarial-Boosting [b=5]    300  0.371742         0.165395   \n",
       "38   Adversarial-Boosting [b=15]    300  0.359406         0.161305   \n",
       "39  Adversarial-Boosting [b=150]    300  0.340607         0.153234   \n",
       "40  Adversarial-Boosting [b=300]    300  0.328444         0.148038   \n",
       "41         Non-Interferent [b=5]    300  0.395583         0.169154   \n",
       "42        Non-Interferent [b=15]    300  0.397260         0.168933   \n",
       "43       Non-Interferent [b=150]    300  0.398422         0.171918   \n",
       "44       Non-Interferent [b=300]    300  0.397313         0.168823   \n",
       "\n",
       "    Specificity  Precision    Recall       Npv        F1   Roc Auc  \n",
       "0      0.935852   0.762730  0.635092  0.887623  0.802092  0.916728  \n",
       "1      0.966022   0.831518  0.516464  0.860198  0.773609  0.913199  \n",
       "2      0.967926   0.837416  0.508796  0.858535  0.771476  0.913467  \n",
       "3      0.968219   0.838180  0.506991  0.858126  0.770835  0.913253  \n",
       "4      0.969098   0.841592  0.505638  0.857902  0.770922  0.913692  \n",
       "5      0.933070   0.761358  0.657645  0.893548  0.809297  0.923131  \n",
       "6      0.933948   0.764245  0.659450  0.894139  0.810800  0.923153  \n",
       "7      0.933656   0.764062  0.661705  0.894737  0.811496  0.923354  \n",
       "8      0.933216   0.763117  0.662607  0.894944  0.811499  0.923355  \n",
       "9      0.912419   0.701894  0.635092      None  0.782680  0.897666  \n",
       "10     0.964704   0.826118  0.516464      None  0.772474  0.910535  \n",
       "11     0.966462   0.831245  0.508796      None  0.770215  0.911083  \n",
       "12     0.967047   0.833210  0.506991      None  0.769826  0.910905  \n",
       "13     0.967780   0.835943  0.505638      None  0.769785  0.911422  \n",
       "14     0.920035   0.727545  0.657645      None  0.798368  0.908567  \n",
       "15     0.919010   0.725558  0.659450      None  0.798270  0.908511  \n",
       "16     0.917252   0.721949  0.661705      None  0.797754  0.908698  \n",
       "17     0.918717   0.725791  0.662607      None  0.799337  0.908974  \n",
       "18     0.902900   0.679865  0.635092      None  0.775033  0.888038  \n",
       "19     0.958553   0.801821  0.516464      None  0.767227  0.898126  \n",
       "20     0.965876   0.828802  0.508796      None  0.769711  0.909228  \n",
       "21     0.966608   0.831361  0.506991      None  0.769448  0.909069  \n",
       "22     0.967487   0.834698  0.505638      None  0.769533  0.909572  \n",
       "23     0.913445   0.711567  0.657645      None  0.792944  0.899859  \n",
       "24     0.912419   0.709709  0.659450      None  0.792853  0.899865  \n",
       "25     0.908612   0.701578  0.661705      None  0.790682  0.899674  \n",
       "26     0.912566   0.711036  0.662607      None  0.794277  0.900631  \n",
       "27     0.886643   0.645280  0.635092      None  0.762261  0.876950  \n",
       "28     0.948448   0.764863  0.516464      None  0.758766  0.888028  \n",
       "29     0.955624   0.788260  0.508796      None  0.761018  0.899099  \n",
       "30     0.964411   0.822238  0.506991      None  0.767566  0.906929  \n",
       "31     0.965583   0.826696  0.505638      None  0.767899  0.907591  \n",
       "32     0.897774   0.676252  0.657645      None  0.780300  0.888552  \n",
       "33     0.897335   0.675913  0.659450      None  0.780690  0.888442  \n",
       "34     0.893087   0.667729  0.661705      None  0.778242  0.888264  \n",
       "35     0.896749   0.675713  0.662607      None  0.781515  0.888915  \n",
       "36     0.876538   0.625500  0.635092      None  0.754493  0.869172  \n",
       "37     0.937903   0.729764  0.516464      None  0.750137  0.880591  \n",
       "38     0.945811   0.753004  0.508796      None  0.752886  0.891943  \n",
       "39     0.957088   0.793225  0.506991      None  0.761362  0.901390  \n",
       "40     0.964411   0.821848  0.505638      None  0.766897  0.906424  \n",
       "41     0.887083   0.654105  0.657645      None  0.771867  0.880590  \n",
       "42     0.886790   0.654139  0.659450      None  0.772372  0.880555  \n",
       "43     0.882103   0.645687  0.661705      None  0.769634  0.880275  \n",
       "44     0.885911   0.653470  0.662607      None  0.772967  0.880949  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the DataFrame containing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df.to_csv(\"../plots/plot_census.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
